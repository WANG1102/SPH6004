{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "torch.set_num_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "ROOT_PATH = '/home/jiahao/code/SPH6004/mimiciv_aki/'\n",
    "\n",
    "\n",
    "class ISIC(Dataset):\n",
    "\n",
    "    def __init__(self, setname):\n",
    "        csv_path = osp.join(ROOT_PATH, setname + '.npy')\n",
    "        data = np.load(csv_path)\n",
    "        \n",
    "        self.data = data[:,0]\n",
    "        label = data[:,1]\n",
    "        label_tensor = torch.from_numpy(label.astype(float))\n",
    "        self.label = label_tensor.tolist()\n",
    "#         self.label = torch.from_numpy(label.astype(float))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        data, label = self.data[i], self.label[i]\n",
    "        data_tensor = torch.tensor(data)\n",
    "        label = torch.tensor(label)\n",
    "        return data_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None):\n",
    "\n",
    "        # if indices is not provided,\n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset)))             if indices is None else indices\n",
    "\n",
    "        # if num_samples is not provided,\n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices)             if num_samples is None else num_samples\n",
    "\n",
    "        # distribution of classes in the dataset\n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "\n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        dataset_type = type(dataset)\n",
    "        if dataset_type is torchvision.datasets.MNIST:\n",
    "            return dataset.train_labels[idx].item()\n",
    "        elif dataset_type is torchvision.datasets.ImageFolder:\n",
    "            return dataset.imgs[idx][1]\n",
    "        else:\n",
    "            return dataset.label[idx]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ISIC('train_data_window_7')\n",
    "valset = ISIC('test_data_window_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "# n_train = len(dataset)\n",
    "# split = n_train // 8\n",
    "# trainset, valset = torch.utils.data.random_split(dataset, [n_train-split, split])\n",
    "train_loader = DataLoader(dataset=trainset, sampler=ImbalancedDatasetSampler(trainset),\n",
    "                              num_workers=4,batch_size=1024,pin_memory=True)\n",
    "test_loader  = DataLoader(dataset=valset, shuffle=True,\n",
    "                              num_workers=0,batch_size=1024,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 7, 26])\n"
     ]
    }
   ],
   "source": [
    "data,label = next(iter(train_loader))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Any\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_class=3,num_classes: int = 1000) -> None:\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.embedding = nn.Conv2d(in_class,3,kernel_size=1)\n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 64, 3, 1, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(True),\n",
    "#             torch.nn.MaxPool2d(2,2,0),\n",
    "            \n",
    "            torch.nn.Conv2d(64, 64, 3, 1, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(True),\n",
    "#             torch.nn.MaxPool2d(2,2,0),\n",
    "            \n",
    "            torch.nn.Conv2d(64, 64, 3, 1, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(True),\n",
    "#             torch.nn.MaxPool2d(2,2,0),\n",
    "            \n",
    "            torch.nn.Conv2d(64, 64, 3, 1, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(True),\n",
    "#             torch.nn.MaxPool2d(2,2,0),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = torch.nn.Sigmoid()\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    acc_sum = 0\n",
    "    model.train()\n",
    "    times = time.time()\n",
    "    nb_classes = 2\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    \n",
    "    \n",
    "    for i ,(images,labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = Variable(images.unsqueeze(3).float().cuda())\n",
    "\n",
    "        labels = Variable(labels.view(-1,1).cuda()).float()\n",
    "#         labels = Variable(labels.cuda())\n",
    "\n",
    "                # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        results = model(images)\n",
    "        outputs = results\n",
    "\n",
    "        loss = criterion(outputs,labels)\n",
    "        result = F(outputs)\n",
    "        predicted = (result.data>0.5).float()\n",
    "        #             total += a.size(0)\n",
    "        #             correct += (predicted == a.data).sum()\n",
    "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "            confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "        acc = confusion_matrix.diag() / confusion_matrix.sum(1)\n",
    "        acc_non = acc[0]\n",
    "        acc_in = acc[1]\n",
    "        mean_acc = torch.mean(acc)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # record the loss\n",
    "        iter_loss = loss.data.item()      \n",
    "        loss_sum += float(iter_loss)\n",
    "        write_loss.add_scalar('epoch/loss', iter_loss, epoch*len(train_loader) + i)\n",
    "        \n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "                print(\"Epoch [%d/%d], Iter [%d/%d] Loss: %.4f Acc: %d %%\" %(epoch+1, total_epoch, i+1, len(train_loader),\n",
    "                                                                            loss.data.item(),100*float(mean_acc)))\n",
    "\n",
    "    return  float(loss_sum)/len(train_loader), float(acc_non),float(acc_in)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum_t = 0\n",
    "    nb_classes = 2\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    with torch.no_grad():\n",
    "        for images,labels in test_loader:\n",
    "        \n",
    "            images = Variable(images.unsqueeze(3).float().cuda())\n",
    "            a = labels\n",
    "            a = Variable(a.view(-1,1).cuda()).float()\n",
    "            \n",
    "            results = model(images)\n",
    "            outputs = results\n",
    "            outputs = F(outputs)\n",
    "            loss_test = criterion(results, a)\n",
    "            iter_loss_t = loss_test.data.item()\n",
    "            loss_sum_t += float(iter_loss_t)\n",
    "            predicted = (outputs.data>0.5).float()\n",
    "        #             total += a.size(0)\n",
    "        #             correct += (predicted == a.data).sum()\n",
    "            for t, p in zip(a.view(-1), predicted.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "        acc = confusion_matrix.diag() / confusion_matrix.sum(1)\n",
    "        acc_non = acc[0]\n",
    "        acc_in = acc[1]\n",
    "        mean_acc = torch.mean(acc)\n",
    "\n",
    "\n",
    "    print('Accuracy of the model on the neg seq: %d %%' % (100 * float(acc_non)))\n",
    "    print('Accuracy of the model on the pos seq: %d %%' % (100*float(acc_in)))\n",
    "    return float(acc_non), float(acc_in),float(loss_sum_t) / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        save_filename_c = 'conv4-3-max-acc.pt'\n",
    "        save_path_c = os.path.join(save_dir, save_filename_c)\n",
    "        torch.save(model.state_dict(), save_path_c)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tensorboardX import SummaryWriter\n",
    "LR = 0.1\n",
    "total_epoch = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=LR)\n",
    "criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "model.cuda()\n",
    "classes = ('aki_neg','aki_pos')\n",
    "# optimizer = torch.optim.Adam(model.fc.parameters(), lr=lr,weight_decay=4e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=5)\n",
    "acc_best = 0\n",
    "total_epoch = 100\n",
    "save_dir = '/home/jiahao/code/SPH6004/mimiciv_aki/model/'\n",
    "write_loss = SummaryWriter('/home/jiahao/code/SPH6004/mimiciv_aki/log/conv4-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Iter [10/3426] Loss: 0.4739 Acc: 75 %\n",
      "Epoch [1/100], Iter [20/3426] Loss: 0.4108 Acc: 77 %\n",
      "Epoch [1/100], Iter [30/3426] Loss: 0.3834 Acc: 79 %\n",
      "Epoch [1/100], Iter [40/3426] Loss: 0.3831 Acc: 80 %\n",
      "Epoch [1/100], Iter [50/3426] Loss: 0.3438 Acc: 80 %\n",
      "Epoch [1/100], Iter [60/3426] Loss: 0.3508 Acc: 80 %\n",
      "Epoch [1/100], Iter [70/3426] Loss: 0.3385 Acc: 81 %\n",
      "Epoch [1/100], Iter [80/3426] Loss: 0.3573 Acc: 81 %\n",
      "Epoch [1/100], Iter [90/3426] Loss: 0.3741 Acc: 81 %\n",
      "Epoch [1/100], Iter [100/3426] Loss: 0.3482 Acc: 81 %\n",
      "Epoch [1/100], Iter [110/3426] Loss: 0.3876 Acc: 82 %\n",
      "Epoch [1/100], Iter [120/3426] Loss: 0.3355 Acc: 82 %\n",
      "Epoch [1/100], Iter [130/3426] Loss: 0.3917 Acc: 82 %\n",
      "Epoch [1/100], Iter [140/3426] Loss: 0.3339 Acc: 82 %\n",
      "Epoch [1/100], Iter [150/3426] Loss: 0.3471 Acc: 82 %\n",
      "Epoch [1/100], Iter [160/3426] Loss: 0.3402 Acc: 82 %\n",
      "Epoch [1/100], Iter [170/3426] Loss: 0.3266 Acc: 82 %\n",
      "Epoch [1/100], Iter [180/3426] Loss: 0.3232 Acc: 82 %\n",
      "Epoch [1/100], Iter [190/3426] Loss: 0.3214 Acc: 82 %\n",
      "Epoch [1/100], Iter [200/3426] Loss: 0.3320 Acc: 82 %\n",
      "Epoch [1/100], Iter [210/3426] Loss: 0.3453 Acc: 83 %\n",
      "Epoch [1/100], Iter [220/3426] Loss: 0.3232 Acc: 83 %\n",
      "Epoch [1/100], Iter [230/3426] Loss: 0.3378 Acc: 83 %\n",
      "Epoch [1/100], Iter [240/3426] Loss: 0.3362 Acc: 83 %\n",
      "Epoch [1/100], Iter [250/3426] Loss: 0.3695 Acc: 83 %\n",
      "Epoch [1/100], Iter [260/3426] Loss: 0.3180 Acc: 83 %\n",
      "Epoch [1/100], Iter [270/3426] Loss: 0.3098 Acc: 83 %\n",
      "Epoch [1/100], Iter [280/3426] Loss: 0.3285 Acc: 83 %\n",
      "Epoch [1/100], Iter [290/3426] Loss: 0.3126 Acc: 83 %\n",
      "Epoch [1/100], Iter [300/3426] Loss: 0.3358 Acc: 83 %\n",
      "Epoch [1/100], Iter [310/3426] Loss: 0.3371 Acc: 83 %\n",
      "Epoch [1/100], Iter [320/3426] Loss: 0.3365 Acc: 83 %\n",
      "Epoch [1/100], Iter [330/3426] Loss: 0.3752 Acc: 83 %\n",
      "Epoch [1/100], Iter [340/3426] Loss: 0.3650 Acc: 83 %\n",
      "Epoch [1/100], Iter [350/3426] Loss: 0.3616 Acc: 83 %\n",
      "Epoch [1/100], Iter [360/3426] Loss: 0.3201 Acc: 83 %\n",
      "Epoch [1/100], Iter [370/3426] Loss: 0.3392 Acc: 83 %\n",
      "Epoch [1/100], Iter [380/3426] Loss: 0.3774 Acc: 83 %\n",
      "Epoch [1/100], Iter [390/3426] Loss: 0.3634 Acc: 83 %\n",
      "Epoch [1/100], Iter [400/3426] Loss: 0.3338 Acc: 83 %\n",
      "Epoch [1/100], Iter [410/3426] Loss: 0.3208 Acc: 83 %\n",
      "Epoch [1/100], Iter [420/3426] Loss: 0.3452 Acc: 83 %\n",
      "Epoch [1/100], Iter [430/3426] Loss: 0.3523 Acc: 83 %\n",
      "Epoch [1/100], Iter [440/3426] Loss: 0.2947 Acc: 83 %\n",
      "Epoch [1/100], Iter [450/3426] Loss: 0.3264 Acc: 83 %\n",
      "Epoch [1/100], Iter [460/3426] Loss: 0.3216 Acc: 83 %\n",
      "Epoch [1/100], Iter [470/3426] Loss: 0.3365 Acc: 83 %\n",
      "Epoch [1/100], Iter [480/3426] Loss: 0.3132 Acc: 83 %\n",
      "Epoch [1/100], Iter [490/3426] Loss: 0.3458 Acc: 83 %\n",
      "Epoch [1/100], Iter [500/3426] Loss: 0.3136 Acc: 84 %\n",
      "Epoch [1/100], Iter [510/3426] Loss: 0.3395 Acc: 84 %\n",
      "Epoch [1/100], Iter [520/3426] Loss: 0.2989 Acc: 84 %\n",
      "Epoch [1/100], Iter [530/3426] Loss: 0.3118 Acc: 84 %\n",
      "Epoch [1/100], Iter [540/3426] Loss: 0.3252 Acc: 84 %\n",
      "Epoch [1/100], Iter [550/3426] Loss: 0.3303 Acc: 84 %\n",
      "Epoch [1/100], Iter [560/3426] Loss: 0.2956 Acc: 84 %\n",
      "Epoch [1/100], Iter [570/3426] Loss: 0.3120 Acc: 84 %\n",
      "Epoch [1/100], Iter [580/3426] Loss: 0.3452 Acc: 84 %\n",
      "Epoch [1/100], Iter [590/3426] Loss: 0.3017 Acc: 84 %\n",
      "Epoch [1/100], Iter [600/3426] Loss: 0.2997 Acc: 84 %\n",
      "Epoch [1/100], Iter [610/3426] Loss: 0.2873 Acc: 84 %\n",
      "Epoch [1/100], Iter [620/3426] Loss: 0.3237 Acc: 84 %\n",
      "Epoch [1/100], Iter [630/3426] Loss: 0.3183 Acc: 84 %\n",
      "Epoch [1/100], Iter [640/3426] Loss: 0.2881 Acc: 84 %\n",
      "Epoch [1/100], Iter [650/3426] Loss: 0.3185 Acc: 84 %\n",
      "Epoch [1/100], Iter [660/3426] Loss: 0.3057 Acc: 84 %\n",
      "Epoch [1/100], Iter [670/3426] Loss: 0.3133 Acc: 84 %\n",
      "Epoch [1/100], Iter [680/3426] Loss: 0.3180 Acc: 84 %\n",
      "Epoch [1/100], Iter [690/3426] Loss: 0.3186 Acc: 84 %\n",
      "Epoch [1/100], Iter [700/3426] Loss: 0.2996 Acc: 84 %\n",
      "Epoch [1/100], Iter [710/3426] Loss: 0.3079 Acc: 84 %\n",
      "Epoch [1/100], Iter [720/3426] Loss: 0.2624 Acc: 84 %\n",
      "Epoch [1/100], Iter [730/3426] Loss: 0.3115 Acc: 84 %\n",
      "Epoch [1/100], Iter [740/3426] Loss: 0.3182 Acc: 84 %\n",
      "Epoch [1/100], Iter [750/3426] Loss: 0.3205 Acc: 84 %\n",
      "Epoch [1/100], Iter [760/3426] Loss: 0.2908 Acc: 84 %\n",
      "Epoch [1/100], Iter [770/3426] Loss: 0.3010 Acc: 84 %\n",
      "Epoch [1/100], Iter [780/3426] Loss: 0.2914 Acc: 84 %\n",
      "Epoch [1/100], Iter [790/3426] Loss: 0.2861 Acc: 84 %\n",
      "Epoch [1/100], Iter [800/3426] Loss: 0.2971 Acc: 84 %\n",
      "Epoch [1/100], Iter [810/3426] Loss: 0.3156 Acc: 84 %\n",
      "Epoch [1/100], Iter [820/3426] Loss: 0.2918 Acc: 84 %\n",
      "Epoch [1/100], Iter [830/3426] Loss: 0.2905 Acc: 84 %\n",
      "Epoch [1/100], Iter [840/3426] Loss: 0.2817 Acc: 84 %\n",
      "Epoch [1/100], Iter [850/3426] Loss: 0.2994 Acc: 84 %\n",
      "Epoch [1/100], Iter [860/3426] Loss: 0.2970 Acc: 84 %\n",
      "Epoch [1/100], Iter [870/3426] Loss: 0.2726 Acc: 85 %\n",
      "Epoch [1/100], Iter [880/3426] Loss: 0.2915 Acc: 85 %\n",
      "Epoch [1/100], Iter [890/3426] Loss: 0.2959 Acc: 85 %\n",
      "Epoch [1/100], Iter [900/3426] Loss: 0.2945 Acc: 85 %\n",
      "Epoch [1/100], Iter [910/3426] Loss: 0.2869 Acc: 85 %\n",
      "Epoch [1/100], Iter [920/3426] Loss: 0.2998 Acc: 85 %\n",
      "Epoch [1/100], Iter [930/3426] Loss: 0.2672 Acc: 85 %\n",
      "Epoch [1/100], Iter [940/3426] Loss: 0.2766 Acc: 85 %\n",
      "Epoch [1/100], Iter [950/3426] Loss: 0.3114 Acc: 85 %\n",
      "Epoch [1/100], Iter [960/3426] Loss: 0.2702 Acc: 85 %\n",
      "Epoch [1/100], Iter [970/3426] Loss: 0.2467 Acc: 85 %\n",
      "Epoch [1/100], Iter [980/3426] Loss: 0.2696 Acc: 85 %\n",
      "Epoch [1/100], Iter [990/3426] Loss: 0.2599 Acc: 85 %\n",
      "Epoch [1/100], Iter [1000/3426] Loss: 0.3062 Acc: 85 %\n",
      "Epoch [1/100], Iter [1010/3426] Loss: 0.2999 Acc: 85 %\n",
      "Epoch [1/100], Iter [1020/3426] Loss: 0.2878 Acc: 85 %\n",
      "Epoch [1/100], Iter [1030/3426] Loss: 0.2454 Acc: 85 %\n",
      "Epoch [1/100], Iter [1040/3426] Loss: 0.2607 Acc: 85 %\n",
      "Epoch [1/100], Iter [1050/3426] Loss: 0.2727 Acc: 85 %\n",
      "Epoch [1/100], Iter [1060/3426] Loss: 0.2544 Acc: 85 %\n",
      "Epoch [1/100], Iter [1070/3426] Loss: 0.2958 Acc: 85 %\n",
      "Epoch [1/100], Iter [1080/3426] Loss: 0.2979 Acc: 85 %\n",
      "Epoch [1/100], Iter [1090/3426] Loss: 0.3249 Acc: 85 %\n",
      "Epoch [1/100], Iter [1100/3426] Loss: 0.2654 Acc: 85 %\n",
      "Epoch [1/100], Iter [1110/3426] Loss: 0.3162 Acc: 85 %\n",
      "Epoch [1/100], Iter [1120/3426] Loss: 0.3108 Acc: 85 %\n",
      "Epoch [1/100], Iter [1130/3426] Loss: 0.2585 Acc: 85 %\n",
      "Epoch [1/100], Iter [1140/3426] Loss: 0.2841 Acc: 85 %\n",
      "Epoch [1/100], Iter [1150/3426] Loss: 0.2947 Acc: 85 %\n",
      "Epoch [1/100], Iter [1160/3426] Loss: 0.2819 Acc: 85 %\n",
      "Epoch [1/100], Iter [1170/3426] Loss: 0.2728 Acc: 85 %\n",
      "Epoch [1/100], Iter [1180/3426] Loss: 0.2805 Acc: 85 %\n",
      "Epoch [1/100], Iter [1190/3426] Loss: 0.3110 Acc: 85 %\n",
      "Epoch [1/100], Iter [1200/3426] Loss: 0.3001 Acc: 85 %\n",
      "Epoch [1/100], Iter [1210/3426] Loss: 0.3193 Acc: 85 %\n",
      "Epoch [1/100], Iter [1220/3426] Loss: 0.2638 Acc: 85 %\n",
      "Epoch [1/100], Iter [1230/3426] Loss: 0.2913 Acc: 85 %\n",
      "Epoch [1/100], Iter [1240/3426] Loss: 0.2374 Acc: 85 %\n",
      "Epoch [1/100], Iter [1250/3426] Loss: 0.2655 Acc: 85 %\n",
      "Epoch [1/100], Iter [1260/3426] Loss: 0.2843 Acc: 85 %\n",
      "Epoch [1/100], Iter [1270/3426] Loss: 0.2179 Acc: 85 %\n",
      "Epoch [1/100], Iter [1280/3426] Loss: 0.2824 Acc: 85 %\n",
      "Epoch [1/100], Iter [1290/3426] Loss: 0.2693 Acc: 85 %\n",
      "Epoch [1/100], Iter [1300/3426] Loss: 0.2447 Acc: 85 %\n",
      "Epoch [1/100], Iter [1310/3426] Loss: 0.2932 Acc: 85 %\n",
      "Epoch [1/100], Iter [1320/3426] Loss: 0.2492 Acc: 85 %\n",
      "Epoch [1/100], Iter [1330/3426] Loss: 0.2324 Acc: 85 %\n",
      "Epoch [1/100], Iter [1340/3426] Loss: 0.2394 Acc: 85 %\n",
      "Epoch [1/100], Iter [1350/3426] Loss: 0.2255 Acc: 85 %\n",
      "Epoch [1/100], Iter [1360/3426] Loss: 0.2393 Acc: 85 %\n",
      "Epoch [1/100], Iter [1370/3426] Loss: 0.3176 Acc: 85 %\n",
      "Epoch [1/100], Iter [1380/3426] Loss: 0.2694 Acc: 85 %\n",
      "Epoch [1/100], Iter [1390/3426] Loss: 0.2491 Acc: 85 %\n",
      "Epoch [1/100], Iter [1400/3426] Loss: 0.2412 Acc: 85 %\n",
      "Epoch [1/100], Iter [1410/3426] Loss: 0.2273 Acc: 86 %\n",
      "Epoch [1/100], Iter [1420/3426] Loss: 0.2288 Acc: 86 %\n",
      "Epoch [1/100], Iter [1430/3426] Loss: 0.2562 Acc: 86 %\n",
      "Epoch [1/100], Iter [1440/3426] Loss: 0.2592 Acc: 86 %\n",
      "Epoch [1/100], Iter [1450/3426] Loss: 0.2429 Acc: 86 %\n",
      "Epoch [1/100], Iter [1460/3426] Loss: 0.2736 Acc: 86 %\n",
      "Epoch [1/100], Iter [1470/3426] Loss: 0.2421 Acc: 86 %\n",
      "Epoch [1/100], Iter [1480/3426] Loss: 0.2476 Acc: 86 %\n",
      "Epoch [1/100], Iter [1490/3426] Loss: 0.2298 Acc: 86 %\n",
      "Epoch [1/100], Iter [1500/3426] Loss: 0.2528 Acc: 86 %\n",
      "Epoch [1/100], Iter [1510/3426] Loss: 0.2563 Acc: 86 %\n",
      "Epoch [1/100], Iter [1520/3426] Loss: 0.2679 Acc: 86 %\n",
      "Epoch [1/100], Iter [1530/3426] Loss: 0.2555 Acc: 86 %\n",
      "Epoch [1/100], Iter [1540/3426] Loss: 0.2355 Acc: 86 %\n",
      "Epoch [1/100], Iter [1550/3426] Loss: 0.2542 Acc: 86 %\n",
      "Epoch [1/100], Iter [1560/3426] Loss: 0.2700 Acc: 86 %\n",
      "Epoch [1/100], Iter [1570/3426] Loss: 0.2384 Acc: 86 %\n",
      "Epoch [1/100], Iter [1580/3426] Loss: 0.2959 Acc: 86 %\n",
      "Epoch [1/100], Iter [1590/3426] Loss: 0.2531 Acc: 86 %\n",
      "Epoch [1/100], Iter [1600/3426] Loss: 0.2700 Acc: 86 %\n",
      "Epoch [1/100], Iter [1610/3426] Loss: 0.2208 Acc: 86 %\n",
      "Epoch [1/100], Iter [1620/3426] Loss: 0.2569 Acc: 86 %\n",
      "Epoch [1/100], Iter [1630/3426] Loss: 0.2047 Acc: 86 %\n",
      "Epoch [1/100], Iter [1640/3426] Loss: 0.2394 Acc: 86 %\n",
      "Epoch [1/100], Iter [1650/3426] Loss: 0.2435 Acc: 86 %\n",
      "Epoch [1/100], Iter [1660/3426] Loss: 0.2641 Acc: 86 %\n",
      "Epoch [1/100], Iter [1670/3426] Loss: 0.2771 Acc: 86 %\n",
      "Epoch [1/100], Iter [1680/3426] Loss: 0.2368 Acc: 86 %\n",
      "Epoch [1/100], Iter [1690/3426] Loss: 0.1979 Acc: 86 %\n",
      "Epoch [1/100], Iter [1700/3426] Loss: 0.2508 Acc: 86 %\n",
      "Epoch [1/100], Iter [1710/3426] Loss: 0.2492 Acc: 86 %\n",
      "Epoch [1/100], Iter [1720/3426] Loss: 0.2569 Acc: 86 %\n",
      "Epoch [1/100], Iter [1730/3426] Loss: 0.2257 Acc: 86 %\n",
      "Epoch [1/100], Iter [1740/3426] Loss: 0.2538 Acc: 86 %\n",
      "Epoch [1/100], Iter [1750/3426] Loss: 0.2715 Acc: 86 %\n",
      "Epoch [1/100], Iter [1760/3426] Loss: 0.2161 Acc: 86 %\n",
      "Epoch [1/100], Iter [1770/3426] Loss: 0.2693 Acc: 86 %\n",
      "Epoch [1/100], Iter [1780/3426] Loss: 0.2034 Acc: 86 %\n",
      "Epoch [1/100], Iter [1790/3426] Loss: 0.2603 Acc: 86 %\n",
      "Epoch [1/100], Iter [1800/3426] Loss: 0.2252 Acc: 86 %\n",
      "Epoch [1/100], Iter [1810/3426] Loss: 0.2522 Acc: 86 %\n",
      "Epoch [1/100], Iter [1820/3426] Loss: 0.2396 Acc: 86 %\n",
      "Epoch [1/100], Iter [1830/3426] Loss: 0.2448 Acc: 86 %\n",
      "Epoch [1/100], Iter [1840/3426] Loss: 0.2089 Acc: 86 %\n",
      "Epoch [1/100], Iter [1850/3426] Loss: 0.2269 Acc: 86 %\n",
      "Epoch [1/100], Iter [1860/3426] Loss: 0.2338 Acc: 86 %\n",
      "Epoch [1/100], Iter [1870/3426] Loss: 0.2535 Acc: 86 %\n",
      "Epoch [1/100], Iter [1880/3426] Loss: 0.2351 Acc: 86 %\n",
      "Epoch [1/100], Iter [1890/3426] Loss: 0.2171 Acc: 86 %\n",
      "Epoch [1/100], Iter [1900/3426] Loss: 0.2239 Acc: 86 %\n",
      "Epoch [1/100], Iter [1910/3426] Loss: 0.2410 Acc: 86 %\n",
      "Epoch [1/100], Iter [1920/3426] Loss: 0.2190 Acc: 86 %\n",
      "Epoch [1/100], Iter [1930/3426] Loss: 0.3025 Acc: 86 %\n",
      "Epoch [1/100], Iter [1940/3426] Loss: 0.2943 Acc: 86 %\n",
      "Epoch [1/100], Iter [1950/3426] Loss: 0.2419 Acc: 86 %\n",
      "Epoch [1/100], Iter [1960/3426] Loss: 0.2543 Acc: 86 %\n",
      "Epoch [1/100], Iter [1970/3426] Loss: 0.2581 Acc: 86 %\n",
      "Epoch [1/100], Iter [1980/3426] Loss: 0.2474 Acc: 86 %\n",
      "Epoch [1/100], Iter [1990/3426] Loss: 0.2584 Acc: 87 %\n",
      "Epoch [1/100], Iter [2000/3426] Loss: 0.2457 Acc: 87 %\n",
      "Epoch [1/100], Iter [2010/3426] Loss: 0.2227 Acc: 87 %\n",
      "Epoch [1/100], Iter [2020/3426] Loss: 0.2247 Acc: 87 %\n",
      "Epoch [1/100], Iter [2030/3426] Loss: 0.2226 Acc: 87 %\n",
      "Epoch [1/100], Iter [2040/3426] Loss: 0.2334 Acc: 87 %\n",
      "Epoch [1/100], Iter [2050/3426] Loss: 0.2616 Acc: 87 %\n",
      "Epoch [1/100], Iter [2060/3426] Loss: 0.2616 Acc: 87 %\n",
      "Epoch [1/100], Iter [2070/3426] Loss: 0.1923 Acc: 87 %\n",
      "Epoch [1/100], Iter [2080/3426] Loss: 0.2133 Acc: 87 %\n",
      "Epoch [1/100], Iter [2090/3426] Loss: 0.2135 Acc: 87 %\n",
      "Epoch [1/100], Iter [2100/3426] Loss: 0.2110 Acc: 87 %\n",
      "Epoch [1/100], Iter [2110/3426] Loss: 0.2056 Acc: 87 %\n",
      "Epoch [1/100], Iter [2120/3426] Loss: 0.2232 Acc: 87 %\n",
      "Epoch [1/100], Iter [2130/3426] Loss: 0.2247 Acc: 87 %\n",
      "Epoch [1/100], Iter [2140/3426] Loss: 0.2764 Acc: 87 %\n",
      "Epoch [1/100], Iter [2150/3426] Loss: 0.2487 Acc: 87 %\n",
      "Epoch [1/100], Iter [2160/3426] Loss: 0.2425 Acc: 87 %\n",
      "Epoch [1/100], Iter [2170/3426] Loss: 0.2422 Acc: 87 %\n",
      "Epoch [1/100], Iter [2180/3426] Loss: 0.2602 Acc: 87 %\n",
      "Epoch [1/100], Iter [2190/3426] Loss: 0.2506 Acc: 87 %\n",
      "Epoch [1/100], Iter [2200/3426] Loss: 0.2508 Acc: 87 %\n",
      "Epoch [1/100], Iter [2210/3426] Loss: 0.2409 Acc: 87 %\n",
      "Epoch [1/100], Iter [2220/3426] Loss: 0.2387 Acc: 87 %\n",
      "Epoch [1/100], Iter [2230/3426] Loss: 0.1945 Acc: 87 %\n",
      "Epoch [1/100], Iter [2240/3426] Loss: 0.2138 Acc: 87 %\n",
      "Epoch [1/100], Iter [2250/3426] Loss: 0.2175 Acc: 87 %\n",
      "Epoch [1/100], Iter [2260/3426] Loss: 0.2649 Acc: 87 %\n",
      "Epoch [1/100], Iter [2270/3426] Loss: 0.2144 Acc: 87 %\n",
      "Epoch [1/100], Iter [2280/3426] Loss: 0.2501 Acc: 87 %\n",
      "Epoch [1/100], Iter [2290/3426] Loss: 0.2191 Acc: 87 %\n",
      "Epoch [1/100], Iter [2300/3426] Loss: 0.2289 Acc: 87 %\n",
      "Epoch [1/100], Iter [2310/3426] Loss: 0.2572 Acc: 87 %\n",
      "Epoch [1/100], Iter [2320/3426] Loss: 0.2505 Acc: 87 %\n",
      "Epoch [1/100], Iter [2330/3426] Loss: 0.2385 Acc: 87 %\n",
      "Epoch [1/100], Iter [2340/3426] Loss: 0.2647 Acc: 87 %\n",
      "Epoch [1/100], Iter [2350/3426] Loss: 0.2427 Acc: 87 %\n",
      "Epoch [1/100], Iter [2360/3426] Loss: 0.2064 Acc: 87 %\n",
      "Epoch [1/100], Iter [2370/3426] Loss: 0.2827 Acc: 87 %\n",
      "Epoch [1/100], Iter [2380/3426] Loss: 0.2324 Acc: 87 %\n",
      "Epoch [1/100], Iter [2390/3426] Loss: 0.1942 Acc: 87 %\n",
      "Epoch [1/100], Iter [2400/3426] Loss: 0.2515 Acc: 87 %\n",
      "Epoch [1/100], Iter [2410/3426] Loss: 0.2221 Acc: 87 %\n",
      "Epoch [1/100], Iter [2420/3426] Loss: 0.2490 Acc: 87 %\n",
      "Epoch [1/100], Iter [2430/3426] Loss: 0.2415 Acc: 87 %\n",
      "Epoch [1/100], Iter [2440/3426] Loss: 0.2211 Acc: 87 %\n",
      "Epoch [1/100], Iter [2450/3426] Loss: 0.2588 Acc: 87 %\n",
      "Epoch [1/100], Iter [2460/3426] Loss: 0.2088 Acc: 87 %\n",
      "Epoch [1/100], Iter [2470/3426] Loss: 0.2510 Acc: 87 %\n",
      "Epoch [1/100], Iter [2480/3426] Loss: 0.1952 Acc: 87 %\n",
      "Epoch [1/100], Iter [2490/3426] Loss: 0.2131 Acc: 87 %\n",
      "Epoch [1/100], Iter [2500/3426] Loss: 0.2281 Acc: 87 %\n",
      "Epoch [1/100], Iter [2510/3426] Loss: 0.2353 Acc: 87 %\n",
      "Epoch [1/100], Iter [2520/3426] Loss: 0.2028 Acc: 87 %\n",
      "Epoch [1/100], Iter [2530/3426] Loss: 0.2087 Acc: 87 %\n",
      "Epoch [1/100], Iter [2540/3426] Loss: 0.2483 Acc: 87 %\n",
      "Epoch [1/100], Iter [2550/3426] Loss: 0.2196 Acc: 87 %\n",
      "Epoch [1/100], Iter [2560/3426] Loss: 0.2111 Acc: 87 %\n",
      "Epoch [1/100], Iter [2570/3426] Loss: 0.2107 Acc: 87 %\n",
      "Epoch [1/100], Iter [2580/3426] Loss: 0.2235 Acc: 87 %\n",
      "Epoch [1/100], Iter [2590/3426] Loss: 0.1945 Acc: 87 %\n",
      "Epoch [1/100], Iter [2600/3426] Loss: 0.2725 Acc: 87 %\n",
      "Epoch [1/100], Iter [2610/3426] Loss: 0.2297 Acc: 87 %\n",
      "Epoch [1/100], Iter [2620/3426] Loss: 0.2268 Acc: 87 %\n",
      "Epoch [1/100], Iter [2630/3426] Loss: 0.2605 Acc: 87 %\n",
      "Epoch [1/100], Iter [2640/3426] Loss: 0.2346 Acc: 87 %\n",
      "Epoch [1/100], Iter [2650/3426] Loss: 0.2638 Acc: 87 %\n",
      "Epoch [1/100], Iter [2660/3426] Loss: 0.2226 Acc: 87 %\n",
      "Epoch [1/100], Iter [2670/3426] Loss: 0.2513 Acc: 87 %\n",
      "Epoch [1/100], Iter [2680/3426] Loss: 0.2515 Acc: 87 %\n",
      "Epoch [1/100], Iter [2690/3426] Loss: 0.2877 Acc: 87 %\n",
      "Epoch [1/100], Iter [2700/3426] Loss: 0.2824 Acc: 87 %\n",
      "Epoch [1/100], Iter [2710/3426] Loss: 0.1965 Acc: 87 %\n",
      "Epoch [1/100], Iter [2720/3426] Loss: 0.2233 Acc: 87 %\n",
      "Epoch [1/100], Iter [2730/3426] Loss: 0.2586 Acc: 87 %\n",
      "Epoch [1/100], Iter [2740/3426] Loss: 0.2441 Acc: 87 %\n",
      "Epoch [1/100], Iter [2750/3426] Loss: 0.2031 Acc: 87 %\n",
      "Epoch [1/100], Iter [2760/3426] Loss: 0.2401 Acc: 87 %\n",
      "Epoch [1/100], Iter [2770/3426] Loss: 0.2196 Acc: 87 %\n",
      "Epoch [1/100], Iter [2780/3426] Loss: 0.2067 Acc: 87 %\n",
      "Epoch [1/100], Iter [2790/3426] Loss: 0.2540 Acc: 87 %\n",
      "Epoch [1/100], Iter [2800/3426] Loss: 0.2258 Acc: 87 %\n",
      "Epoch [1/100], Iter [2810/3426] Loss: 0.2362 Acc: 87 %\n",
      "Epoch [1/100], Iter [2820/3426] Loss: 0.2107 Acc: 87 %\n",
      "Epoch [1/100], Iter [2830/3426] Loss: 0.2141 Acc: 87 %\n",
      "Epoch [1/100], Iter [2840/3426] Loss: 0.2121 Acc: 87 %\n",
      "Epoch [1/100], Iter [2850/3426] Loss: 0.2165 Acc: 87 %\n",
      "Epoch [1/100], Iter [2860/3426] Loss: 0.2398 Acc: 87 %\n",
      "Epoch [1/100], Iter [2870/3426] Loss: 0.2080 Acc: 87 %\n",
      "Epoch [1/100], Iter [2880/3426] Loss: 0.2241 Acc: 87 %\n",
      "Epoch [1/100], Iter [2890/3426] Loss: 0.2315 Acc: 87 %\n",
      "Epoch [1/100], Iter [2900/3426] Loss: 0.2097 Acc: 87 %\n",
      "Epoch [1/100], Iter [2910/3426] Loss: 0.1891 Acc: 88 %\n",
      "Epoch [1/100], Iter [2920/3426] Loss: 0.2048 Acc: 88 %\n",
      "Epoch [1/100], Iter [2930/3426] Loss: 0.2010 Acc: 88 %\n",
      "Epoch [1/100], Iter [2940/3426] Loss: 0.2086 Acc: 88 %\n",
      "Epoch [1/100], Iter [2950/3426] Loss: 0.2081 Acc: 88 %\n",
      "Epoch [1/100], Iter [2960/3426] Loss: 0.2063 Acc: 88 %\n",
      "Epoch [1/100], Iter [2970/3426] Loss: 0.2333 Acc: 88 %\n",
      "Epoch [1/100], Iter [2980/3426] Loss: 0.2116 Acc: 88 %\n",
      "Epoch [1/100], Iter [2990/3426] Loss: 0.2230 Acc: 88 %\n",
      "Epoch [1/100], Iter [3000/3426] Loss: 0.2516 Acc: 88 %\n",
      "Epoch [1/100], Iter [3010/3426] Loss: 0.2163 Acc: 88 %\n",
      "Epoch [1/100], Iter [3020/3426] Loss: 0.2014 Acc: 88 %\n",
      "Epoch [1/100], Iter [3030/3426] Loss: 0.2088 Acc: 88 %\n",
      "Epoch [1/100], Iter [3040/3426] Loss: 0.1807 Acc: 88 %\n",
      "Epoch [1/100], Iter [3050/3426] Loss: 0.2140 Acc: 88 %\n",
      "Epoch [1/100], Iter [3060/3426] Loss: 0.2073 Acc: 88 %\n",
      "Epoch [1/100], Iter [3070/3426] Loss: 0.2154 Acc: 88 %\n",
      "Epoch [1/100], Iter [3080/3426] Loss: 0.2113 Acc: 88 %\n",
      "Epoch [1/100], Iter [3090/3426] Loss: 0.2152 Acc: 88 %\n",
      "Epoch [1/100], Iter [3100/3426] Loss: 0.2253 Acc: 88 %\n",
      "Epoch [1/100], Iter [3110/3426] Loss: 0.2365 Acc: 88 %\n",
      "Epoch [1/100], Iter [3120/3426] Loss: 0.2229 Acc: 88 %\n",
      "Epoch [1/100], Iter [3130/3426] Loss: 0.2193 Acc: 88 %\n",
      "Epoch [1/100], Iter [3140/3426] Loss: 0.1812 Acc: 88 %\n",
      "Epoch [1/100], Iter [3150/3426] Loss: 0.2241 Acc: 88 %\n",
      "Epoch [1/100], Iter [3160/3426] Loss: 0.2119 Acc: 88 %\n",
      "Epoch [1/100], Iter [3170/3426] Loss: 0.2228 Acc: 88 %\n",
      "Epoch [1/100], Iter [3180/3426] Loss: 0.1980 Acc: 88 %\n",
      "Epoch [1/100], Iter [3190/3426] Loss: 0.2039 Acc: 88 %\n",
      "Epoch [1/100], Iter [3200/3426] Loss: 0.2423 Acc: 88 %\n",
      "Epoch [1/100], Iter [3210/3426] Loss: 0.2553 Acc: 88 %\n",
      "Epoch [1/100], Iter [3220/3426] Loss: 0.2069 Acc: 88 %\n",
      "Epoch [1/100], Iter [3230/3426] Loss: 0.2330 Acc: 88 %\n",
      "Epoch [1/100], Iter [3240/3426] Loss: 0.2173 Acc: 88 %\n",
      "Epoch [1/100], Iter [3250/3426] Loss: 0.2742 Acc: 88 %\n",
      "Epoch [1/100], Iter [3260/3426] Loss: 0.1887 Acc: 88 %\n",
      "Epoch [1/100], Iter [3270/3426] Loss: 0.2168 Acc: 88 %\n",
      "Epoch [1/100], Iter [3280/3426] Loss: 0.2453 Acc: 88 %\n",
      "Epoch [1/100], Iter [3290/3426] Loss: 0.2020 Acc: 88 %\n",
      "Epoch [1/100], Iter [3300/3426] Loss: 0.2693 Acc: 88 %\n",
      "Epoch [1/100], Iter [3310/3426] Loss: 0.2160 Acc: 88 %\n",
      "Epoch [1/100], Iter [3320/3426] Loss: 0.2260 Acc: 88 %\n",
      "Epoch [1/100], Iter [3330/3426] Loss: 0.2520 Acc: 88 %\n",
      "Epoch [1/100], Iter [3340/3426] Loss: 0.2144 Acc: 88 %\n",
      "Epoch [1/100], Iter [3350/3426] Loss: 0.3089 Acc: 88 %\n",
      "Epoch [1/100], Iter [3360/3426] Loss: 0.2713 Acc: 88 %\n",
      "Epoch [1/100], Iter [3370/3426] Loss: 0.2365 Acc: 88 %\n",
      "Epoch [1/100], Iter [3380/3426] Loss: 0.2486 Acc: 88 %\n",
      "Epoch [1/100], Iter [3390/3426] Loss: 0.3173 Acc: 88 %\n",
      "Epoch [1/100], Iter [3400/3426] Loss: 0.2447 Acc: 88 %\n",
      "Epoch [1/100], Iter [3410/3426] Loss: 0.2589 Acc: 88 %\n",
      "Epoch [1/100], Iter [3420/3426] Loss: 0.2879 Acc: 88 %\n",
      "Accuracy of the model on the neg seq: 99 %\n",
      "Accuracy of the model on the pos seq: 1 %\n",
      "Validation loss decreased (inf --> 0.083281).  Saving model ...\n",
      "Epoch [2/100], Iter [10/3426] Loss: 0.2549 Acc: 88 %\n",
      "Epoch [2/100], Iter [20/3426] Loss: 0.2571 Acc: 89 %\n",
      "Epoch [2/100], Iter [30/3426] Loss: 0.3064 Acc: 89 %\n",
      "Epoch [2/100], Iter [40/3426] Loss: 0.2425 Acc: 89 %\n",
      "Epoch [2/100], Iter [50/3426] Loss: 0.2172 Acc: 90 %\n",
      "Epoch [2/100], Iter [60/3426] Loss: 0.2427 Acc: 89 %\n",
      "Epoch [2/100], Iter [70/3426] Loss: 0.2266 Acc: 89 %\n",
      "Epoch [2/100], Iter [80/3426] Loss: 0.1691 Acc: 90 %\n",
      "Epoch [2/100], Iter [90/3426] Loss: 0.1767 Acc: 90 %\n",
      "Epoch [2/100], Iter [100/3426] Loss: 0.1979 Acc: 90 %\n",
      "Epoch [2/100], Iter [110/3426] Loss: 0.2169 Acc: 90 %\n",
      "Epoch [2/100], Iter [120/3426] Loss: 0.1967 Acc: 90 %\n",
      "Epoch [2/100], Iter [130/3426] Loss: 0.1984 Acc: 90 %\n",
      "Epoch [2/100], Iter [140/3426] Loss: 0.2340 Acc: 90 %\n",
      "Epoch [2/100], Iter [150/3426] Loss: 0.1779 Acc: 90 %\n",
      "Epoch [2/100], Iter [160/3426] Loss: 0.2351 Acc: 90 %\n",
      "Epoch [2/100], Iter [170/3426] Loss: 0.2324 Acc: 90 %\n",
      "Epoch [2/100], Iter [180/3426] Loss: 0.2613 Acc: 90 %\n",
      "Epoch [2/100], Iter [190/3426] Loss: 0.2390 Acc: 90 %\n",
      "Epoch [2/100], Iter [200/3426] Loss: 0.2128 Acc: 90 %\n",
      "Epoch [2/100], Iter [210/3426] Loss: 0.2413 Acc: 90 %\n",
      "Epoch [2/100], Iter [220/3426] Loss: 0.2392 Acc: 90 %\n",
      "Epoch [2/100], Iter [230/3426] Loss: 0.2093 Acc: 90 %\n",
      "Epoch [2/100], Iter [240/3426] Loss: 0.2522 Acc: 90 %\n",
      "Epoch [2/100], Iter [250/3426] Loss: 0.2029 Acc: 90 %\n",
      "Epoch [2/100], Iter [260/3426] Loss: 0.2344 Acc: 90 %\n",
      "Epoch [2/100], Iter [270/3426] Loss: 0.2123 Acc: 90 %\n",
      "Epoch [2/100], Iter [280/3426] Loss: 0.2281 Acc: 90 %\n",
      "Epoch [2/100], Iter [290/3426] Loss: 0.3350 Acc: 90 %\n",
      "Epoch [2/100], Iter [300/3426] Loss: 0.1944 Acc: 90 %\n",
      "Epoch [2/100], Iter [310/3426] Loss: 0.2242 Acc: 90 %\n",
      "Epoch [2/100], Iter [320/3426] Loss: 0.2497 Acc: 90 %\n",
      "Epoch [2/100], Iter [330/3426] Loss: 0.1995 Acc: 90 %\n",
      "Epoch [2/100], Iter [340/3426] Loss: 0.2159 Acc: 90 %\n",
      "Epoch [2/100], Iter [350/3426] Loss: 0.2134 Acc: 90 %\n",
      "Epoch [2/100], Iter [360/3426] Loss: 0.2433 Acc: 90 %\n",
      "Epoch [2/100], Iter [370/3426] Loss: 0.2500 Acc: 90 %\n",
      "Epoch [2/100], Iter [380/3426] Loss: 0.2279 Acc: 90 %\n",
      "Epoch [2/100], Iter [390/3426] Loss: 0.2158 Acc: 90 %\n",
      "Epoch [2/100], Iter [400/3426] Loss: 0.2039 Acc: 90 %\n",
      "Epoch [2/100], Iter [410/3426] Loss: 0.2525 Acc: 90 %\n",
      "Epoch [2/100], Iter [420/3426] Loss: 0.2076 Acc: 90 %\n",
      "Epoch [2/100], Iter [430/3426] Loss: 0.2304 Acc: 90 %\n",
      "Epoch [2/100], Iter [440/3426] Loss: 0.2211 Acc: 90 %\n",
      "Epoch [2/100], Iter [450/3426] Loss: 0.2294 Acc: 90 %\n",
      "Epoch [2/100], Iter [460/3426] Loss: 0.2145 Acc: 90 %\n",
      "Epoch [2/100], Iter [470/3426] Loss: 0.2016 Acc: 90 %\n",
      "Epoch [2/100], Iter [480/3426] Loss: 0.1998 Acc: 90 %\n",
      "Epoch [2/100], Iter [490/3426] Loss: 0.2214 Acc: 90 %\n",
      "Epoch [2/100], Iter [500/3426] Loss: 0.4218 Acc: 90 %\n",
      "Epoch [2/100], Iter [510/3426] Loss: 0.2278 Acc: 90 %\n",
      "Epoch [2/100], Iter [520/3426] Loss: 0.2329 Acc: 90 %\n",
      "Epoch [2/100], Iter [530/3426] Loss: 0.2005 Acc: 90 %\n",
      "Epoch [2/100], Iter [540/3426] Loss: 0.2151 Acc: 90 %\n",
      "Epoch [2/100], Iter [550/3426] Loss: 0.1811 Acc: 90 %\n",
      "Epoch [2/100], Iter [560/3426] Loss: 0.2385 Acc: 90 %\n",
      "Epoch [2/100], Iter [570/3426] Loss: 0.2317 Acc: 90 %\n",
      "Epoch [2/100], Iter [580/3426] Loss: 0.2692 Acc: 90 %\n",
      "Epoch [2/100], Iter [590/3426] Loss: 0.2454 Acc: 90 %\n",
      "Epoch [2/100], Iter [600/3426] Loss: 0.2125 Acc: 90 %\n",
      "Epoch [2/100], Iter [610/3426] Loss: 0.2475 Acc: 90 %\n",
      "Epoch [2/100], Iter [620/3426] Loss: 0.2191 Acc: 90 %\n",
      "Epoch [2/100], Iter [630/3426] Loss: 0.2056 Acc: 90 %\n",
      "Epoch [2/100], Iter [640/3426] Loss: 0.2631 Acc: 90 %\n",
      "Epoch [2/100], Iter [650/3426] Loss: 0.2030 Acc: 90 %\n",
      "Epoch [2/100], Iter [660/3426] Loss: 0.1816 Acc: 90 %\n",
      "Epoch [2/100], Iter [670/3426] Loss: 0.2411 Acc: 90 %\n",
      "Epoch [2/100], Iter [680/3426] Loss: 0.2220 Acc: 90 %\n",
      "Epoch [2/100], Iter [690/3426] Loss: 0.2288 Acc: 90 %\n",
      "Epoch [2/100], Iter [700/3426] Loss: 0.2084 Acc: 90 %\n",
      "Epoch [2/100], Iter [710/3426] Loss: 0.2250 Acc: 90 %\n",
      "Epoch [2/100], Iter [720/3426] Loss: 0.1911 Acc: 90 %\n",
      "Epoch [2/100], Iter [730/3426] Loss: 0.2021 Acc: 90 %\n",
      "Epoch [2/100], Iter [740/3426] Loss: 0.2508 Acc: 90 %\n",
      "Epoch [2/100], Iter [750/3426] Loss: 0.2193 Acc: 90 %\n",
      "Epoch [2/100], Iter [760/3426] Loss: 0.2185 Acc: 90 %\n",
      "Epoch [2/100], Iter [770/3426] Loss: 0.2735 Acc: 90 %\n",
      "Epoch [2/100], Iter [780/3426] Loss: 0.2190 Acc: 90 %\n",
      "Epoch [2/100], Iter [790/3426] Loss: 0.2331 Acc: 90 %\n",
      "Epoch [2/100], Iter [800/3426] Loss: 0.2165 Acc: 90 %\n",
      "Epoch [2/100], Iter [810/3426] Loss: 0.2177 Acc: 90 %\n",
      "Epoch [2/100], Iter [820/3426] Loss: 0.2103 Acc: 90 %\n",
      "Epoch [2/100], Iter [830/3426] Loss: 0.2518 Acc: 90 %\n",
      "Epoch [2/100], Iter [840/3426] Loss: 0.2222 Acc: 90 %\n",
      "Epoch [2/100], Iter [850/3426] Loss: 0.2101 Acc: 90 %\n",
      "Epoch [2/100], Iter [860/3426] Loss: 0.2460 Acc: 90 %\n",
      "Epoch [2/100], Iter [870/3426] Loss: 0.2310 Acc: 90 %\n",
      "Epoch [2/100], Iter [880/3426] Loss: 0.2049 Acc: 90 %\n",
      "Epoch [2/100], Iter [890/3426] Loss: 0.2192 Acc: 90 %\n",
      "Epoch [2/100], Iter [900/3426] Loss: 0.2576 Acc: 90 %\n",
      "Epoch [2/100], Iter [910/3426] Loss: 0.1936 Acc: 90 %\n",
      "Epoch [2/100], Iter [920/3426] Loss: 0.1942 Acc: 90 %\n",
      "Epoch [2/100], Iter [930/3426] Loss: 0.2045 Acc: 90 %\n",
      "Epoch [2/100], Iter [940/3426] Loss: 0.1916 Acc: 90 %\n",
      "Epoch [2/100], Iter [950/3426] Loss: 0.2147 Acc: 90 %\n",
      "Epoch [2/100], Iter [960/3426] Loss: 0.1977 Acc: 90 %\n",
      "Epoch [2/100], Iter [970/3426] Loss: 0.1983 Acc: 90 %\n",
      "Epoch [2/100], Iter [980/3426] Loss: 0.1846 Acc: 90 %\n",
      "Epoch [2/100], Iter [990/3426] Loss: 0.2153 Acc: 90 %\n",
      "Epoch [2/100], Iter [1000/3426] Loss: 0.2088 Acc: 90 %\n",
      "Epoch [2/100], Iter [1010/3426] Loss: 0.2177 Acc: 90 %\n",
      "Epoch [2/100], Iter [1020/3426] Loss: 0.2186 Acc: 90 %\n",
      "Epoch [2/100], Iter [1030/3426] Loss: 0.1933 Acc: 90 %\n",
      "Epoch [2/100], Iter [1040/3426] Loss: 0.2363 Acc: 90 %\n",
      "Epoch [2/100], Iter [1050/3426] Loss: 0.2356 Acc: 90 %\n",
      "Epoch [2/100], Iter [1060/3426] Loss: 0.1816 Acc: 90 %\n",
      "Epoch [2/100], Iter [1070/3426] Loss: 0.1833 Acc: 90 %\n",
      "Epoch [2/100], Iter [1080/3426] Loss: 0.1983 Acc: 90 %\n",
      "Epoch [2/100], Iter [1090/3426] Loss: 0.2373 Acc: 90 %\n",
      "Epoch [2/100], Iter [1100/3426] Loss: 0.2191 Acc: 90 %\n",
      "Epoch [2/100], Iter [1110/3426] Loss: 0.2109 Acc: 90 %\n",
      "Epoch [2/100], Iter [1120/3426] Loss: 0.2058 Acc: 90 %\n",
      "Epoch [2/100], Iter [1130/3426] Loss: 0.1795 Acc: 90 %\n",
      "Epoch [2/100], Iter [1140/3426] Loss: 0.2249 Acc: 90 %\n",
      "Epoch [2/100], Iter [1150/3426] Loss: 0.2236 Acc: 90 %\n",
      "Epoch [2/100], Iter [1160/3426] Loss: 0.2159 Acc: 90 %\n",
      "Epoch [2/100], Iter [1170/3426] Loss: 0.1730 Acc: 90 %\n",
      "Epoch [2/100], Iter [1180/3426] Loss: 0.2019 Acc: 90 %\n",
      "Epoch [2/100], Iter [1190/3426] Loss: 0.1926 Acc: 90 %\n",
      "Epoch [2/100], Iter [1200/3426] Loss: 0.2447 Acc: 90 %\n",
      "Epoch [2/100], Iter [1210/3426] Loss: 0.2065 Acc: 90 %\n",
      "Epoch [2/100], Iter [1220/3426] Loss: 0.2252 Acc: 90 %\n",
      "Epoch [2/100], Iter [1230/3426] Loss: 0.2277 Acc: 90 %\n",
      "Epoch [2/100], Iter [1240/3426] Loss: 0.2184 Acc: 90 %\n",
      "Epoch [2/100], Iter [1250/3426] Loss: 0.2183 Acc: 90 %\n",
      "Epoch [2/100], Iter [1260/3426] Loss: 0.1656 Acc: 90 %\n",
      "Epoch [2/100], Iter [1270/3426] Loss: 0.2117 Acc: 90 %\n",
      "Epoch [2/100], Iter [1280/3426] Loss: 0.2206 Acc: 90 %\n",
      "Epoch [2/100], Iter [1290/3426] Loss: 0.2446 Acc: 90 %\n",
      "Epoch [2/100], Iter [1300/3426] Loss: 0.1972 Acc: 90 %\n",
      "Epoch [2/100], Iter [1310/3426] Loss: 0.2017 Acc: 90 %\n",
      "Epoch [2/100], Iter [1320/3426] Loss: 0.2071 Acc: 90 %\n",
      "Epoch [2/100], Iter [1330/3426] Loss: 0.2585 Acc: 90 %\n",
      "Epoch [2/100], Iter [1340/3426] Loss: 0.1963 Acc: 90 %\n",
      "Epoch [2/100], Iter [1350/3426] Loss: 0.2160 Acc: 90 %\n",
      "Epoch [2/100], Iter [1360/3426] Loss: 0.2315 Acc: 90 %\n",
      "Epoch [2/100], Iter [1370/3426] Loss: 0.2074 Acc: 90 %\n",
      "Epoch [2/100], Iter [1380/3426] Loss: 0.2261 Acc: 90 %\n",
      "Epoch [2/100], Iter [1390/3426] Loss: 0.2242 Acc: 90 %\n",
      "Epoch [2/100], Iter [1400/3426] Loss: 0.2226 Acc: 90 %\n",
      "Epoch [2/100], Iter [1410/3426] Loss: 0.2377 Acc: 90 %\n",
      "Epoch [2/100], Iter [1420/3426] Loss: 0.2197 Acc: 90 %\n",
      "Epoch [2/100], Iter [1430/3426] Loss: 0.2098 Acc: 90 %\n",
      "Epoch [2/100], Iter [1440/3426] Loss: 0.1885 Acc: 90 %\n",
      "Epoch [2/100], Iter [1450/3426] Loss: 0.4357 Acc: 90 %\n",
      "Epoch [2/100], Iter [1460/3426] Loss: 0.2232 Acc: 90 %\n",
      "Epoch [2/100], Iter [1470/3426] Loss: 0.2166 Acc: 90 %\n",
      "Epoch [2/100], Iter [1480/3426] Loss: 0.2156 Acc: 90 %\n",
      "Epoch [2/100], Iter [1490/3426] Loss: 0.2121 Acc: 90 %\n",
      "Epoch [2/100], Iter [1500/3426] Loss: 0.2042 Acc: 90 %\n",
      "Epoch [2/100], Iter [1510/3426] Loss: 0.2026 Acc: 90 %\n",
      "Epoch [2/100], Iter [1520/3426] Loss: 0.2217 Acc: 90 %\n",
      "Epoch [2/100], Iter [1530/3426] Loss: 0.2116 Acc: 90 %\n",
      "Epoch [2/100], Iter [1540/3426] Loss: 0.2153 Acc: 90 %\n",
      "Epoch [2/100], Iter [1550/3426] Loss: 0.2311 Acc: 90 %\n",
      "Epoch [2/100], Iter [1560/3426] Loss: 0.2068 Acc: 90 %\n",
      "Epoch [2/100], Iter [1570/3426] Loss: 0.2073 Acc: 90 %\n",
      "Epoch [2/100], Iter [1580/3426] Loss: 0.2461 Acc: 90 %\n",
      "Epoch [2/100], Iter [1590/3426] Loss: 0.2392 Acc: 90 %\n",
      "Epoch [2/100], Iter [1600/3426] Loss: 0.1999 Acc: 90 %\n",
      "Epoch [2/100], Iter [1610/3426] Loss: 0.2069 Acc: 90 %\n",
      "Epoch [2/100], Iter [1620/3426] Loss: 0.1833 Acc: 90 %\n",
      "Epoch [2/100], Iter [1630/3426] Loss: 0.2222 Acc: 90 %\n",
      "Epoch [2/100], Iter [1640/3426] Loss: 0.2111 Acc: 90 %\n",
      "Epoch [2/100], Iter [1650/3426] Loss: 0.2375 Acc: 90 %\n",
      "Epoch [2/100], Iter [1660/3426] Loss: 0.2627 Acc: 90 %\n",
      "Epoch [2/100], Iter [1670/3426] Loss: 0.2374 Acc: 90 %\n",
      "Epoch [2/100], Iter [1680/3426] Loss: 0.2033 Acc: 90 %\n",
      "Epoch [2/100], Iter [1690/3426] Loss: 0.2603 Acc: 90 %\n",
      "Epoch [2/100], Iter [1700/3426] Loss: 0.2122 Acc: 90 %\n",
      "Epoch [2/100], Iter [1710/3426] Loss: 0.2124 Acc: 90 %\n",
      "Epoch [2/100], Iter [1720/3426] Loss: 0.2181 Acc: 90 %\n",
      "Epoch [2/100], Iter [1730/3426] Loss: 0.2105 Acc: 90 %\n",
      "Epoch [2/100], Iter [1740/3426] Loss: 0.1891 Acc: 90 %\n",
      "Epoch [2/100], Iter [1750/3426] Loss: 0.2210 Acc: 90 %\n",
      "Epoch [2/100], Iter [1760/3426] Loss: 0.1931 Acc: 90 %\n",
      "Epoch [2/100], Iter [1770/3426] Loss: 0.2097 Acc: 90 %\n",
      "Epoch [2/100], Iter [1780/3426] Loss: 0.2167 Acc: 90 %\n",
      "Epoch [2/100], Iter [1790/3426] Loss: 0.2293 Acc: 90 %\n",
      "Epoch [2/100], Iter [1800/3426] Loss: 0.1818 Acc: 90 %\n",
      "Epoch [2/100], Iter [1810/3426] Loss: 0.1765 Acc: 90 %\n",
      "Epoch [2/100], Iter [1820/3426] Loss: 0.2002 Acc: 90 %\n",
      "Epoch [2/100], Iter [1830/3426] Loss: 0.2103 Acc: 90 %\n",
      "Epoch [2/100], Iter [1840/3426] Loss: 0.2325 Acc: 90 %\n",
      "Epoch [2/100], Iter [1850/3426] Loss: 0.1982 Acc: 90 %\n",
      "Epoch [2/100], Iter [1860/3426] Loss: 0.2118 Acc: 90 %\n",
      "Epoch [2/100], Iter [1870/3426] Loss: 0.2151 Acc: 90 %\n",
      "Epoch [2/100], Iter [1880/3426] Loss: 0.2030 Acc: 90 %\n",
      "Epoch [2/100], Iter [1890/3426] Loss: 0.2064 Acc: 90 %\n",
      "Epoch [2/100], Iter [1900/3426] Loss: 0.2289 Acc: 90 %\n",
      "Epoch [2/100], Iter [1910/3426] Loss: 0.1950 Acc: 90 %\n",
      "Epoch [2/100], Iter [1920/3426] Loss: 0.2272 Acc: 90 %\n",
      "Epoch [2/100], Iter [1930/3426] Loss: 0.1855 Acc: 90 %\n",
      "Epoch [2/100], Iter [1940/3426] Loss: 0.2208 Acc: 90 %\n",
      "Epoch [2/100], Iter [1950/3426] Loss: 0.2325 Acc: 90 %\n",
      "Epoch [2/100], Iter [1960/3426] Loss: 0.2207 Acc: 90 %\n",
      "Epoch [2/100], Iter [1970/3426] Loss: 0.2113 Acc: 90 %\n",
      "Epoch [2/100], Iter [1980/3426] Loss: 0.2286 Acc: 90 %\n",
      "Epoch [2/100], Iter [1990/3426] Loss: 0.1973 Acc: 90 %\n",
      "Epoch [2/100], Iter [2000/3426] Loss: 0.2244 Acc: 90 %\n",
      "Epoch [2/100], Iter [2010/3426] Loss: 0.1652 Acc: 90 %\n",
      "Epoch [2/100], Iter [2020/3426] Loss: 0.2047 Acc: 90 %\n",
      "Epoch [2/100], Iter [2030/3426] Loss: 0.2228 Acc: 90 %\n",
      "Epoch [2/100], Iter [2040/3426] Loss: 0.2233 Acc: 90 %\n",
      "Epoch [2/100], Iter [2050/3426] Loss: 0.2048 Acc: 90 %\n",
      "Epoch [2/100], Iter [2060/3426] Loss: 0.2021 Acc: 90 %\n",
      "Epoch [2/100], Iter [2070/3426] Loss: 0.2053 Acc: 90 %\n",
      "Epoch [2/100], Iter [2080/3426] Loss: 0.2498 Acc: 90 %\n",
      "Epoch [2/100], Iter [2090/3426] Loss: 0.2241 Acc: 90 %\n",
      "Epoch [2/100], Iter [2100/3426] Loss: 0.2717 Acc: 90 %\n",
      "Epoch [2/100], Iter [2110/3426] Loss: 0.2266 Acc: 90 %\n",
      "Epoch [2/100], Iter [2120/3426] Loss: 0.2220 Acc: 90 %\n",
      "Epoch [2/100], Iter [2130/3426] Loss: 0.2247 Acc: 90 %\n",
      "Epoch [2/100], Iter [2140/3426] Loss: 0.1897 Acc: 90 %\n",
      "Epoch [2/100], Iter [2150/3426] Loss: 0.2339 Acc: 90 %\n",
      "Epoch [2/100], Iter [2160/3426] Loss: 0.2115 Acc: 90 %\n",
      "Epoch [2/100], Iter [2170/3426] Loss: 0.1833 Acc: 90 %\n",
      "Epoch [2/100], Iter [2180/3426] Loss: 0.2081 Acc: 90 %\n",
      "Epoch [2/100], Iter [2190/3426] Loss: 0.2030 Acc: 90 %\n",
      "Epoch [2/100], Iter [2200/3426] Loss: 0.2048 Acc: 90 %\n",
      "Epoch [2/100], Iter [2210/3426] Loss: 0.2257 Acc: 90 %\n",
      "Epoch [2/100], Iter [2220/3426] Loss: 0.2259 Acc: 90 %\n",
      "Epoch [2/100], Iter [2230/3426] Loss: 0.2204 Acc: 90 %\n",
      "Epoch [2/100], Iter [2240/3426] Loss: 0.2181 Acc: 90 %\n",
      "Epoch [2/100], Iter [2250/3426] Loss: 0.1872 Acc: 90 %\n",
      "Epoch [2/100], Iter [2260/3426] Loss: 0.1840 Acc: 90 %\n",
      "Epoch [2/100], Iter [2270/3426] Loss: 0.1836 Acc: 90 %\n",
      "Epoch [2/100], Iter [2280/3426] Loss: 0.2285 Acc: 90 %\n",
      "Epoch [2/100], Iter [2290/3426] Loss: 0.1928 Acc: 90 %\n",
      "Epoch [2/100], Iter [2300/3426] Loss: 0.1987 Acc: 90 %\n",
      "Epoch [2/100], Iter [2310/3426] Loss: 0.2066 Acc: 90 %\n",
      "Epoch [2/100], Iter [2320/3426] Loss: 0.2124 Acc: 90 %\n",
      "Epoch [2/100], Iter [2330/3426] Loss: 0.1957 Acc: 90 %\n",
      "Epoch [2/100], Iter [2340/3426] Loss: 0.2158 Acc: 90 %\n",
      "Epoch [2/100], Iter [2350/3426] Loss: 0.1861 Acc: 90 %\n",
      "Epoch [2/100], Iter [2360/3426] Loss: 0.2343 Acc: 90 %\n",
      "Epoch [2/100], Iter [2370/3426] Loss: 0.2123 Acc: 90 %\n",
      "Epoch [2/100], Iter [2380/3426] Loss: 0.1924 Acc: 90 %\n",
      "Epoch [2/100], Iter [2390/3426] Loss: 0.1979 Acc: 90 %\n",
      "Epoch [2/100], Iter [2400/3426] Loss: 0.1884 Acc: 90 %\n",
      "Epoch [2/100], Iter [2410/3426] Loss: 0.2073 Acc: 90 %\n",
      "Epoch [2/100], Iter [2420/3426] Loss: 0.2028 Acc: 90 %\n",
      "Epoch [2/100], Iter [2430/3426] Loss: 0.1692 Acc: 90 %\n",
      "Epoch [2/100], Iter [2440/3426] Loss: 0.2075 Acc: 90 %\n",
      "Epoch [2/100], Iter [2450/3426] Loss: 0.2012 Acc: 90 %\n",
      "Epoch [2/100], Iter [2460/3426] Loss: 0.1950 Acc: 90 %\n",
      "Epoch [2/100], Iter [2470/3426] Loss: 0.1984 Acc: 90 %\n",
      "Epoch [2/100], Iter [2480/3426] Loss: 0.2023 Acc: 90 %\n",
      "Epoch [2/100], Iter [2490/3426] Loss: 0.2128 Acc: 90 %\n",
      "Epoch [2/100], Iter [2500/3426] Loss: 0.2091 Acc: 90 %\n",
      "Epoch [2/100], Iter [2510/3426] Loss: 0.1846 Acc: 90 %\n",
      "Epoch [2/100], Iter [2520/3426] Loss: 0.2003 Acc: 90 %\n",
      "Epoch [2/100], Iter [2530/3426] Loss: 0.2373 Acc: 90 %\n",
      "Epoch [2/100], Iter [2540/3426] Loss: 0.2219 Acc: 90 %\n",
      "Epoch [2/100], Iter [2550/3426] Loss: 0.1924 Acc: 90 %\n",
      "Epoch [2/100], Iter [2560/3426] Loss: 0.1839 Acc: 91 %\n",
      "Epoch [2/100], Iter [2570/3426] Loss: 0.1930 Acc: 91 %\n",
      "Epoch [2/100], Iter [2580/3426] Loss: 0.1918 Acc: 91 %\n",
      "Epoch [2/100], Iter [2590/3426] Loss: 0.2106 Acc: 91 %\n",
      "Epoch [2/100], Iter [2600/3426] Loss: 0.2189 Acc: 91 %\n",
      "Epoch [2/100], Iter [2610/3426] Loss: 0.2120 Acc: 91 %\n",
      "Epoch [2/100], Iter [2620/3426] Loss: 0.1968 Acc: 91 %\n",
      "Epoch [2/100], Iter [2630/3426] Loss: 0.2176 Acc: 91 %\n",
      "Epoch [2/100], Iter [2640/3426] Loss: 0.2502 Acc: 91 %\n",
      "Epoch [2/100], Iter [2650/3426] Loss: 0.2128 Acc: 91 %\n",
      "Epoch [2/100], Iter [2660/3426] Loss: 0.1976 Acc: 91 %\n",
      "Epoch [2/100], Iter [2670/3426] Loss: 0.1873 Acc: 91 %\n",
      "Epoch [2/100], Iter [2680/3426] Loss: 0.1598 Acc: 91 %\n",
      "Epoch [2/100], Iter [2690/3426] Loss: 0.2196 Acc: 91 %\n",
      "Epoch [2/100], Iter [2700/3426] Loss: 0.1894 Acc: 91 %\n",
      "Epoch [2/100], Iter [2710/3426] Loss: 0.2170 Acc: 91 %\n",
      "Epoch [2/100], Iter [2720/3426] Loss: 0.2176 Acc: 91 %\n",
      "Epoch [2/100], Iter [2730/3426] Loss: 0.2159 Acc: 91 %\n",
      "Epoch [2/100], Iter [2740/3426] Loss: 0.2275 Acc: 91 %\n",
      "Epoch [2/100], Iter [2750/3426] Loss: 0.2572 Acc: 91 %\n",
      "Epoch [2/100], Iter [2760/3426] Loss: 0.2255 Acc: 91 %\n",
      "Epoch [2/100], Iter [2770/3426] Loss: 0.2212 Acc: 91 %\n",
      "Epoch [2/100], Iter [2780/3426] Loss: 0.1897 Acc: 91 %\n",
      "Epoch [2/100], Iter [2790/3426] Loss: 0.2056 Acc: 91 %\n",
      "Epoch [2/100], Iter [2800/3426] Loss: 0.1791 Acc: 91 %\n",
      "Epoch [2/100], Iter [2810/3426] Loss: 0.1851 Acc: 91 %\n",
      "Epoch [2/100], Iter [2820/3426] Loss: 0.1998 Acc: 91 %\n",
      "Epoch [2/100], Iter [2830/3426] Loss: 0.2245 Acc: 91 %\n",
      "Epoch [2/100], Iter [2840/3426] Loss: 0.2231 Acc: 91 %\n",
      "Epoch [2/100], Iter [2850/3426] Loss: 0.2219 Acc: 91 %\n",
      "Epoch [2/100], Iter [2860/3426] Loss: 0.1782 Acc: 91 %\n",
      "Epoch [2/100], Iter [2870/3426] Loss: 0.1976 Acc: 91 %\n",
      "Epoch [2/100], Iter [2880/3426] Loss: 0.1977 Acc: 91 %\n",
      "Epoch [2/100], Iter [2890/3426] Loss: 0.1865 Acc: 91 %\n",
      "Epoch [2/100], Iter [2900/3426] Loss: 0.1978 Acc: 91 %\n",
      "Epoch [2/100], Iter [2910/3426] Loss: 0.2010 Acc: 91 %\n",
      "Epoch [2/100], Iter [2920/3426] Loss: 0.2030 Acc: 91 %\n",
      "Epoch [2/100], Iter [2930/3426] Loss: 0.1795 Acc: 91 %\n",
      "Epoch [2/100], Iter [2940/3426] Loss: 0.2194 Acc: 91 %\n",
      "Epoch [2/100], Iter [2950/3426] Loss: 0.2350 Acc: 91 %\n",
      "Epoch [2/100], Iter [2960/3426] Loss: 0.2270 Acc: 91 %\n",
      "Epoch [2/100], Iter [2970/3426] Loss: 0.2001 Acc: 91 %\n",
      "Epoch [2/100], Iter [2980/3426] Loss: 0.1999 Acc: 91 %\n",
      "Epoch [2/100], Iter [2990/3426] Loss: 0.2051 Acc: 91 %\n",
      "Epoch [2/100], Iter [3000/3426] Loss: 0.1996 Acc: 91 %\n",
      "Epoch [2/100], Iter [3010/3426] Loss: 0.1695 Acc: 91 %\n",
      "Epoch [2/100], Iter [3020/3426] Loss: 0.1921 Acc: 91 %\n",
      "Epoch [2/100], Iter [3030/3426] Loss: 0.2356 Acc: 91 %\n",
      "Epoch [2/100], Iter [3040/3426] Loss: 0.2024 Acc: 91 %\n",
      "Epoch [2/100], Iter [3050/3426] Loss: 0.2034 Acc: 91 %\n",
      "Epoch [2/100], Iter [3060/3426] Loss: 0.2176 Acc: 91 %\n",
      "Epoch [2/100], Iter [3070/3426] Loss: 0.1904 Acc: 91 %\n",
      "Epoch [2/100], Iter [3080/3426] Loss: 0.2036 Acc: 91 %\n",
      "Epoch [2/100], Iter [3090/3426] Loss: 0.2069 Acc: 91 %\n",
      "Epoch [2/100], Iter [3100/3426] Loss: 0.2014 Acc: 91 %\n",
      "Epoch [2/100], Iter [3110/3426] Loss: 0.2047 Acc: 91 %\n",
      "Epoch [2/100], Iter [3120/3426] Loss: 0.1770 Acc: 91 %\n",
      "Epoch [2/100], Iter [3130/3426] Loss: 0.1958 Acc: 91 %\n",
      "Epoch [2/100], Iter [3140/3426] Loss: 0.2032 Acc: 91 %\n",
      "Epoch [2/100], Iter [3150/3426] Loss: 0.2178 Acc: 91 %\n",
      "Epoch [2/100], Iter [3160/3426] Loss: 0.2180 Acc: 91 %\n",
      "Epoch [2/100], Iter [3170/3426] Loss: 0.2347 Acc: 91 %\n",
      "Epoch [2/100], Iter [3180/3426] Loss: 0.2180 Acc: 91 %\n",
      "Epoch [2/100], Iter [3190/3426] Loss: 0.2250 Acc: 91 %\n",
      "Epoch [2/100], Iter [3200/3426] Loss: 0.1963 Acc: 91 %\n",
      "Epoch [2/100], Iter [3210/3426] Loss: 0.2021 Acc: 91 %\n",
      "Epoch [2/100], Iter [3220/3426] Loss: 0.2104 Acc: 91 %\n",
      "Epoch [2/100], Iter [3230/3426] Loss: 0.2033 Acc: 91 %\n",
      "Epoch [2/100], Iter [3240/3426] Loss: 0.1865 Acc: 91 %\n",
      "Epoch [2/100], Iter [3250/3426] Loss: 0.2094 Acc: 91 %\n",
      "Epoch [2/100], Iter [3260/3426] Loss: 0.2078 Acc: 91 %\n",
      "Epoch [2/100], Iter [3270/3426] Loss: 0.2014 Acc: 91 %\n",
      "Epoch [2/100], Iter [3280/3426] Loss: 0.2084 Acc: 91 %\n",
      "Epoch [2/100], Iter [3290/3426] Loss: 0.1916 Acc: 91 %\n",
      "Epoch [2/100], Iter [3300/3426] Loss: 0.2300 Acc: 91 %\n",
      "Epoch [2/100], Iter [3310/3426] Loss: 0.2095 Acc: 91 %\n",
      "Epoch [2/100], Iter [3320/3426] Loss: 0.2067 Acc: 91 %\n",
      "Epoch [2/100], Iter [3330/3426] Loss: 0.2204 Acc: 91 %\n",
      "Epoch [2/100], Iter [3340/3426] Loss: 0.1731 Acc: 91 %\n",
      "Epoch [2/100], Iter [3350/3426] Loss: 0.1772 Acc: 91 %\n",
      "Epoch [2/100], Iter [3360/3426] Loss: 0.2309 Acc: 91 %\n",
      "Epoch [2/100], Iter [3370/3426] Loss: 0.1986 Acc: 91 %\n",
      "Epoch [2/100], Iter [3380/3426] Loss: 0.2014 Acc: 91 %\n",
      "Epoch [2/100], Iter [3390/3426] Loss: 0.1978 Acc: 91 %\n",
      "Epoch [2/100], Iter [3400/3426] Loss: 0.2035 Acc: 91 %\n",
      "Epoch [2/100], Iter [3410/3426] Loss: 0.2057 Acc: 91 %\n",
      "Epoch [2/100], Iter [3420/3426] Loss: 0.2182 Acc: 91 %\n",
      "Accuracy of the model on the neg seq: 53 %\n",
      "Accuracy of the model on the pos seq: 99 %\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch [3/100], Iter [10/3426] Loss: 0.1926 Acc: 92 %\n",
      "Epoch [3/100], Iter [20/3426] Loss: 0.1880 Acc: 91 %\n",
      "Epoch [3/100], Iter [30/3426] Loss: 0.1985 Acc: 91 %\n",
      "Epoch [3/100], Iter [40/3426] Loss: 0.2065 Acc: 91 %\n",
      "Epoch [3/100], Iter [50/3426] Loss: 0.2213 Acc: 91 %\n",
      "Epoch [3/100], Iter [60/3426] Loss: 0.1897 Acc: 91 %\n",
      "Epoch [3/100], Iter [70/3426] Loss: 0.2046 Acc: 91 %\n",
      "Epoch [3/100], Iter [80/3426] Loss: 0.2232 Acc: 91 %\n",
      "Epoch [3/100], Iter [90/3426] Loss: 0.2154 Acc: 91 %\n",
      "Epoch [3/100], Iter [100/3426] Loss: 0.2219 Acc: 91 %\n",
      "Epoch [3/100], Iter [110/3426] Loss: 0.2163 Acc: 91 %\n",
      "Epoch [3/100], Iter [120/3426] Loss: 0.1997 Acc: 91 %\n",
      "Epoch [3/100], Iter [130/3426] Loss: 0.1721 Acc: 91 %\n",
      "Epoch [3/100], Iter [140/3426] Loss: 0.1507 Acc: 91 %\n",
      "Epoch [3/100], Iter [150/3426] Loss: 0.1649 Acc: 91 %\n",
      "Epoch [3/100], Iter [160/3426] Loss: 0.2070 Acc: 91 %\n",
      "Epoch [3/100], Iter [170/3426] Loss: 0.1701 Acc: 91 %\n",
      "Epoch [3/100], Iter [180/3426] Loss: 0.2039 Acc: 91 %\n",
      "Epoch [3/100], Iter [190/3426] Loss: 0.1915 Acc: 91 %\n",
      "Epoch [3/100], Iter [200/3426] Loss: 0.1707 Acc: 91 %\n",
      "Epoch [3/100], Iter [210/3426] Loss: 0.1955 Acc: 91 %\n",
      "Epoch [3/100], Iter [220/3426] Loss: 0.1993 Acc: 91 %\n",
      "Epoch [3/100], Iter [230/3426] Loss: 0.1944 Acc: 91 %\n",
      "Epoch [3/100], Iter [240/3426] Loss: 0.1724 Acc: 91 %\n",
      "Epoch [3/100], Iter [250/3426] Loss: 0.2229 Acc: 91 %\n",
      "Epoch [3/100], Iter [260/3426] Loss: 0.2313 Acc: 91 %\n",
      "Epoch [3/100], Iter [270/3426] Loss: 0.2392 Acc: 91 %\n",
      "Epoch [3/100], Iter [280/3426] Loss: 0.1891 Acc: 91 %\n",
      "Epoch [3/100], Iter [290/3426] Loss: 0.1786 Acc: 91 %\n",
      "Epoch [3/100], Iter [300/3426] Loss: 0.2164 Acc: 91 %\n",
      "Epoch [3/100], Iter [310/3426] Loss: 0.1890 Acc: 91 %\n",
      "Epoch [3/100], Iter [320/3426] Loss: 0.1905 Acc: 91 %\n",
      "Epoch [3/100], Iter [330/3426] Loss: 0.1879 Acc: 91 %\n",
      "Epoch [3/100], Iter [340/3426] Loss: 0.1926 Acc: 91 %\n",
      "Epoch [3/100], Iter [350/3426] Loss: 0.2366 Acc: 91 %\n",
      "Epoch [3/100], Iter [360/3426] Loss: 0.2006 Acc: 91 %\n",
      "Epoch [3/100], Iter [370/3426] Loss: 0.2017 Acc: 91 %\n",
      "Epoch [3/100], Iter [380/3426] Loss: 0.2199 Acc: 91 %\n",
      "Epoch [3/100], Iter [390/3426] Loss: 0.2290 Acc: 91 %\n",
      "Epoch [3/100], Iter [400/3426] Loss: 0.2220 Acc: 91 %\n",
      "Epoch [3/100], Iter [410/3426] Loss: 0.1858 Acc: 91 %\n",
      "Epoch [3/100], Iter [420/3426] Loss: 0.1957 Acc: 91 %\n",
      "Epoch [3/100], Iter [430/3426] Loss: 0.2038 Acc: 91 %\n",
      "Epoch [3/100], Iter [440/3426] Loss: 0.1907 Acc: 91 %\n",
      "Epoch [3/100], Iter [450/3426] Loss: 0.2138 Acc: 91 %\n",
      "Epoch [3/100], Iter [460/3426] Loss: 0.1863 Acc: 91 %\n",
      "Epoch [3/100], Iter [470/3426] Loss: 0.2012 Acc: 91 %\n",
      "Epoch [3/100], Iter [480/3426] Loss: 0.1958 Acc: 91 %\n",
      "Epoch [3/100], Iter [490/3426] Loss: 0.2116 Acc: 91 %\n",
      "Epoch [3/100], Iter [500/3426] Loss: 0.2142 Acc: 91 %\n",
      "Epoch [3/100], Iter [510/3426] Loss: 0.2008 Acc: 91 %\n",
      "Epoch [3/100], Iter [520/3426] Loss: 0.2012 Acc: 91 %\n",
      "Epoch [3/100], Iter [530/3426] Loss: 0.2338 Acc: 91 %\n",
      "Epoch [3/100], Iter [540/3426] Loss: 0.2500 Acc: 91 %\n",
      "Epoch [3/100], Iter [550/3426] Loss: 0.2076 Acc: 91 %\n",
      "Epoch [3/100], Iter [560/3426] Loss: 0.2257 Acc: 91 %\n",
      "Epoch [3/100], Iter [570/3426] Loss: 0.2035 Acc: 91 %\n",
      "Epoch [3/100], Iter [580/3426] Loss: 0.1718 Acc: 91 %\n",
      "Epoch [3/100], Iter [590/3426] Loss: 0.1919 Acc: 91 %\n",
      "Epoch [3/100], Iter [600/3426] Loss: 0.1641 Acc: 91 %\n",
      "Epoch [3/100], Iter [610/3426] Loss: 0.1901 Acc: 91 %\n",
      "Epoch [3/100], Iter [620/3426] Loss: 0.1940 Acc: 91 %\n",
      "Epoch [3/100], Iter [630/3426] Loss: 0.1861 Acc: 91 %\n",
      "Epoch [3/100], Iter [640/3426] Loss: 0.1941 Acc: 91 %\n",
      "Epoch [3/100], Iter [650/3426] Loss: 0.1900 Acc: 91 %\n",
      "Epoch [3/100], Iter [660/3426] Loss: 0.2377 Acc: 91 %\n",
      "Epoch [3/100], Iter [670/3426] Loss: 0.2301 Acc: 91 %\n",
      "Epoch [3/100], Iter [680/3426] Loss: 0.2048 Acc: 91 %\n",
      "Epoch [3/100], Iter [690/3426] Loss: 0.1910 Acc: 91 %\n",
      "Epoch [3/100], Iter [700/3426] Loss: 0.1718 Acc: 91 %\n",
      "Epoch [3/100], Iter [710/3426] Loss: 0.1697 Acc: 91 %\n",
      "Epoch [3/100], Iter [720/3426] Loss: 0.1813 Acc: 91 %\n",
      "Epoch [3/100], Iter [730/3426] Loss: 0.2334 Acc: 91 %\n",
      "Epoch [3/100], Iter [740/3426] Loss: 0.2071 Acc: 91 %\n",
      "Epoch [3/100], Iter [750/3426] Loss: 0.2105 Acc: 91 %\n",
      "Epoch [3/100], Iter [760/3426] Loss: 0.1788 Acc: 91 %\n",
      "Epoch [3/100], Iter [770/3426] Loss: 0.2168 Acc: 91 %\n",
      "Epoch [3/100], Iter [780/3426] Loss: 0.1833 Acc: 91 %\n",
      "Epoch [3/100], Iter [790/3426] Loss: 0.1913 Acc: 91 %\n",
      "Epoch [3/100], Iter [800/3426] Loss: 0.1997 Acc: 91 %\n",
      "Epoch [3/100], Iter [810/3426] Loss: 0.1893 Acc: 91 %\n",
      "Epoch [3/100], Iter [820/3426] Loss: 0.2051 Acc: 91 %\n",
      "Epoch [3/100], Iter [830/3426] Loss: 0.1961 Acc: 91 %\n",
      "Epoch [3/100], Iter [840/3426] Loss: 0.2125 Acc: 91 %\n",
      "Epoch [3/100], Iter [850/3426] Loss: 0.1951 Acc: 91 %\n",
      "Epoch [3/100], Iter [860/3426] Loss: 0.1592 Acc: 91 %\n",
      "Epoch [3/100], Iter [870/3426] Loss: 0.1622 Acc: 91 %\n",
      "Epoch [3/100], Iter [880/3426] Loss: 0.1821 Acc: 91 %\n",
      "Epoch [3/100], Iter [890/3426] Loss: 0.1963 Acc: 91 %\n",
      "Epoch [3/100], Iter [900/3426] Loss: 0.2089 Acc: 91 %\n",
      "Epoch [3/100], Iter [910/3426] Loss: 0.2089 Acc: 91 %\n",
      "Epoch [3/100], Iter [920/3426] Loss: 0.2606 Acc: 91 %\n",
      "Epoch [3/100], Iter [930/3426] Loss: 0.2499 Acc: 91 %\n",
      "Epoch [3/100], Iter [940/3426] Loss: 0.2350 Acc: 91 %\n",
      "Epoch [3/100], Iter [950/3426] Loss: 0.2122 Acc: 91 %\n",
      "Epoch [3/100], Iter [960/3426] Loss: 0.2125 Acc: 91 %\n",
      "Epoch [3/100], Iter [970/3426] Loss: 0.1962 Acc: 91 %\n",
      "Epoch [3/100], Iter [980/3426] Loss: 0.2382 Acc: 91 %\n",
      "Epoch [3/100], Iter [990/3426] Loss: 0.2406 Acc: 91 %\n",
      "Epoch [3/100], Iter [1000/3426] Loss: 0.2185 Acc: 91 %\n",
      "Epoch [3/100], Iter [1010/3426] Loss: 0.2507 Acc: 91 %\n",
      "Epoch [3/100], Iter [1020/3426] Loss: 0.2032 Acc: 91 %\n",
      "Epoch [3/100], Iter [1030/3426] Loss: 0.2126 Acc: 91 %\n",
      "Epoch [3/100], Iter [1040/3426] Loss: 0.1673 Acc: 91 %\n",
      "Epoch [3/100], Iter [1050/3426] Loss: 0.1999 Acc: 91 %\n",
      "Epoch [3/100], Iter [1060/3426] Loss: 0.1832 Acc: 91 %\n",
      "Epoch [3/100], Iter [1070/3426] Loss: 0.1929 Acc: 91 %\n",
      "Epoch [3/100], Iter [1080/3426] Loss: 0.2123 Acc: 91 %\n",
      "Epoch [3/100], Iter [1090/3426] Loss: 0.2066 Acc: 91 %\n",
      "Epoch [3/100], Iter [1100/3426] Loss: 0.2540 Acc: 91 %\n",
      "Epoch [3/100], Iter [1110/3426] Loss: 0.1899 Acc: 91 %\n",
      "Epoch [3/100], Iter [1120/3426] Loss: 0.2665 Acc: 91 %\n",
      "Epoch [3/100], Iter [1130/3426] Loss: 0.1850 Acc: 91 %\n",
      "Epoch [3/100], Iter [1140/3426] Loss: 0.2130 Acc: 91 %\n",
      "Epoch [3/100], Iter [1150/3426] Loss: 0.2233 Acc: 91 %\n",
      "Epoch [3/100], Iter [1160/3426] Loss: 0.2401 Acc: 91 %\n",
      "Epoch [3/100], Iter [1170/3426] Loss: 0.2310 Acc: 91 %\n",
      "Epoch [3/100], Iter [1180/3426] Loss: 0.1886 Acc: 91 %\n",
      "Epoch [3/100], Iter [1190/3426] Loss: 0.2159 Acc: 91 %\n",
      "Epoch [3/100], Iter [1200/3426] Loss: 0.2127 Acc: 91 %\n",
      "Epoch [3/100], Iter [1210/3426] Loss: 0.1900 Acc: 91 %\n",
      "Epoch [3/100], Iter [1220/3426] Loss: 0.2066 Acc: 91 %\n",
      "Epoch [3/100], Iter [1230/3426] Loss: 0.1975 Acc: 91 %\n",
      "Epoch [3/100], Iter [1240/3426] Loss: 0.2116 Acc: 91 %\n",
      "Epoch [3/100], Iter [1250/3426] Loss: 0.1963 Acc: 91 %\n",
      "Epoch [3/100], Iter [1260/3426] Loss: 0.2095 Acc: 91 %\n",
      "Epoch [3/100], Iter [1270/3426] Loss: 0.2170 Acc: 91 %\n",
      "Epoch [3/100], Iter [1280/3426] Loss: 0.2010 Acc: 91 %\n",
      "Epoch [3/100], Iter [1290/3426] Loss: 0.1809 Acc: 91 %\n",
      "Epoch [3/100], Iter [1300/3426] Loss: 0.2178 Acc: 91 %\n",
      "Epoch [3/100], Iter [1310/3426] Loss: 0.2248 Acc: 91 %\n",
      "Epoch [3/100], Iter [1320/3426] Loss: 0.2794 Acc: 91 %\n",
      "Epoch [3/100], Iter [1330/3426] Loss: 0.2046 Acc: 91 %\n",
      "Epoch [3/100], Iter [1340/3426] Loss: 0.1857 Acc: 91 %\n",
      "Epoch [3/100], Iter [1350/3426] Loss: 0.2031 Acc: 91 %\n",
      "Epoch [3/100], Iter [1360/3426] Loss: 0.2314 Acc: 91 %\n",
      "Epoch [3/100], Iter [1370/3426] Loss: 0.2057 Acc: 91 %\n",
      "Epoch [3/100], Iter [1380/3426] Loss: 0.2372 Acc: 91 %\n",
      "Epoch [3/100], Iter [1390/3426] Loss: 0.2084 Acc: 91 %\n",
      "Epoch [3/100], Iter [1400/3426] Loss: 0.2059 Acc: 91 %\n",
      "Epoch [3/100], Iter [1410/3426] Loss: 0.2129 Acc: 91 %\n",
      "Epoch [3/100], Iter [1420/3426] Loss: 0.2312 Acc: 91 %\n",
      "Epoch [3/100], Iter [1430/3426] Loss: 0.2386 Acc: 91 %\n",
      "Epoch [3/100], Iter [1440/3426] Loss: 0.1725 Acc: 91 %\n",
      "Epoch [3/100], Iter [1450/3426] Loss: 0.2239 Acc: 91 %\n",
      "Epoch [3/100], Iter [1460/3426] Loss: 0.1974 Acc: 91 %\n",
      "Epoch [3/100], Iter [1470/3426] Loss: 0.2168 Acc: 91 %\n",
      "Epoch [3/100], Iter [1480/3426] Loss: 0.1777 Acc: 91 %\n",
      "Epoch [3/100], Iter [1490/3426] Loss: 0.1895 Acc: 91 %\n",
      "Epoch [3/100], Iter [1500/3426] Loss: 0.2221 Acc: 91 %\n",
      "Epoch [3/100], Iter [1510/3426] Loss: 0.1897 Acc: 91 %\n",
      "Epoch [3/100], Iter [1520/3426] Loss: 0.1691 Acc: 91 %\n",
      "Epoch [3/100], Iter [1530/3426] Loss: 0.1840 Acc: 91 %\n",
      "Epoch [3/100], Iter [1540/3426] Loss: 0.1891 Acc: 91 %\n",
      "Epoch [3/100], Iter [1550/3426] Loss: 0.1876 Acc: 91 %\n",
      "Epoch [3/100], Iter [1560/3426] Loss: 0.1975 Acc: 91 %\n",
      "Epoch [3/100], Iter [1570/3426] Loss: 0.1613 Acc: 91 %\n",
      "Epoch [3/100], Iter [1580/3426] Loss: 0.2293 Acc: 91 %\n",
      "Epoch [3/100], Iter [1590/3426] Loss: 0.1769 Acc: 91 %\n",
      "Epoch [3/100], Iter [1600/3426] Loss: 0.2199 Acc: 91 %\n",
      "Epoch [3/100], Iter [1610/3426] Loss: 0.1984 Acc: 91 %\n",
      "Epoch [3/100], Iter [1620/3426] Loss: 0.1512 Acc: 91 %\n",
      "Epoch [3/100], Iter [1630/3426] Loss: 0.2030 Acc: 91 %\n",
      "Epoch [3/100], Iter [1640/3426] Loss: 0.1803 Acc: 91 %\n",
      "Epoch [3/100], Iter [1650/3426] Loss: 0.1907 Acc: 91 %\n",
      "Epoch [3/100], Iter [1660/3426] Loss: 0.2076 Acc: 91 %\n",
      "Epoch [3/100], Iter [1670/3426] Loss: 0.2093 Acc: 91 %\n",
      "Epoch [3/100], Iter [1680/3426] Loss: 0.2005 Acc: 91 %\n",
      "Epoch [3/100], Iter [1690/3426] Loss: 0.1971 Acc: 91 %\n",
      "Epoch [3/100], Iter [1700/3426] Loss: 0.1827 Acc: 91 %\n",
      "Epoch [3/100], Iter [1710/3426] Loss: 0.2003 Acc: 91 %\n",
      "Epoch [3/100], Iter [1720/3426] Loss: 0.2160 Acc: 91 %\n",
      "Epoch [3/100], Iter [1730/3426] Loss: 0.1760 Acc: 91 %\n",
      "Epoch [3/100], Iter [1740/3426] Loss: 0.1994 Acc: 91 %\n",
      "Epoch [3/100], Iter [1750/3426] Loss: 0.2020 Acc: 91 %\n",
      "Epoch [3/100], Iter [1760/3426] Loss: 0.2105 Acc: 91 %\n",
      "Epoch [3/100], Iter [1770/3426] Loss: 0.1689 Acc: 91 %\n",
      "Epoch [3/100], Iter [1780/3426] Loss: 0.1919 Acc: 91 %\n",
      "Epoch [3/100], Iter [1790/3426] Loss: 0.2023 Acc: 91 %\n",
      "Epoch [3/100], Iter [1800/3426] Loss: 0.2247 Acc: 91 %\n",
      "Epoch [3/100], Iter [1810/3426] Loss: 0.2141 Acc: 91 %\n",
      "Epoch [3/100], Iter [1820/3426] Loss: 0.2193 Acc: 91 %\n",
      "Epoch [3/100], Iter [1830/3426] Loss: 0.2287 Acc: 91 %\n",
      "Epoch [3/100], Iter [1840/3426] Loss: 0.1990 Acc: 91 %\n",
      "Epoch [3/100], Iter [1850/3426] Loss: 0.1841 Acc: 91 %\n",
      "Epoch [3/100], Iter [1860/3426] Loss: 0.1939 Acc: 91 %\n",
      "Epoch [3/100], Iter [1870/3426] Loss: 0.1932 Acc: 91 %\n",
      "Epoch [3/100], Iter [1880/3426] Loss: 0.1756 Acc: 91 %\n",
      "Epoch [3/100], Iter [1890/3426] Loss: 0.4180 Acc: 91 %\n",
      "Epoch [3/100], Iter [1900/3426] Loss: 0.2136 Acc: 91 %\n",
      "Epoch [3/100], Iter [1910/3426] Loss: 0.2195 Acc: 91 %\n",
      "Epoch [3/100], Iter [1920/3426] Loss: 0.2239 Acc: 91 %\n",
      "Epoch [3/100], Iter [1930/3426] Loss: 0.1729 Acc: 91 %\n",
      "Epoch [3/100], Iter [1940/3426] Loss: 0.2019 Acc: 91 %\n",
      "Epoch [3/100], Iter [1950/3426] Loss: 0.2098 Acc: 91 %\n",
      "Epoch [3/100], Iter [1960/3426] Loss: 0.2034 Acc: 91 %\n",
      "Epoch [3/100], Iter [1970/3426] Loss: 0.2262 Acc: 91 %\n",
      "Epoch [3/100], Iter [1980/3426] Loss: 0.2089 Acc: 91 %\n",
      "Epoch [3/100], Iter [1990/3426] Loss: 0.2051 Acc: 91 %\n",
      "Epoch [3/100], Iter [2000/3426] Loss: 0.1785 Acc: 91 %\n",
      "Epoch [3/100], Iter [2010/3426] Loss: 0.1988 Acc: 91 %\n",
      "Epoch [3/100], Iter [2020/3426] Loss: 0.2147 Acc: 91 %\n",
      "Epoch [3/100], Iter [2030/3426] Loss: 0.2120 Acc: 91 %\n",
      "Epoch [3/100], Iter [2040/3426] Loss: 0.1915 Acc: 91 %\n",
      "Epoch [3/100], Iter [2050/3426] Loss: 0.1981 Acc: 91 %\n",
      "Epoch [3/100], Iter [2060/3426] Loss: 0.2415 Acc: 91 %\n",
      "Epoch [3/100], Iter [2070/3426] Loss: 0.1793 Acc: 91 %\n",
      "Epoch [3/100], Iter [2080/3426] Loss: 0.2316 Acc: 91 %\n",
      "Epoch [3/100], Iter [2090/3426] Loss: 0.1809 Acc: 91 %\n",
      "Epoch [3/100], Iter [2100/3426] Loss: 0.2182 Acc: 91 %\n",
      "Epoch [3/100], Iter [2110/3426] Loss: 0.1870 Acc: 91 %\n",
      "Epoch [3/100], Iter [2120/3426] Loss: 0.1738 Acc: 91 %\n",
      "Epoch [3/100], Iter [2130/3426] Loss: 0.2429 Acc: 91 %\n",
      "Epoch [3/100], Iter [2140/3426] Loss: 0.2068 Acc: 91 %\n",
      "Epoch [3/100], Iter [2150/3426] Loss: 0.2170 Acc: 91 %\n",
      "Epoch [3/100], Iter [2160/3426] Loss: 0.2100 Acc: 91 %\n",
      "Epoch [3/100], Iter [2170/3426] Loss: 0.2142 Acc: 91 %\n",
      "Epoch [3/100], Iter [2180/3426] Loss: 0.2190 Acc: 91 %\n",
      "Epoch [3/100], Iter [2190/3426] Loss: 0.2147 Acc: 91 %\n",
      "Epoch [3/100], Iter [2200/3426] Loss: 0.1871 Acc: 91 %\n",
      "Epoch [3/100], Iter [2210/3426] Loss: 0.1877 Acc: 91 %\n",
      "Epoch [3/100], Iter [2220/3426] Loss: 0.2111 Acc: 91 %\n",
      "Epoch [3/100], Iter [2230/3426] Loss: 0.1873 Acc: 91 %\n",
      "Epoch [3/100], Iter [2240/3426] Loss: 0.2035 Acc: 91 %\n",
      "Epoch [3/100], Iter [2250/3426] Loss: 0.2096 Acc: 91 %\n",
      "Epoch [3/100], Iter [2260/3426] Loss: 0.1879 Acc: 91 %\n",
      "Epoch [3/100], Iter [2270/3426] Loss: 0.2266 Acc: 91 %\n",
      "Epoch [3/100], Iter [2280/3426] Loss: 0.2165 Acc: 91 %\n",
      "Epoch [3/100], Iter [2290/3426] Loss: 0.2276 Acc: 91 %\n",
      "Epoch [3/100], Iter [2300/3426] Loss: 0.2065 Acc: 91 %\n",
      "Epoch [3/100], Iter [2310/3426] Loss: 0.1664 Acc: 91 %\n",
      "Epoch [3/100], Iter [2320/3426] Loss: 0.2217 Acc: 91 %\n",
      "Epoch [3/100], Iter [2330/3426] Loss: 0.2029 Acc: 91 %\n",
      "Epoch [3/100], Iter [2340/3426] Loss: 0.2220 Acc: 91 %\n",
      "Epoch [3/100], Iter [2350/3426] Loss: 0.1945 Acc: 91 %\n",
      "Epoch [3/100], Iter [2360/3426] Loss: 0.1847 Acc: 91 %\n",
      "Epoch [3/100], Iter [2370/3426] Loss: 0.2010 Acc: 91 %\n",
      "Epoch [3/100], Iter [2380/3426] Loss: 0.2199 Acc: 91 %\n",
      "Epoch [3/100], Iter [2390/3426] Loss: 0.2015 Acc: 91 %\n",
      "Epoch [3/100], Iter [2400/3426] Loss: 0.1907 Acc: 91 %\n",
      "Epoch [3/100], Iter [2410/3426] Loss: 0.2132 Acc: 91 %\n",
      "Epoch [3/100], Iter [2420/3426] Loss: 0.1944 Acc: 91 %\n",
      "Epoch [3/100], Iter [2430/3426] Loss: 0.1866 Acc: 91 %\n",
      "Epoch [3/100], Iter [2440/3426] Loss: 0.2015 Acc: 91 %\n",
      "Epoch [3/100], Iter [2450/3426] Loss: 0.1659 Acc: 91 %\n",
      "Epoch [3/100], Iter [2460/3426] Loss: 0.1656 Acc: 91 %\n",
      "Epoch [3/100], Iter [2470/3426] Loss: 0.2199 Acc: 91 %\n",
      "Epoch [3/100], Iter [2480/3426] Loss: 0.1885 Acc: 91 %\n",
      "Epoch [3/100], Iter [2490/3426] Loss: 0.2171 Acc: 91 %\n",
      "Epoch [3/100], Iter [2500/3426] Loss: 0.2278 Acc: 91 %\n",
      "Epoch [3/100], Iter [2510/3426] Loss: 0.2009 Acc: 91 %\n",
      "Epoch [3/100], Iter [2520/3426] Loss: 0.2248 Acc: 91 %\n",
      "Epoch [3/100], Iter [2530/3426] Loss: 0.2005 Acc: 91 %\n",
      "Epoch [3/100], Iter [2540/3426] Loss: 0.1982 Acc: 91 %\n",
      "Epoch [3/100], Iter [2550/3426] Loss: 0.2249 Acc: 91 %\n",
      "Epoch [3/100], Iter [2560/3426] Loss: 0.1955 Acc: 91 %\n",
      "Epoch [3/100], Iter [2570/3426] Loss: 0.1745 Acc: 91 %\n",
      "Epoch [3/100], Iter [2580/3426] Loss: 0.2088 Acc: 91 %\n",
      "Epoch [3/100], Iter [2590/3426] Loss: 0.2011 Acc: 91 %\n",
      "Epoch [3/100], Iter [2600/3426] Loss: 0.1584 Acc: 91 %\n",
      "Epoch [3/100], Iter [2610/3426] Loss: 0.1923 Acc: 91 %\n",
      "Epoch [3/100], Iter [2620/3426] Loss: 0.1826 Acc: 91 %\n",
      "Epoch [3/100], Iter [2630/3426] Loss: 0.2052 Acc: 91 %\n",
      "Epoch [3/100], Iter [2640/3426] Loss: 0.1693 Acc: 91 %\n",
      "Epoch [3/100], Iter [2650/3426] Loss: 0.2278 Acc: 91 %\n",
      "Epoch [3/100], Iter [2660/3426] Loss: 0.1885 Acc: 91 %\n",
      "Epoch [3/100], Iter [2670/3426] Loss: 0.2260 Acc: 91 %\n",
      "Epoch [3/100], Iter [2680/3426] Loss: 0.1776 Acc: 91 %\n",
      "Epoch [3/100], Iter [2690/3426] Loss: 0.1540 Acc: 91 %\n",
      "Epoch [3/100], Iter [2700/3426] Loss: 0.1936 Acc: 91 %\n",
      "Epoch [3/100], Iter [2710/3426] Loss: 0.1890 Acc: 91 %\n",
      "Epoch [3/100], Iter [2720/3426] Loss: 0.2273 Acc: 91 %\n",
      "Epoch [3/100], Iter [2730/3426] Loss: 0.2261 Acc: 91 %\n",
      "Epoch [3/100], Iter [2740/3426] Loss: 0.2023 Acc: 91 %\n",
      "Epoch [3/100], Iter [2750/3426] Loss: 0.2861 Acc: 91 %\n",
      "Epoch [3/100], Iter [2760/3426] Loss: 0.2192 Acc: 91 %\n",
      "Epoch [3/100], Iter [2770/3426] Loss: 0.1954 Acc: 91 %\n",
      "Epoch [3/100], Iter [2780/3426] Loss: 0.2179 Acc: 91 %\n",
      "Epoch [3/100], Iter [2790/3426] Loss: 0.1982 Acc: 91 %\n",
      "Epoch [3/100], Iter [2800/3426] Loss: 0.2061 Acc: 91 %\n",
      "Epoch [3/100], Iter [2810/3426] Loss: 0.2057 Acc: 91 %\n",
      "Epoch [3/100], Iter [2820/3426] Loss: 0.1720 Acc: 91 %\n",
      "Epoch [3/100], Iter [2830/3426] Loss: 0.2297 Acc: 91 %\n",
      "Epoch [3/100], Iter [2840/3426] Loss: 0.2011 Acc: 91 %\n",
      "Epoch [3/100], Iter [2850/3426] Loss: 0.2059 Acc: 91 %\n",
      "Epoch [3/100], Iter [2860/3426] Loss: 0.2184 Acc: 91 %\n",
      "Epoch [3/100], Iter [2870/3426] Loss: 0.2071 Acc: 91 %\n",
      "Epoch [3/100], Iter [2880/3426] Loss: 0.1812 Acc: 91 %\n",
      "Epoch [3/100], Iter [2890/3426] Loss: 0.1907 Acc: 91 %\n",
      "Epoch [3/100], Iter [2900/3426] Loss: 0.1831 Acc: 91 %\n",
      "Epoch [3/100], Iter [2910/3426] Loss: 0.1882 Acc: 91 %\n",
      "Epoch [3/100], Iter [2920/3426] Loss: 0.2004 Acc: 91 %\n",
      "Epoch [3/100], Iter [2930/3426] Loss: 0.1994 Acc: 91 %\n",
      "Epoch [3/100], Iter [2940/3426] Loss: 0.2025 Acc: 91 %\n",
      "Epoch [3/100], Iter [2950/3426] Loss: 0.1851 Acc: 91 %\n",
      "Epoch [3/100], Iter [2960/3426] Loss: 0.2158 Acc: 91 %\n",
      "Epoch [3/100], Iter [2970/3426] Loss: 0.2236 Acc: 91 %\n",
      "Epoch [3/100], Iter [2980/3426] Loss: 0.2389 Acc: 91 %\n",
      "Epoch [3/100], Iter [2990/3426] Loss: 0.2012 Acc: 91 %\n",
      "Epoch [3/100], Iter [3000/3426] Loss: 0.1942 Acc: 91 %\n",
      "Epoch [3/100], Iter [3010/3426] Loss: 0.2139 Acc: 91 %\n",
      "Epoch [3/100], Iter [3020/3426] Loss: 0.2305 Acc: 91 %\n",
      "Epoch [3/100], Iter [3030/3426] Loss: 0.2437 Acc: 91 %\n",
      "Epoch [3/100], Iter [3040/3426] Loss: 0.2167 Acc: 91 %\n",
      "Epoch [3/100], Iter [3050/3426] Loss: 0.1945 Acc: 91 %\n",
      "Epoch [3/100], Iter [3060/3426] Loss: 0.1810 Acc: 91 %\n",
      "Epoch [3/100], Iter [3070/3426] Loss: 0.2082 Acc: 91 %\n",
      "Epoch [3/100], Iter [3080/3426] Loss: 0.2042 Acc: 91 %\n",
      "Epoch [3/100], Iter [3090/3426] Loss: 0.1945 Acc: 91 %\n",
      "Epoch [3/100], Iter [3100/3426] Loss: 0.2057 Acc: 91 %\n",
      "Epoch [3/100], Iter [3110/3426] Loss: 0.2194 Acc: 91 %\n",
      "Epoch [3/100], Iter [3120/3426] Loss: 0.2231 Acc: 91 %\n",
      "Epoch [3/100], Iter [3130/3426] Loss: 0.1512 Acc: 91 %\n",
      "Epoch [3/100], Iter [3140/3426] Loss: 0.1906 Acc: 91 %\n",
      "Epoch [3/100], Iter [3150/3426] Loss: 0.2289 Acc: 91 %\n",
      "Epoch [3/100], Iter [3160/3426] Loss: 0.1778 Acc: 91 %\n",
      "Epoch [3/100], Iter [3170/3426] Loss: 0.1961 Acc: 91 %\n",
      "Epoch [3/100], Iter [3180/3426] Loss: 0.1993 Acc: 91 %\n",
      "Epoch [3/100], Iter [3190/3426] Loss: 0.1817 Acc: 91 %\n",
      "Epoch [3/100], Iter [3200/3426] Loss: 0.2103 Acc: 91 %\n",
      "Epoch [3/100], Iter [3210/3426] Loss: 0.2055 Acc: 91 %\n",
      "Epoch [3/100], Iter [3220/3426] Loss: 0.2175 Acc: 91 %\n",
      "Epoch [3/100], Iter [3230/3426] Loss: 0.2103 Acc: 91 %\n",
      "Epoch [3/100], Iter [3240/3426] Loss: 0.1858 Acc: 91 %\n",
      "Epoch [3/100], Iter [3250/3426] Loss: 0.1921 Acc: 91 %\n",
      "Epoch [3/100], Iter [3260/3426] Loss: 0.1780 Acc: 91 %\n",
      "Epoch [3/100], Iter [3270/3426] Loss: 0.2004 Acc: 91 %\n",
      "Epoch [3/100], Iter [3280/3426] Loss: 0.1794 Acc: 91 %\n",
      "Epoch [3/100], Iter [3290/3426] Loss: 0.4104 Acc: 91 %\n",
      "Epoch [3/100], Iter [3300/3426] Loss: 0.2538 Acc: 91 %\n",
      "Epoch [3/100], Iter [3310/3426] Loss: 0.2042 Acc: 91 %\n",
      "Epoch [3/100], Iter [3320/3426] Loss: 0.2120 Acc: 91 %\n",
      "Epoch [3/100], Iter [3330/3426] Loss: 0.1598 Acc: 91 %\n",
      "Epoch [3/100], Iter [3340/3426] Loss: 0.1979 Acc: 91 %\n",
      "Epoch [3/100], Iter [3350/3426] Loss: 0.2069 Acc: 91 %\n",
      "Epoch [3/100], Iter [3360/3426] Loss: 0.1957 Acc: 91 %\n",
      "Epoch [3/100], Iter [3370/3426] Loss: 0.1917 Acc: 91 %\n",
      "Epoch [3/100], Iter [3380/3426] Loss: 0.1768 Acc: 91 %\n",
      "Epoch [3/100], Iter [3390/3426] Loss: 0.2207 Acc: 91 %\n",
      "Epoch [3/100], Iter [3400/3426] Loss: 0.2066 Acc: 91 %\n",
      "Epoch [3/100], Iter [3410/3426] Loss: 0.2157 Acc: 91 %\n",
      "Epoch [3/100], Iter [3420/3426] Loss: 0.2153 Acc: 91 %\n",
      "Accuracy of the model on the neg seq: 64 %\n",
      "Accuracy of the model on the pos seq: 99 %\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch [4/100], Iter [10/3426] Loss: 0.1906 Acc: 91 %\n",
      "Epoch [4/100], Iter [20/3426] Loss: 0.1865 Acc: 91 %\n",
      "Epoch [4/100], Iter [30/3426] Loss: 0.2019 Acc: 91 %\n",
      "Epoch [4/100], Iter [40/3426] Loss: 0.1969 Acc: 91 %\n",
      "Epoch [4/100], Iter [50/3426] Loss: 0.1994 Acc: 91 %\n",
      "Epoch [4/100], Iter [60/3426] Loss: 0.1997 Acc: 91 %\n",
      "Epoch [4/100], Iter [70/3426] Loss: 0.1976 Acc: 91 %\n",
      "Epoch [4/100], Iter [80/3426] Loss: 0.1925 Acc: 91 %\n",
      "Epoch [4/100], Iter [90/3426] Loss: 0.1964 Acc: 91 %\n",
      "Epoch [4/100], Iter [100/3426] Loss: 0.1860 Acc: 91 %\n",
      "Epoch [4/100], Iter [110/3426] Loss: 0.1791 Acc: 91 %\n",
      "Epoch [4/100], Iter [120/3426] Loss: 0.2231 Acc: 91 %\n",
      "Epoch [4/100], Iter [130/3426] Loss: 0.2157 Acc: 91 %\n",
      "Epoch [4/100], Iter [140/3426] Loss: 0.1739 Acc: 91 %\n",
      "Epoch [4/100], Iter [150/3426] Loss: 0.1807 Acc: 91 %\n",
      "Epoch [4/100], Iter [160/3426] Loss: 0.2163 Acc: 91 %\n",
      "Epoch [4/100], Iter [170/3426] Loss: 0.2099 Acc: 91 %\n",
      "Epoch [4/100], Iter [180/3426] Loss: 0.1854 Acc: 91 %\n",
      "Epoch [4/100], Iter [190/3426] Loss: 0.2213 Acc: 91 %\n",
      "Epoch [4/100], Iter [200/3426] Loss: 0.2156 Acc: 91 %\n",
      "Epoch [4/100], Iter [210/3426] Loss: 0.2470 Acc: 91 %\n",
      "Epoch [4/100], Iter [220/3426] Loss: 0.1666 Acc: 91 %\n",
      "Epoch [4/100], Iter [230/3426] Loss: 0.2015 Acc: 91 %\n",
      "Epoch [4/100], Iter [240/3426] Loss: 0.1877 Acc: 91 %\n",
      "Epoch [4/100], Iter [250/3426] Loss: 0.2044 Acc: 91 %\n",
      "Epoch [4/100], Iter [260/3426] Loss: 0.1818 Acc: 91 %\n",
      "Epoch [4/100], Iter [270/3426] Loss: 0.1994 Acc: 91 %\n",
      "Epoch [4/100], Iter [280/3426] Loss: 0.2285 Acc: 91 %\n",
      "Epoch [4/100], Iter [290/3426] Loss: 0.2266 Acc: 91 %\n",
      "Epoch [4/100], Iter [300/3426] Loss: 0.1772 Acc: 91 %\n",
      "Epoch [4/100], Iter [310/3426] Loss: 0.2027 Acc: 91 %\n",
      "Epoch [4/100], Iter [320/3426] Loss: 0.1877 Acc: 91 %\n",
      "Epoch [4/100], Iter [330/3426] Loss: 0.1844 Acc: 91 %\n",
      "Epoch [4/100], Iter [340/3426] Loss: 0.2162 Acc: 91 %\n",
      "Epoch [4/100], Iter [350/3426] Loss: 0.2050 Acc: 91 %\n",
      "Epoch [4/100], Iter [360/3426] Loss: 0.2008 Acc: 91 %\n",
      "Epoch [4/100], Iter [370/3426] Loss: 0.1951 Acc: 91 %\n",
      "Epoch [4/100], Iter [380/3426] Loss: 0.1850 Acc: 91 %\n",
      "Epoch [4/100], Iter [390/3426] Loss: 0.1784 Acc: 91 %\n",
      "Epoch [4/100], Iter [400/3426] Loss: 0.1977 Acc: 91 %\n",
      "Epoch [4/100], Iter [410/3426] Loss: 0.2031 Acc: 91 %\n",
      "Epoch [4/100], Iter [420/3426] Loss: 0.1967 Acc: 91 %\n",
      "Epoch [4/100], Iter [430/3426] Loss: 0.2552 Acc: 91 %\n",
      "Epoch [4/100], Iter [440/3426] Loss: 0.1887 Acc: 91 %\n",
      "Epoch [4/100], Iter [450/3426] Loss: 0.1994 Acc: 91 %\n",
      "Epoch [4/100], Iter [460/3426] Loss: 0.1980 Acc: 91 %\n",
      "Epoch [4/100], Iter [470/3426] Loss: 0.2138 Acc: 91 %\n",
      "Epoch [4/100], Iter [480/3426] Loss: 0.2037 Acc: 91 %\n",
      "Epoch [4/100], Iter [490/3426] Loss: 0.1843 Acc: 91 %\n",
      "Epoch [4/100], Iter [500/3426] Loss: 0.1795 Acc: 91 %\n",
      "Epoch [4/100], Iter [510/3426] Loss: 0.2032 Acc: 91 %\n",
      "Epoch [4/100], Iter [520/3426] Loss: 0.1898 Acc: 91 %\n",
      "Epoch [4/100], Iter [530/3426] Loss: 0.2032 Acc: 91 %\n",
      "Epoch [4/100], Iter [540/3426] Loss: 0.1789 Acc: 91 %\n",
      "Epoch [4/100], Iter [550/3426] Loss: 0.2030 Acc: 91 %\n",
      "Epoch [4/100], Iter [560/3426] Loss: 0.2207 Acc: 91 %\n",
      "Epoch [4/100], Iter [570/3426] Loss: 0.2131 Acc: 91 %\n",
      "Epoch [4/100], Iter [580/3426] Loss: 0.1921 Acc: 91 %\n",
      "Epoch [4/100], Iter [590/3426] Loss: 0.1428 Acc: 91 %\n",
      "Epoch [4/100], Iter [600/3426] Loss: 0.2553 Acc: 91 %\n",
      "Epoch [4/100], Iter [610/3426] Loss: 0.1829 Acc: 91 %\n",
      "Epoch [4/100], Iter [620/3426] Loss: 0.2221 Acc: 91 %\n",
      "Epoch [4/100], Iter [630/3426] Loss: 0.1877 Acc: 91 %\n",
      "Epoch [4/100], Iter [640/3426] Loss: 0.1875 Acc: 91 %\n",
      "Epoch [4/100], Iter [650/3426] Loss: 0.2187 Acc: 91 %\n",
      "Epoch [4/100], Iter [660/3426] Loss: 0.1950 Acc: 91 %\n",
      "Epoch [4/100], Iter [670/3426] Loss: 0.1999 Acc: 91 %\n",
      "Epoch [4/100], Iter [680/3426] Loss: 0.2129 Acc: 91 %\n",
      "Epoch [4/100], Iter [690/3426] Loss: 0.1731 Acc: 91 %\n",
      "Epoch [4/100], Iter [700/3426] Loss: 0.2015 Acc: 91 %\n",
      "Epoch [4/100], Iter [710/3426] Loss: 0.1827 Acc: 91 %\n",
      "Epoch [4/100], Iter [720/3426] Loss: 0.2164 Acc: 91 %\n",
      "Epoch [4/100], Iter [730/3426] Loss: 0.2203 Acc: 91 %\n",
      "Epoch [4/100], Iter [740/3426] Loss: 0.2352 Acc: 91 %\n",
      "Epoch [4/100], Iter [750/3426] Loss: 0.1774 Acc: 91 %\n",
      "Epoch [4/100], Iter [760/3426] Loss: 0.1947 Acc: 91 %\n",
      "Epoch [4/100], Iter [770/3426] Loss: 0.2153 Acc: 91 %\n",
      "Epoch [4/100], Iter [780/3426] Loss: 0.1955 Acc: 91 %\n",
      "Epoch [4/100], Iter [790/3426] Loss: 0.1763 Acc: 91 %\n",
      "Epoch [4/100], Iter [800/3426] Loss: 0.1934 Acc: 91 %\n",
      "Epoch [4/100], Iter [810/3426] Loss: 0.1750 Acc: 91 %\n",
      "Epoch [4/100], Iter [820/3426] Loss: 0.1885 Acc: 91 %\n",
      "Epoch [4/100], Iter [830/3426] Loss: 0.1922 Acc: 91 %\n",
      "Epoch [4/100], Iter [840/3426] Loss: 0.1844 Acc: 91 %\n",
      "Epoch [4/100], Iter [850/3426] Loss: 0.1843 Acc: 91 %\n",
      "Epoch [4/100], Iter [860/3426] Loss: 0.1889 Acc: 91 %\n",
      "Epoch [4/100], Iter [870/3426] Loss: 0.2397 Acc: 91 %\n",
      "Epoch [4/100], Iter [880/3426] Loss: 0.2023 Acc: 91 %\n",
      "Epoch [4/100], Iter [890/3426] Loss: 0.1986 Acc: 91 %\n",
      "Epoch [4/100], Iter [900/3426] Loss: 0.1934 Acc: 91 %\n",
      "Epoch [4/100], Iter [910/3426] Loss: 0.2195 Acc: 91 %\n",
      "Epoch [4/100], Iter [920/3426] Loss: 0.2457 Acc: 91 %\n",
      "Epoch [4/100], Iter [930/3426] Loss: 0.2195 Acc: 91 %\n",
      "Epoch [4/100], Iter [940/3426] Loss: 0.2010 Acc: 91 %\n",
      "Epoch [4/100], Iter [950/3426] Loss: 0.1808 Acc: 91 %\n",
      "Epoch [4/100], Iter [960/3426] Loss: 0.2139 Acc: 91 %\n",
      "Epoch [4/100], Iter [970/3426] Loss: 0.1762 Acc: 91 %\n",
      "Epoch [4/100], Iter [980/3426] Loss: 0.2149 Acc: 91 %\n",
      "Epoch [4/100], Iter [990/3426] Loss: 0.2318 Acc: 91 %\n",
      "Epoch [4/100], Iter [1000/3426] Loss: 0.1759 Acc: 91 %\n",
      "Epoch [4/100], Iter [1010/3426] Loss: 0.1647 Acc: 91 %\n",
      "Epoch [4/100], Iter [1020/3426] Loss: 0.1814 Acc: 91 %\n",
      "Epoch [4/100], Iter [1030/3426] Loss: 0.2216 Acc: 91 %\n",
      "Epoch [4/100], Iter [1040/3426] Loss: 0.2431 Acc: 91 %\n",
      "Epoch [4/100], Iter [1050/3426] Loss: 0.1712 Acc: 91 %\n",
      "Epoch [4/100], Iter [1060/3426] Loss: 0.1905 Acc: 91 %\n",
      "Epoch [4/100], Iter [1070/3426] Loss: 0.2004 Acc: 91 %\n",
      "Epoch [4/100], Iter [1080/3426] Loss: 0.1500 Acc: 91 %\n",
      "Epoch [4/100], Iter [1090/3426] Loss: 0.2122 Acc: 91 %\n",
      "Epoch [4/100], Iter [1100/3426] Loss: 0.1800 Acc: 91 %\n",
      "Epoch [4/100], Iter [1110/3426] Loss: 0.2023 Acc: 91 %\n",
      "Epoch [4/100], Iter [1120/3426] Loss: 0.3517 Acc: 91 %\n",
      "Epoch [4/100], Iter [1130/3426] Loss: 0.2670 Acc: 91 %\n",
      "Epoch [4/100], Iter [1140/3426] Loss: 0.2547 Acc: 91 %\n",
      "Epoch [4/100], Iter [1150/3426] Loss: 0.2185 Acc: 91 %\n",
      "Epoch [4/100], Iter [1160/3426] Loss: 0.2123 Acc: 91 %\n",
      "Epoch [4/100], Iter [1170/3426] Loss: 0.2299 Acc: 91 %\n",
      "Epoch [4/100], Iter [1180/3426] Loss: 0.1943 Acc: 91 %\n",
      "Epoch [4/100], Iter [1190/3426] Loss: 0.2021 Acc: 91 %\n",
      "Epoch [4/100], Iter [1200/3426] Loss: 0.1993 Acc: 91 %\n",
      "Epoch [4/100], Iter [1210/3426] Loss: 0.1646 Acc: 91 %\n",
      "Epoch [4/100], Iter [1220/3426] Loss: 0.2209 Acc: 91 %\n",
      "Epoch [4/100], Iter [1230/3426] Loss: 0.2085 Acc: 91 %\n",
      "Epoch [4/100], Iter [1240/3426] Loss: 0.2132 Acc: 91 %\n",
      "Epoch [4/100], Iter [1250/3426] Loss: 0.2009 Acc: 91 %\n",
      "Epoch [4/100], Iter [1260/3426] Loss: 0.1801 Acc: 91 %\n",
      "Epoch [4/100], Iter [1270/3426] Loss: 0.1799 Acc: 91 %\n",
      "Epoch [4/100], Iter [1280/3426] Loss: 0.2034 Acc: 91 %\n",
      "Epoch [4/100], Iter [1290/3426] Loss: 0.2181 Acc: 91 %\n",
      "Epoch [4/100], Iter [1300/3426] Loss: 0.1959 Acc: 91 %\n",
      "Epoch [4/100], Iter [1310/3426] Loss: 0.2269 Acc: 91 %\n",
      "Epoch [4/100], Iter [1320/3426] Loss: 0.1990 Acc: 91 %\n",
      "Epoch [4/100], Iter [1330/3426] Loss: 0.2424 Acc: 91 %\n",
      "Epoch [4/100], Iter [1340/3426] Loss: 0.1701 Acc: 91 %\n",
      "Epoch [4/100], Iter [1350/3426] Loss: 0.2091 Acc: 91 %\n",
      "Epoch [4/100], Iter [1360/3426] Loss: 0.1755 Acc: 91 %\n",
      "Epoch [4/100], Iter [1370/3426] Loss: 0.2040 Acc: 91 %\n",
      "Epoch [4/100], Iter [1380/3426] Loss: 0.1682 Acc: 91 %\n",
      "Epoch [4/100], Iter [1390/3426] Loss: 0.1972 Acc: 91 %\n",
      "Epoch [4/100], Iter [1400/3426] Loss: 0.1971 Acc: 91 %\n",
      "Epoch [4/100], Iter [1410/3426] Loss: 0.1935 Acc: 91 %\n",
      "Epoch [4/100], Iter [1420/3426] Loss: 0.1867 Acc: 91 %\n",
      "Epoch [4/100], Iter [1430/3426] Loss: 0.1641 Acc: 91 %\n",
      "Epoch [4/100], Iter [1440/3426] Loss: 0.2052 Acc: 91 %\n",
      "Epoch [4/100], Iter [1450/3426] Loss: 0.2447 Acc: 91 %\n",
      "Epoch [4/100], Iter [1460/3426] Loss: 0.1832 Acc: 91 %\n",
      "Epoch [4/100], Iter [1470/3426] Loss: 0.1967 Acc: 91 %\n",
      "Epoch [4/100], Iter [1480/3426] Loss: 0.2008 Acc: 91 %\n",
      "Epoch [4/100], Iter [1490/3426] Loss: 0.2003 Acc: 91 %\n",
      "Epoch [4/100], Iter [1500/3426] Loss: 0.1761 Acc: 91 %\n",
      "Epoch [4/100], Iter [1510/3426] Loss: 0.2063 Acc: 91 %\n",
      "Epoch [4/100], Iter [1520/3426] Loss: 0.1941 Acc: 91 %\n",
      "Epoch [4/100], Iter [1530/3426] Loss: 0.1976 Acc: 91 %\n",
      "Epoch [4/100], Iter [1540/3426] Loss: 0.1954 Acc: 91 %\n",
      "Epoch [4/100], Iter [1550/3426] Loss: 0.1832 Acc: 91 %\n",
      "Epoch [4/100], Iter [1560/3426] Loss: 0.2064 Acc: 91 %\n",
      "Epoch [4/100], Iter [1570/3426] Loss: 0.2132 Acc: 91 %\n",
      "Epoch [4/100], Iter [1580/3426] Loss: 0.2473 Acc: 91 %\n",
      "Epoch [4/100], Iter [1590/3426] Loss: 0.1807 Acc: 91 %\n",
      "Epoch [4/100], Iter [1600/3426] Loss: 0.1959 Acc: 91 %\n",
      "Epoch [4/100], Iter [1610/3426] Loss: 0.2049 Acc: 91 %\n",
      "Epoch [4/100], Iter [1620/3426] Loss: 0.1969 Acc: 91 %\n",
      "Epoch [4/100], Iter [1630/3426] Loss: 0.2341 Acc: 91 %\n",
      "Epoch [4/100], Iter [1640/3426] Loss: 0.2027 Acc: 91 %\n",
      "Epoch [4/100], Iter [1650/3426] Loss: 0.2012 Acc: 91 %\n",
      "Epoch [4/100], Iter [1660/3426] Loss: 0.2024 Acc: 91 %\n",
      "Epoch [4/100], Iter [1670/3426] Loss: 0.1768 Acc: 91 %\n",
      "Epoch [4/100], Iter [1680/3426] Loss: 0.1837 Acc: 91 %\n",
      "Epoch [4/100], Iter [1690/3426] Loss: 0.1788 Acc: 91 %\n",
      "Epoch [4/100], Iter [1700/3426] Loss: 0.1717 Acc: 91 %\n",
      "Epoch [4/100], Iter [1710/3426] Loss: 0.2298 Acc: 91 %\n",
      "Epoch [4/100], Iter [1720/3426] Loss: 0.2027 Acc: 91 %\n",
      "Epoch [4/100], Iter [1730/3426] Loss: 0.2217 Acc: 91 %\n",
      "Epoch [4/100], Iter [1740/3426] Loss: 0.1985 Acc: 91 %\n",
      "Epoch [4/100], Iter [1750/3426] Loss: 0.1997 Acc: 91 %\n",
      "Epoch [4/100], Iter [1760/3426] Loss: 0.2043 Acc: 91 %\n",
      "Epoch [4/100], Iter [1770/3426] Loss: 0.1864 Acc: 91 %\n",
      "Epoch [4/100], Iter [1780/3426] Loss: 0.1935 Acc: 91 %\n",
      "Epoch [4/100], Iter [1790/3426] Loss: 0.1857 Acc: 91 %\n",
      "Epoch [4/100], Iter [1800/3426] Loss: 0.1847 Acc: 91 %\n",
      "Epoch [4/100], Iter [1810/3426] Loss: 0.1877 Acc: 91 %\n",
      "Epoch [4/100], Iter [1820/3426] Loss: 0.1821 Acc: 91 %\n",
      "Epoch [4/100], Iter [1830/3426] Loss: 0.2021 Acc: 91 %\n",
      "Epoch [4/100], Iter [1840/3426] Loss: 0.2171 Acc: 91 %\n",
      "Epoch [4/100], Iter [1850/3426] Loss: 0.1753 Acc: 91 %\n",
      "Epoch [4/100], Iter [1860/3426] Loss: 0.2094 Acc: 91 %\n",
      "Epoch [4/100], Iter [1870/3426] Loss: 0.2338 Acc: 91 %\n",
      "Epoch [4/100], Iter [1880/3426] Loss: 0.1860 Acc: 91 %\n",
      "Epoch [4/100], Iter [1890/3426] Loss: 0.1893 Acc: 91 %\n",
      "Epoch [4/100], Iter [1900/3426] Loss: 0.1808 Acc: 91 %\n",
      "Epoch [4/100], Iter [1910/3426] Loss: 0.1818 Acc: 91 %\n",
      "Epoch [4/100], Iter [1920/3426] Loss: 0.2181 Acc: 91 %\n",
      "Epoch [4/100], Iter [1930/3426] Loss: 0.2255 Acc: 91 %\n",
      "Epoch [4/100], Iter [1940/3426] Loss: 0.1988 Acc: 91 %\n",
      "Epoch [4/100], Iter [1950/3426] Loss: 0.1969 Acc: 91 %\n",
      "Epoch [4/100], Iter [1960/3426] Loss: 0.1895 Acc: 91 %\n",
      "Epoch [4/100], Iter [1970/3426] Loss: 0.1857 Acc: 91 %\n",
      "Epoch [4/100], Iter [1980/3426] Loss: 0.1800 Acc: 91 %\n",
      "Epoch [4/100], Iter [1990/3426] Loss: 0.2040 Acc: 91 %\n",
      "Epoch [4/100], Iter [2000/3426] Loss: 0.2089 Acc: 91 %\n",
      "Epoch [4/100], Iter [2010/3426] Loss: 0.1917 Acc: 91 %\n",
      "Epoch [4/100], Iter [2020/3426] Loss: 0.1820 Acc: 91 %\n",
      "Epoch [4/100], Iter [2030/3426] Loss: 0.2181 Acc: 91 %\n",
      "Epoch [4/100], Iter [2040/3426] Loss: 0.1971 Acc: 91 %\n",
      "Epoch [4/100], Iter [2050/3426] Loss: 0.1915 Acc: 91 %\n",
      "Epoch [4/100], Iter [2060/3426] Loss: 0.1969 Acc: 91 %\n",
      "Epoch [4/100], Iter [2070/3426] Loss: 0.2099 Acc: 91 %\n",
      "Epoch [4/100], Iter [2080/3426] Loss: 0.1766 Acc: 91 %\n",
      "Epoch [4/100], Iter [2090/3426] Loss: 0.1738 Acc: 91 %\n",
      "Epoch [4/100], Iter [2100/3426] Loss: 0.2092 Acc: 91 %\n",
      "Epoch [4/100], Iter [2110/3426] Loss: 0.2114 Acc: 91 %\n",
      "Epoch [4/100], Iter [2120/3426] Loss: 0.2267 Acc: 91 %\n",
      "Epoch [4/100], Iter [2130/3426] Loss: 0.2674 Acc: 91 %\n",
      "Epoch [4/100], Iter [2140/3426] Loss: 0.2331 Acc: 91 %\n",
      "Epoch [4/100], Iter [2150/3426] Loss: 0.1995 Acc: 91 %\n",
      "Epoch [4/100], Iter [2160/3426] Loss: 0.2116 Acc: 91 %\n",
      "Epoch [4/100], Iter [2170/3426] Loss: 0.2151 Acc: 91 %\n",
      "Epoch [4/100], Iter [2180/3426] Loss: 0.2077 Acc: 91 %\n",
      "Epoch [4/100], Iter [2190/3426] Loss: 0.2220 Acc: 91 %\n",
      "Epoch [4/100], Iter [2200/3426] Loss: 0.1875 Acc: 91 %\n",
      "Epoch [4/100], Iter [2210/3426] Loss: 0.1682 Acc: 91 %\n",
      "Epoch [4/100], Iter [2220/3426] Loss: 0.1829 Acc: 91 %\n",
      "Epoch [4/100], Iter [2230/3426] Loss: 0.1552 Acc: 91 %\n",
      "Epoch [4/100], Iter [2240/3426] Loss: 0.1957 Acc: 91 %\n",
      "Epoch [4/100], Iter [2250/3426] Loss: 0.1723 Acc: 91 %\n",
      "Epoch [4/100], Iter [2260/3426] Loss: 0.2450 Acc: 91 %\n",
      "Epoch [4/100], Iter [2270/3426] Loss: 0.2000 Acc: 91 %\n",
      "Epoch [4/100], Iter [2280/3426] Loss: 0.2076 Acc: 91 %\n",
      "Epoch [4/100], Iter [2290/3426] Loss: 0.1921 Acc: 91 %\n",
      "Epoch [4/100], Iter [2300/3426] Loss: 0.2153 Acc: 91 %\n",
      "Epoch [4/100], Iter [2310/3426] Loss: 0.1928 Acc: 91 %\n",
      "Epoch [4/100], Iter [2320/3426] Loss: 0.2072 Acc: 91 %\n",
      "Epoch [4/100], Iter [2330/3426] Loss: 0.2167 Acc: 91 %\n",
      "Epoch [4/100], Iter [2340/3426] Loss: 0.1892 Acc: 91 %\n",
      "Epoch [4/100], Iter [2350/3426] Loss: 0.1905 Acc: 91 %\n",
      "Epoch [4/100], Iter [2360/3426] Loss: 0.2024 Acc: 91 %\n",
      "Epoch [4/100], Iter [2370/3426] Loss: 0.2102 Acc: 91 %\n",
      "Epoch [4/100], Iter [2380/3426] Loss: 0.2260 Acc: 91 %\n",
      "Epoch [4/100], Iter [2390/3426] Loss: 0.2038 Acc: 91 %\n",
      "Epoch [4/100], Iter [2400/3426] Loss: 0.2191 Acc: 91 %\n",
      "Epoch [4/100], Iter [2410/3426] Loss: 0.2119 Acc: 91 %\n",
      "Epoch [4/100], Iter [2420/3426] Loss: 0.2079 Acc: 91 %\n",
      "Epoch [4/100], Iter [2430/3426] Loss: 0.1899 Acc: 91 %\n",
      "Epoch [4/100], Iter [2440/3426] Loss: 0.1798 Acc: 91 %\n",
      "Epoch [4/100], Iter [2450/3426] Loss: 0.1967 Acc: 91 %\n",
      "Epoch [4/100], Iter [2460/3426] Loss: 0.1588 Acc: 91 %\n",
      "Epoch [4/100], Iter [2470/3426] Loss: 0.1988 Acc: 91 %\n",
      "Epoch [4/100], Iter [2480/3426] Loss: 0.1794 Acc: 91 %\n",
      "Epoch [4/100], Iter [2490/3426] Loss: 0.1927 Acc: 91 %\n",
      "Epoch [4/100], Iter [2500/3426] Loss: 0.1907 Acc: 91 %\n",
      "Epoch [4/100], Iter [2510/3426] Loss: 0.1830 Acc: 91 %\n",
      "Epoch [4/100], Iter [2520/3426] Loss: 0.2169 Acc: 91 %\n",
      "Epoch [4/100], Iter [2530/3426] Loss: 0.1810 Acc: 91 %\n",
      "Epoch [4/100], Iter [2540/3426] Loss: 0.2111 Acc: 91 %\n",
      "Epoch [4/100], Iter [2550/3426] Loss: 0.2060 Acc: 91 %\n",
      "Epoch [4/100], Iter [2560/3426] Loss: 0.1678 Acc: 91 %\n",
      "Epoch [4/100], Iter [2570/3426] Loss: 0.2275 Acc: 91 %\n",
      "Epoch [4/100], Iter [2580/3426] Loss: 0.1732 Acc: 91 %\n",
      "Epoch [4/100], Iter [2590/3426] Loss: 0.2252 Acc: 91 %\n",
      "Epoch [4/100], Iter [2600/3426] Loss: 0.1908 Acc: 91 %\n",
      "Epoch [4/100], Iter [2610/3426] Loss: 0.1882 Acc: 91 %\n",
      "Epoch [4/100], Iter [2620/3426] Loss: 0.1938 Acc: 91 %\n",
      "Epoch [4/100], Iter [2630/3426] Loss: 0.1679 Acc: 91 %\n",
      "Epoch [4/100], Iter [2640/3426] Loss: 0.1871 Acc: 91 %\n",
      "Epoch [4/100], Iter [2650/3426] Loss: 0.1811 Acc: 91 %\n",
      "Epoch [4/100], Iter [2660/3426] Loss: 0.1892 Acc: 91 %\n",
      "Epoch [4/100], Iter [2670/3426] Loss: 0.1810 Acc: 91 %\n",
      "Epoch [4/100], Iter [2680/3426] Loss: 0.2003 Acc: 91 %\n",
      "Epoch [4/100], Iter [2690/3426] Loss: 0.2083 Acc: 91 %\n",
      "Epoch [4/100], Iter [2700/3426] Loss: 0.2242 Acc: 91 %\n",
      "Epoch [4/100], Iter [2710/3426] Loss: 0.1938 Acc: 91 %\n",
      "Epoch [4/100], Iter [2720/3426] Loss: 0.2071 Acc: 91 %\n",
      "Epoch [4/100], Iter [2730/3426] Loss: 0.1902 Acc: 91 %\n",
      "Epoch [4/100], Iter [2740/3426] Loss: 0.1891 Acc: 91 %\n",
      "Epoch [4/100], Iter [2750/3426] Loss: 0.1941 Acc: 91 %\n",
      "Epoch [4/100], Iter [2760/3426] Loss: 0.2010 Acc: 91 %\n",
      "Epoch [4/100], Iter [2770/3426] Loss: 0.2136 Acc: 91 %\n",
      "Epoch [4/100], Iter [2780/3426] Loss: 0.1928 Acc: 91 %\n",
      "Epoch [4/100], Iter [2790/3426] Loss: 0.2124 Acc: 91 %\n",
      "Epoch [4/100], Iter [2800/3426] Loss: 0.1909 Acc: 91 %\n",
      "Epoch [4/100], Iter [2810/3426] Loss: 0.2114 Acc: 91 %\n",
      "Epoch [4/100], Iter [2820/3426] Loss: 0.1797 Acc: 91 %\n",
      "Epoch [4/100], Iter [2830/3426] Loss: 0.1725 Acc: 91 %\n",
      "Epoch [4/100], Iter [2840/3426] Loss: 0.2009 Acc: 91 %\n",
      "Epoch [4/100], Iter [2850/3426] Loss: 0.1883 Acc: 91 %\n",
      "Epoch [4/100], Iter [2860/3426] Loss: 0.2482 Acc: 91 %\n",
      "Epoch [4/100], Iter [2870/3426] Loss: 0.2169 Acc: 91 %\n",
      "Epoch [4/100], Iter [2880/3426] Loss: 0.2082 Acc: 91 %\n",
      "Epoch [4/100], Iter [2890/3426] Loss: 0.2155 Acc: 91 %\n",
      "Epoch [4/100], Iter [2900/3426] Loss: 0.2330 Acc: 91 %\n",
      "Epoch [4/100], Iter [2910/3426] Loss: 0.2057 Acc: 91 %\n",
      "Epoch [4/100], Iter [2920/3426] Loss: 0.1840 Acc: 91 %\n",
      "Epoch [4/100], Iter [2930/3426] Loss: 0.2000 Acc: 91 %\n",
      "Epoch [4/100], Iter [2940/3426] Loss: 0.2101 Acc: 91 %\n",
      "Epoch [4/100], Iter [2950/3426] Loss: 0.1892 Acc: 91 %\n",
      "Epoch [4/100], Iter [2960/3426] Loss: 0.1791 Acc: 91 %\n",
      "Epoch [4/100], Iter [2970/3426] Loss: 0.1881 Acc: 91 %\n",
      "Epoch [4/100], Iter [2980/3426] Loss: 0.1870 Acc: 91 %\n",
      "Epoch [4/100], Iter [2990/3426] Loss: 0.1819 Acc: 91 %\n",
      "Epoch [4/100], Iter [3000/3426] Loss: 0.1836 Acc: 91 %\n",
      "Epoch [4/100], Iter [3010/3426] Loss: 0.2062 Acc: 91 %\n",
      "Epoch [4/100], Iter [3020/3426] Loss: 0.2298 Acc: 91 %\n",
      "Epoch [4/100], Iter [3030/3426] Loss: 0.2287 Acc: 91 %\n",
      "Epoch [4/100], Iter [3040/3426] Loss: 0.1994 Acc: 91 %\n",
      "Epoch [4/100], Iter [3050/3426] Loss: 0.1811 Acc: 91 %\n",
      "Epoch [4/100], Iter [3060/3426] Loss: 0.1980 Acc: 91 %\n",
      "Epoch [4/100], Iter [3070/3426] Loss: 0.1866 Acc: 91 %\n",
      "Epoch [4/100], Iter [3080/3426] Loss: 0.1932 Acc: 91 %\n",
      "Epoch [4/100], Iter [3090/3426] Loss: 0.1883 Acc: 91 %\n",
      "Epoch [4/100], Iter [3100/3426] Loss: 0.1765 Acc: 91 %\n",
      "Epoch [4/100], Iter [3110/3426] Loss: 0.1902 Acc: 91 %\n",
      "Epoch [4/100], Iter [3120/3426] Loss: 0.1961 Acc: 91 %\n",
      "Epoch [4/100], Iter [3130/3426] Loss: 0.1941 Acc: 91 %\n",
      "Epoch [4/100], Iter [3140/3426] Loss: 0.1465 Acc: 91 %\n",
      "Epoch [4/100], Iter [3150/3426] Loss: 0.1882 Acc: 91 %\n",
      "Epoch [4/100], Iter [3160/3426] Loss: 0.2313 Acc: 91 %\n",
      "Epoch [4/100], Iter [3170/3426] Loss: 0.1886 Acc: 91 %\n",
      "Epoch [4/100], Iter [3180/3426] Loss: 0.2120 Acc: 91 %\n",
      "Epoch [4/100], Iter [3190/3426] Loss: 0.1803 Acc: 91 %\n",
      "Epoch [4/100], Iter [3200/3426] Loss: 0.1770 Acc: 91 %\n",
      "Epoch [4/100], Iter [3210/3426] Loss: 0.2484 Acc: 91 %\n",
      "Epoch [4/100], Iter [3220/3426] Loss: 0.1902 Acc: 91 %\n",
      "Epoch [4/100], Iter [3230/3426] Loss: 0.1763 Acc: 91 %\n",
      "Epoch [4/100], Iter [3240/3426] Loss: 0.1981 Acc: 91 %\n",
      "Epoch [4/100], Iter [3250/3426] Loss: 0.1889 Acc: 91 %\n",
      "Epoch [4/100], Iter [3260/3426] Loss: 0.1957 Acc: 91 %\n",
      "Epoch [4/100], Iter [3270/3426] Loss: 0.2024 Acc: 91 %\n",
      "Epoch [4/100], Iter [3280/3426] Loss: 0.1788 Acc: 91 %\n",
      "Epoch [4/100], Iter [3290/3426] Loss: 0.2027 Acc: 91 %\n",
      "Epoch [4/100], Iter [3300/3426] Loss: 0.1959 Acc: 91 %\n",
      "Epoch [4/100], Iter [3310/3426] Loss: 0.1918 Acc: 91 %\n",
      "Epoch [4/100], Iter [3320/3426] Loss: 0.2093 Acc: 91 %\n",
      "Epoch [4/100], Iter [3330/3426] Loss: 0.1847 Acc: 91 %\n",
      "Epoch [4/100], Iter [3340/3426] Loss: 0.1918 Acc: 91 %\n",
      "Epoch [4/100], Iter [3350/3426] Loss: 0.2017 Acc: 91 %\n",
      "Epoch [4/100], Iter [3360/3426] Loss: 0.1957 Acc: 91 %\n",
      "Epoch [4/100], Iter [3370/3426] Loss: 0.1588 Acc: 91 %\n",
      "Epoch [4/100], Iter [3380/3426] Loss: 0.1933 Acc: 91 %\n",
      "Epoch [4/100], Iter [3390/3426] Loss: 0.1983 Acc: 91 %\n",
      "Epoch [4/100], Iter [3400/3426] Loss: 0.1944 Acc: 91 %\n",
      "Epoch [4/100], Iter [3410/3426] Loss: 0.1706 Acc: 91 %\n",
      "Epoch [4/100], Iter [3420/3426] Loss: 0.1922 Acc: 91 %\n",
      "Accuracy of the model on the neg seq: 62 %\n",
      "Accuracy of the model on the pos seq: 99 %\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch [5/100], Iter [10/3426] Loss: 0.2142 Acc: 91 %\n",
      "Epoch [5/100], Iter [20/3426] Loss: 0.1891 Acc: 91 %\n",
      "Epoch [5/100], Iter [30/3426] Loss: 0.2138 Acc: 91 %\n",
      "Epoch [5/100], Iter [40/3426] Loss: 0.2255 Acc: 91 %\n",
      "Epoch [5/100], Iter [50/3426] Loss: 0.1666 Acc: 91 %\n",
      "Epoch [5/100], Iter [60/3426] Loss: 0.1994 Acc: 91 %\n",
      "Epoch [5/100], Iter [70/3426] Loss: 0.1747 Acc: 91 %\n",
      "Epoch [5/100], Iter [80/3426] Loss: 0.1712 Acc: 91 %\n",
      "Epoch [5/100], Iter [90/3426] Loss: 0.1988 Acc: 91 %\n",
      "Epoch [5/100], Iter [100/3426] Loss: 0.1881 Acc: 91 %\n",
      "Epoch [5/100], Iter [110/3426] Loss: 0.1956 Acc: 91 %\n",
      "Epoch [5/100], Iter [120/3426] Loss: 0.1810 Acc: 91 %\n",
      "Epoch [5/100], Iter [130/3426] Loss: 0.1990 Acc: 91 %\n",
      "Epoch [5/100], Iter [140/3426] Loss: 0.1931 Acc: 91 %\n",
      "Epoch [5/100], Iter [150/3426] Loss: 0.1551 Acc: 91 %\n",
      "Epoch [5/100], Iter [160/3426] Loss: 0.2053 Acc: 91 %\n",
      "Epoch [5/100], Iter [170/3426] Loss: 0.1636 Acc: 91 %\n",
      "Epoch [5/100], Iter [180/3426] Loss: 0.1905 Acc: 91 %\n",
      "Epoch [5/100], Iter [190/3426] Loss: 0.1889 Acc: 91 %\n",
      "Epoch [5/100], Iter [200/3426] Loss: 0.1908 Acc: 91 %\n",
      "Epoch [5/100], Iter [210/3426] Loss: 0.1960 Acc: 91 %\n",
      "Epoch [5/100], Iter [220/3426] Loss: 0.1880 Acc: 91 %\n",
      "Epoch [5/100], Iter [230/3426] Loss: 0.2144 Acc: 91 %\n",
      "Epoch [5/100], Iter [240/3426] Loss: 0.2050 Acc: 91 %\n",
      "Epoch [5/100], Iter [250/3426] Loss: 0.1896 Acc: 91 %\n",
      "Epoch [5/100], Iter [260/3426] Loss: 0.1693 Acc: 91 %\n",
      "Epoch [5/100], Iter [270/3426] Loss: 0.2115 Acc: 91 %\n",
      "Epoch [5/100], Iter [280/3426] Loss: 0.1825 Acc: 91 %\n",
      "Epoch [5/100], Iter [290/3426] Loss: 0.1918 Acc: 91 %\n",
      "Epoch [5/100], Iter [300/3426] Loss: 0.1742 Acc: 91 %\n",
      "Epoch [5/100], Iter [310/3426] Loss: 0.2077 Acc: 91 %\n",
      "Epoch [5/100], Iter [320/3426] Loss: 0.1710 Acc: 91 %\n",
      "Epoch [5/100], Iter [330/3426] Loss: 0.2385 Acc: 91 %\n",
      "Epoch [5/100], Iter [340/3426] Loss: 0.2271 Acc: 91 %\n",
      "Epoch [5/100], Iter [350/3426] Loss: 0.1810 Acc: 91 %\n",
      "Epoch [5/100], Iter [360/3426] Loss: 0.1823 Acc: 91 %\n",
      "Epoch [5/100], Iter [370/3426] Loss: 0.2171 Acc: 91 %\n",
      "Epoch [5/100], Iter [380/3426] Loss: 0.1717 Acc: 91 %\n",
      "Epoch [5/100], Iter [390/3426] Loss: 0.2126 Acc: 91 %\n",
      "Epoch [5/100], Iter [400/3426] Loss: 0.1891 Acc: 91 %\n",
      "Epoch [5/100], Iter [410/3426] Loss: 0.1900 Acc: 91 %\n",
      "Epoch [5/100], Iter [420/3426] Loss: 0.1948 Acc: 91 %\n",
      "Epoch [5/100], Iter [430/3426] Loss: 0.1578 Acc: 91 %\n",
      "Epoch [5/100], Iter [440/3426] Loss: 0.1898 Acc: 91 %\n",
      "Epoch [5/100], Iter [450/3426] Loss: 0.2009 Acc: 91 %\n",
      "Epoch [5/100], Iter [460/3426] Loss: 0.2162 Acc: 91 %\n",
      "Epoch [5/100], Iter [470/3426] Loss: 0.2096 Acc: 91 %\n",
      "Epoch [5/100], Iter [480/3426] Loss: 0.2032 Acc: 91 %\n",
      "Epoch [5/100], Iter [490/3426] Loss: 0.1753 Acc: 91 %\n",
      "Epoch [5/100], Iter [500/3426] Loss: 0.1651 Acc: 91 %\n",
      "Epoch [5/100], Iter [510/3426] Loss: 0.1689 Acc: 91 %\n",
      "Epoch [5/100], Iter [520/3426] Loss: 0.1892 Acc: 91 %\n",
      "Epoch [5/100], Iter [530/3426] Loss: 0.1825 Acc: 91 %\n",
      "Epoch [5/100], Iter [540/3426] Loss: 0.2030 Acc: 91 %\n",
      "Epoch [5/100], Iter [550/3426] Loss: 0.1885 Acc: 91 %\n",
      "Epoch [5/100], Iter [560/3426] Loss: 0.1858 Acc: 91 %\n",
      "Epoch [5/100], Iter [570/3426] Loss: 0.2054 Acc: 91 %\n",
      "Epoch [5/100], Iter [580/3426] Loss: 0.2034 Acc: 91 %\n",
      "Epoch [5/100], Iter [590/3426] Loss: 0.1697 Acc: 91 %\n",
      "Epoch [5/100], Iter [600/3426] Loss: 0.2132 Acc: 91 %\n",
      "Epoch [5/100], Iter [610/3426] Loss: 0.1750 Acc: 91 %\n",
      "Epoch [5/100], Iter [620/3426] Loss: 0.1948 Acc: 91 %\n",
      "Epoch [5/100], Iter [630/3426] Loss: 0.1968 Acc: 91 %\n",
      "Epoch [5/100], Iter [640/3426] Loss: 0.2006 Acc: 91 %\n",
      "Epoch [5/100], Iter [650/3426] Loss: 0.1893 Acc: 91 %\n",
      "Epoch [5/100], Iter [660/3426] Loss: 0.1920 Acc: 91 %\n",
      "Epoch [5/100], Iter [670/3426] Loss: 0.1923 Acc: 91 %\n",
      "Epoch [5/100], Iter [680/3426] Loss: 0.1635 Acc: 91 %\n",
      "Epoch [5/100], Iter [690/3426] Loss: 0.1806 Acc: 91 %\n",
      "Epoch [5/100], Iter [700/3426] Loss: 0.1897 Acc: 91 %\n",
      "Epoch [5/100], Iter [710/3426] Loss: 0.1813 Acc: 91 %\n",
      "Epoch [5/100], Iter [720/3426] Loss: 0.2222 Acc: 91 %\n",
      "Epoch [5/100], Iter [730/3426] Loss: 0.2006 Acc: 91 %\n",
      "Epoch [5/100], Iter [740/3426] Loss: 0.2094 Acc: 91 %\n",
      "Epoch [5/100], Iter [750/3426] Loss: 0.2011 Acc: 91 %\n",
      "Epoch [5/100], Iter [760/3426] Loss: 0.1999 Acc: 91 %\n",
      "Epoch [5/100], Iter [770/3426] Loss: 0.2003 Acc: 91 %\n",
      "Epoch [5/100], Iter [780/3426] Loss: 0.2114 Acc: 91 %\n",
      "Epoch [5/100], Iter [790/3426] Loss: 0.2029 Acc: 91 %\n",
      "Epoch [5/100], Iter [800/3426] Loss: 0.1995 Acc: 91 %\n",
      "Epoch [5/100], Iter [810/3426] Loss: 0.1917 Acc: 91 %\n",
      "Epoch [5/100], Iter [820/3426] Loss: 0.1827 Acc: 91 %\n",
      "Epoch [5/100], Iter [830/3426] Loss: 0.2084 Acc: 91 %\n",
      "Epoch [5/100], Iter [840/3426] Loss: 0.2054 Acc: 91 %\n",
      "Epoch [5/100], Iter [850/3426] Loss: 0.1860 Acc: 91 %\n",
      "Epoch [5/100], Iter [860/3426] Loss: 0.1775 Acc: 91 %\n",
      "Epoch [5/100], Iter [870/3426] Loss: 0.1894 Acc: 91 %\n",
      "Epoch [5/100], Iter [880/3426] Loss: 0.1932 Acc: 91 %\n",
      "Epoch [5/100], Iter [890/3426] Loss: 0.2217 Acc: 91 %\n",
      "Epoch [5/100], Iter [900/3426] Loss: 0.2118 Acc: 91 %\n",
      "Epoch [5/100], Iter [910/3426] Loss: 0.2216 Acc: 91 %\n",
      "Epoch [5/100], Iter [920/3426] Loss: 0.1957 Acc: 91 %\n",
      "Epoch [5/100], Iter [930/3426] Loss: 0.1937 Acc: 91 %\n",
      "Epoch [5/100], Iter [940/3426] Loss: 0.2246 Acc: 91 %\n",
      "Epoch [5/100], Iter [950/3426] Loss: 0.1975 Acc: 91 %\n",
      "Epoch [5/100], Iter [960/3426] Loss: 0.2213 Acc: 91 %\n",
      "Epoch [5/100], Iter [970/3426] Loss: 0.1805 Acc: 91 %\n",
      "Epoch [5/100], Iter [980/3426] Loss: 0.1663 Acc: 91 %\n",
      "Epoch [5/100], Iter [990/3426] Loss: 0.1637 Acc: 91 %\n",
      "Epoch [5/100], Iter [1000/3426] Loss: 0.1731 Acc: 91 %\n",
      "Epoch [5/100], Iter [1010/3426] Loss: 0.1877 Acc: 91 %\n",
      "Epoch [5/100], Iter [1020/3426] Loss: 0.2020 Acc: 91 %\n",
      "Epoch [5/100], Iter [1030/3426] Loss: 0.1868 Acc: 91 %\n",
      "Epoch [5/100], Iter [1040/3426] Loss: 0.1754 Acc: 91 %\n",
      "Epoch [5/100], Iter [1050/3426] Loss: 0.2068 Acc: 91 %\n",
      "Epoch [5/100], Iter [1060/3426] Loss: 0.2016 Acc: 91 %\n",
      "Epoch [5/100], Iter [1070/3426] Loss: 0.1951 Acc: 91 %\n",
      "Epoch [5/100], Iter [1080/3426] Loss: 0.2192 Acc: 91 %\n",
      "Epoch [5/100], Iter [1090/3426] Loss: 0.1564 Acc: 91 %\n",
      "Epoch [5/100], Iter [1100/3426] Loss: 0.2234 Acc: 91 %\n",
      "Epoch [5/100], Iter [1110/3426] Loss: 0.1773 Acc: 91 %\n",
      "Epoch [5/100], Iter [1120/3426] Loss: 0.2074 Acc: 91 %\n",
      "Epoch [5/100], Iter [1130/3426] Loss: 0.1852 Acc: 91 %\n",
      "Epoch [5/100], Iter [1140/3426] Loss: 0.1927 Acc: 91 %\n",
      "Epoch [5/100], Iter [1150/3426] Loss: 0.1508 Acc: 91 %\n",
      "Epoch [5/100], Iter [1160/3426] Loss: 0.1706 Acc: 91 %\n",
      "Epoch [5/100], Iter [1170/3426] Loss: 0.1955 Acc: 91 %\n",
      "Epoch [5/100], Iter [1180/3426] Loss: 0.1750 Acc: 91 %\n",
      "Epoch [5/100], Iter [1190/3426] Loss: 0.1752 Acc: 91 %\n",
      "Epoch [5/100], Iter [1200/3426] Loss: 0.2227 Acc: 91 %\n",
      "Epoch [5/100], Iter [1210/3426] Loss: 0.1898 Acc: 91 %\n",
      "Epoch [5/100], Iter [1220/3426] Loss: 0.1847 Acc: 91 %\n",
      "Epoch [5/100], Iter [1230/3426] Loss: 0.1780 Acc: 91 %\n",
      "Epoch [5/100], Iter [1240/3426] Loss: 0.1630 Acc: 92 %\n",
      "Epoch [5/100], Iter [1250/3426] Loss: 0.2138 Acc: 92 %\n",
      "Epoch [5/100], Iter [1260/3426] Loss: 0.2165 Acc: 91 %\n",
      "Epoch [5/100], Iter [1270/3426] Loss: 0.2198 Acc: 91 %\n",
      "Epoch [5/100], Iter [1280/3426] Loss: 0.1854 Acc: 91 %\n",
      "Epoch [5/100], Iter [1290/3426] Loss: 0.2014 Acc: 91 %\n",
      "Epoch [5/100], Iter [1300/3426] Loss: 0.1877 Acc: 91 %\n",
      "Epoch [5/100], Iter [1310/3426] Loss: 0.2053 Acc: 91 %\n",
      "Epoch [5/100], Iter [1320/3426] Loss: 0.1602 Acc: 92 %\n",
      "Epoch [5/100], Iter [1330/3426] Loss: 0.1806 Acc: 92 %\n",
      "Epoch [5/100], Iter [1340/3426] Loss: 0.1870 Acc: 92 %\n",
      "Epoch [5/100], Iter [1350/3426] Loss: 0.1842 Acc: 92 %\n",
      "Epoch [5/100], Iter [1360/3426] Loss: 0.2023 Acc: 92 %\n",
      "Epoch [5/100], Iter [1370/3426] Loss: 0.1981 Acc: 92 %\n",
      "Epoch [5/100], Iter [1380/3426] Loss: 0.2105 Acc: 92 %\n",
      "Epoch [5/100], Iter [1390/3426] Loss: 0.2348 Acc: 92 %\n",
      "Epoch [5/100], Iter [1400/3426] Loss: 0.1862 Acc: 92 %\n",
      "Epoch [5/100], Iter [1410/3426] Loss: 0.2232 Acc: 92 %\n",
      "Epoch [5/100], Iter [1420/3426] Loss: 0.2142 Acc: 92 %\n",
      "Epoch [5/100], Iter [1430/3426] Loss: 0.1994 Acc: 92 %\n",
      "Epoch [5/100], Iter [1440/3426] Loss: 0.2054 Acc: 91 %\n",
      "Epoch [5/100], Iter [1450/3426] Loss: 0.1920 Acc: 91 %\n",
      "Epoch [5/100], Iter [1460/3426] Loss: 0.2024 Acc: 91 %\n",
      "Epoch [5/100], Iter [1470/3426] Loss: 0.1618 Acc: 91 %\n",
      "Epoch [5/100], Iter [1480/3426] Loss: 0.2141 Acc: 91 %\n",
      "Epoch [5/100], Iter [1490/3426] Loss: 0.2157 Acc: 91 %\n",
      "Epoch [5/100], Iter [1500/3426] Loss: 0.2133 Acc: 91 %\n",
      "Epoch [5/100], Iter [1510/3426] Loss: 0.2043 Acc: 91 %\n",
      "Epoch [5/100], Iter [1520/3426] Loss: 0.2199 Acc: 91 %\n",
      "Epoch [5/100], Iter [1530/3426] Loss: 0.5574 Acc: 91 %\n",
      "Epoch [5/100], Iter [1540/3426] Loss: 0.1820 Acc: 91 %\n",
      "Epoch [5/100], Iter [1550/3426] Loss: 0.2224 Acc: 91 %\n",
      "Epoch [5/100], Iter [1560/3426] Loss: 0.2101 Acc: 91 %\n",
      "Epoch [5/100], Iter [1570/3426] Loss: 0.2127 Acc: 91 %\n",
      "Epoch [5/100], Iter [1580/3426] Loss: 0.1938 Acc: 91 %\n",
      "Epoch [5/100], Iter [1590/3426] Loss: 0.1790 Acc: 91 %\n",
      "Epoch [5/100], Iter [1600/3426] Loss: 0.1980 Acc: 91 %\n",
      "Epoch [5/100], Iter [1610/3426] Loss: 0.1945 Acc: 91 %\n",
      "Epoch [5/100], Iter [1620/3426] Loss: 0.1909 Acc: 91 %\n",
      "Epoch [5/100], Iter [1630/3426] Loss: 0.2104 Acc: 91 %\n",
      "Epoch [5/100], Iter [1640/3426] Loss: 0.1949 Acc: 91 %\n",
      "Epoch [5/100], Iter [1650/3426] Loss: 0.1797 Acc: 91 %\n",
      "Epoch [5/100], Iter [1660/3426] Loss: 0.1911 Acc: 91 %\n",
      "Epoch [5/100], Iter [1670/3426] Loss: 0.1907 Acc: 91 %\n",
      "Epoch [5/100], Iter [1680/3426] Loss: 0.1581 Acc: 91 %\n",
      "Epoch [5/100], Iter [1690/3426] Loss: 0.1937 Acc: 91 %\n",
      "Epoch [5/100], Iter [1700/3426] Loss: 0.1766 Acc: 91 %\n",
      "Epoch [5/100], Iter [1710/3426] Loss: 0.1873 Acc: 91 %\n",
      "Epoch [5/100], Iter [1720/3426] Loss: 0.1805 Acc: 91 %\n",
      "Epoch [5/100], Iter [1730/3426] Loss: 0.1865 Acc: 91 %\n",
      "Epoch [5/100], Iter [1740/3426] Loss: 0.1579 Acc: 91 %\n",
      "Epoch [5/100], Iter [1750/3426] Loss: 0.1985 Acc: 91 %\n",
      "Epoch [5/100], Iter [1760/3426] Loss: 0.1821 Acc: 91 %\n",
      "Epoch [5/100], Iter [1770/3426] Loss: 0.2132 Acc: 91 %\n",
      "Epoch [5/100], Iter [1780/3426] Loss: 0.2305 Acc: 91 %\n",
      "Epoch [5/100], Iter [1790/3426] Loss: 0.1763 Acc: 91 %\n",
      "Epoch [5/100], Iter [1800/3426] Loss: 0.2172 Acc: 91 %\n",
      "Epoch [5/100], Iter [1810/3426] Loss: 0.1751 Acc: 91 %\n",
      "Epoch [5/100], Iter [1820/3426] Loss: 0.2064 Acc: 91 %\n",
      "Epoch [5/100], Iter [1830/3426] Loss: 0.1826 Acc: 91 %\n",
      "Epoch [5/100], Iter [1840/3426] Loss: 0.1587 Acc: 91 %\n",
      "Epoch [5/100], Iter [1850/3426] Loss: 0.2217 Acc: 91 %\n",
      "Epoch [5/100], Iter [1860/3426] Loss: 0.1989 Acc: 91 %\n",
      "Epoch [5/100], Iter [1870/3426] Loss: 0.1743 Acc: 91 %\n",
      "Epoch [5/100], Iter [1880/3426] Loss: 0.1987 Acc: 91 %\n",
      "Epoch [5/100], Iter [1890/3426] Loss: 0.2190 Acc: 91 %\n",
      "Epoch [5/100], Iter [1900/3426] Loss: 0.1888 Acc: 91 %\n",
      "Epoch [5/100], Iter [1910/3426] Loss: 0.2055 Acc: 91 %\n",
      "Epoch [5/100], Iter [1920/3426] Loss: 0.1971 Acc: 91 %\n",
      "Epoch [5/100], Iter [1930/3426] Loss: 0.2050 Acc: 91 %\n",
      "Epoch [5/100], Iter [1940/3426] Loss: 0.2007 Acc: 91 %\n",
      "Epoch [5/100], Iter [1950/3426] Loss: 0.1686 Acc: 91 %\n",
      "Epoch [5/100], Iter [1960/3426] Loss: 0.1976 Acc: 91 %\n",
      "Epoch [5/100], Iter [1970/3426] Loss: 0.2023 Acc: 91 %\n",
      "Epoch [5/100], Iter [1980/3426] Loss: 0.1723 Acc: 91 %\n",
      "Epoch [5/100], Iter [1990/3426] Loss: 0.1586 Acc: 91 %\n",
      "Epoch [5/100], Iter [2000/3426] Loss: 0.2013 Acc: 91 %\n",
      "Epoch [5/100], Iter [2010/3426] Loss: 0.2076 Acc: 91 %\n",
      "Epoch [5/100], Iter [2020/3426] Loss: 0.2162 Acc: 91 %\n",
      "Epoch [5/100], Iter [2030/3426] Loss: 0.1734 Acc: 91 %\n",
      "Epoch [5/100], Iter [2040/3426] Loss: 0.2301 Acc: 91 %\n",
      "Epoch [5/100], Iter [2050/3426] Loss: 0.2278 Acc: 91 %\n",
      "Epoch [5/100], Iter [2060/3426] Loss: 0.1601 Acc: 91 %\n",
      "Epoch [5/100], Iter [2070/3426] Loss: 0.1994 Acc: 91 %\n",
      "Epoch [5/100], Iter [2080/3426] Loss: 0.2042 Acc: 91 %\n",
      "Epoch [5/100], Iter [2090/3426] Loss: 0.2186 Acc: 91 %\n",
      "Epoch [5/100], Iter [2100/3426] Loss: 0.1953 Acc: 91 %\n",
      "Epoch [5/100], Iter [2110/3426] Loss: 0.1877 Acc: 91 %\n",
      "Epoch [5/100], Iter [2120/3426] Loss: 0.2141 Acc: 91 %\n",
      "Epoch [5/100], Iter [2130/3426] Loss: 0.2009 Acc: 91 %\n",
      "Epoch [5/100], Iter [2140/3426] Loss: 0.1947 Acc: 91 %\n",
      "Epoch [5/100], Iter [2150/3426] Loss: 0.2017 Acc: 91 %\n",
      "Epoch [5/100], Iter [2160/3426] Loss: 0.1822 Acc: 91 %\n",
      "Epoch [5/100], Iter [2170/3426] Loss: 0.2202 Acc: 91 %\n",
      "Epoch [5/100], Iter [2180/3426] Loss: 0.1799 Acc: 91 %\n",
      "Epoch [5/100], Iter [2190/3426] Loss: 0.2017 Acc: 91 %\n",
      "Epoch [5/100], Iter [2200/3426] Loss: 0.2033 Acc: 91 %\n",
      "Epoch [5/100], Iter [2210/3426] Loss: 0.1924 Acc: 91 %\n",
      "Epoch [5/100], Iter [2220/3426] Loss: 0.1940 Acc: 91 %\n",
      "Epoch [5/100], Iter [2230/3426] Loss: 0.1862 Acc: 91 %\n",
      "Epoch [5/100], Iter [2240/3426] Loss: 0.1699 Acc: 91 %\n",
      "Epoch [5/100], Iter [2250/3426] Loss: 0.1971 Acc: 91 %\n",
      "Epoch [5/100], Iter [2260/3426] Loss: 0.1954 Acc: 91 %\n",
      "Epoch [5/100], Iter [2270/3426] Loss: 0.1779 Acc: 91 %\n",
      "Epoch [5/100], Iter [2280/3426] Loss: 0.1935 Acc: 91 %\n",
      "Epoch [5/100], Iter [2290/3426] Loss: 0.1910 Acc: 91 %\n",
      "Epoch [5/100], Iter [2300/3426] Loss: 0.2042 Acc: 91 %\n",
      "Epoch [5/100], Iter [2310/3426] Loss: 0.1911 Acc: 91 %\n",
      "Epoch [5/100], Iter [2320/3426] Loss: 0.1862 Acc: 91 %\n",
      "Epoch [5/100], Iter [2330/3426] Loss: 0.2003 Acc: 91 %\n",
      "Epoch [5/100], Iter [2340/3426] Loss: 0.1836 Acc: 92 %\n",
      "Epoch [5/100], Iter [2350/3426] Loss: 0.2018 Acc: 91 %\n",
      "Epoch [5/100], Iter [2360/3426] Loss: 0.1821 Acc: 91 %\n",
      "Epoch [5/100], Iter [2370/3426] Loss: 0.2210 Acc: 91 %\n",
      "Epoch [5/100], Iter [2380/3426] Loss: 0.1931 Acc: 91 %\n",
      "Epoch [5/100], Iter [2390/3426] Loss: 0.1894 Acc: 92 %\n",
      "Epoch [5/100], Iter [2400/3426] Loss: 0.1804 Acc: 92 %\n",
      "Epoch [5/100], Iter [2410/3426] Loss: 0.1904 Acc: 92 %\n",
      "Epoch [5/100], Iter [2420/3426] Loss: 0.1887 Acc: 92 %\n",
      "Epoch [5/100], Iter [2430/3426] Loss: 0.1901 Acc: 92 %\n",
      "Epoch [5/100], Iter [2440/3426] Loss: 0.2007 Acc: 92 %\n",
      "Epoch [5/100], Iter [2450/3426] Loss: 0.1995 Acc: 92 %\n",
      "Epoch [5/100], Iter [2460/3426] Loss: 0.1827 Acc: 92 %\n",
      "Epoch [5/100], Iter [2470/3426] Loss: 0.2069 Acc: 92 %\n",
      "Epoch [5/100], Iter [2480/3426] Loss: 0.1890 Acc: 92 %\n",
      "Epoch [5/100], Iter [2490/3426] Loss: 0.1522 Acc: 92 %\n",
      "Epoch [5/100], Iter [2500/3426] Loss: 0.1888 Acc: 92 %\n",
      "Epoch [5/100], Iter [2510/3426] Loss: 0.2106 Acc: 92 %\n",
      "Epoch [5/100], Iter [2520/3426] Loss: 0.1912 Acc: 92 %\n",
      "Epoch [5/100], Iter [2530/3426] Loss: 0.1702 Acc: 92 %\n",
      "Epoch [5/100], Iter [2540/3426] Loss: 0.2011 Acc: 92 %\n",
      "Epoch [5/100], Iter [2550/3426] Loss: 0.1831 Acc: 92 %\n",
      "Epoch [5/100], Iter [2560/3426] Loss: 0.1992 Acc: 92 %\n",
      "Epoch [5/100], Iter [2570/3426] Loss: 0.2003 Acc: 92 %\n",
      "Epoch [5/100], Iter [2580/3426] Loss: 0.1849 Acc: 92 %\n",
      "Epoch [5/100], Iter [2590/3426] Loss: 0.2041 Acc: 92 %\n",
      "Epoch [5/100], Iter [2600/3426] Loss: 0.1825 Acc: 92 %\n",
      "Epoch [5/100], Iter [2610/3426] Loss: 0.1707 Acc: 92 %\n",
      "Epoch [5/100], Iter [2620/3426] Loss: 0.2062 Acc: 92 %\n",
      "Epoch [5/100], Iter [2630/3426] Loss: 0.2372 Acc: 92 %\n",
      "Epoch [5/100], Iter [2640/3426] Loss: 0.2173 Acc: 92 %\n",
      "Epoch [5/100], Iter [2650/3426] Loss: 0.1766 Acc: 92 %\n",
      "Epoch [5/100], Iter [2660/3426] Loss: 0.1983 Acc: 92 %\n",
      "Epoch [5/100], Iter [2670/3426] Loss: 0.1806 Acc: 92 %\n",
      "Epoch [5/100], Iter [2680/3426] Loss: 0.2200 Acc: 92 %\n",
      "Epoch [5/100], Iter [2690/3426] Loss: 0.1900 Acc: 92 %\n",
      "Epoch [5/100], Iter [2700/3426] Loss: 0.2003 Acc: 92 %\n",
      "Epoch [5/100], Iter [2710/3426] Loss: 0.1952 Acc: 92 %\n",
      "Epoch [5/100], Iter [2720/3426] Loss: 0.1913 Acc: 92 %\n",
      "Epoch [5/100], Iter [2730/3426] Loss: 0.1701 Acc: 92 %\n",
      "Epoch [5/100], Iter [2740/3426] Loss: 0.1821 Acc: 92 %\n",
      "Epoch [5/100], Iter [2750/3426] Loss: 0.2118 Acc: 92 %\n",
      "Epoch [5/100], Iter [2760/3426] Loss: 0.1887 Acc: 92 %\n",
      "Epoch [5/100], Iter [2770/3426] Loss: 0.2281 Acc: 92 %\n",
      "Epoch [5/100], Iter [2780/3426] Loss: 0.2120 Acc: 92 %\n",
      "Epoch [5/100], Iter [2790/3426] Loss: 0.1937 Acc: 92 %\n",
      "Epoch [5/100], Iter [2800/3426] Loss: 0.1845 Acc: 92 %\n",
      "Epoch [5/100], Iter [2810/3426] Loss: 0.2028 Acc: 92 %\n",
      "Epoch [5/100], Iter [2820/3426] Loss: 0.2013 Acc: 92 %\n",
      "Epoch [5/100], Iter [2830/3426] Loss: 0.1727 Acc: 92 %\n",
      "Epoch [5/100], Iter [2840/3426] Loss: 0.1643 Acc: 92 %\n",
      "Epoch [5/100], Iter [2850/3426] Loss: 0.1738 Acc: 92 %\n",
      "Epoch [5/100], Iter [2860/3426] Loss: 0.1707 Acc: 92 %\n",
      "Epoch [5/100], Iter [2870/3426] Loss: 0.1929 Acc: 92 %\n",
      "Epoch [5/100], Iter [2880/3426] Loss: 0.1690 Acc: 92 %\n",
      "Epoch [5/100], Iter [2890/3426] Loss: 0.1810 Acc: 92 %\n",
      "Epoch [5/100], Iter [2900/3426] Loss: 0.1954 Acc: 92 %\n",
      "Epoch [5/100], Iter [2910/3426] Loss: 0.1955 Acc: 92 %\n",
      "Epoch [5/100], Iter [2920/3426] Loss: 0.1849 Acc: 92 %\n",
      "Epoch [5/100], Iter [2930/3426] Loss: 0.1712 Acc: 92 %\n",
      "Epoch [5/100], Iter [2940/3426] Loss: 0.1882 Acc: 92 %\n",
      "Epoch [5/100], Iter [2950/3426] Loss: 0.1794 Acc: 92 %\n",
      "Epoch [5/100], Iter [2960/3426] Loss: 0.2012 Acc: 92 %\n",
      "Epoch [5/100], Iter [2970/3426] Loss: 0.2111 Acc: 92 %\n",
      "Epoch [5/100], Iter [2980/3426] Loss: 0.1823 Acc: 92 %\n",
      "Epoch [5/100], Iter [2990/3426] Loss: 0.2013 Acc: 92 %\n",
      "Epoch [5/100], Iter [3000/3426] Loss: 0.1792 Acc: 92 %\n",
      "Epoch [5/100], Iter [3010/3426] Loss: 0.1865 Acc: 92 %\n",
      "Epoch [5/100], Iter [3020/3426] Loss: 0.1806 Acc: 92 %\n",
      "Epoch [5/100], Iter [3030/3426] Loss: 0.2149 Acc: 92 %\n",
      "Epoch [5/100], Iter [3040/3426] Loss: 0.1975 Acc: 92 %\n",
      "Epoch [5/100], Iter [3050/3426] Loss: 0.1835 Acc: 92 %\n",
      "Epoch [5/100], Iter [3060/3426] Loss: 0.1814 Acc: 92 %\n",
      "Epoch [5/100], Iter [3070/3426] Loss: 0.2050 Acc: 92 %\n",
      "Epoch [5/100], Iter [3080/3426] Loss: 0.2263 Acc: 92 %\n",
      "Epoch [5/100], Iter [3090/3426] Loss: 0.2197 Acc: 92 %\n",
      "Epoch [5/100], Iter [3100/3426] Loss: 0.2042 Acc: 92 %\n",
      "Epoch [5/100], Iter [3110/3426] Loss: 0.3139 Acc: 92 %\n",
      "Epoch [5/100], Iter [3120/3426] Loss: 0.1939 Acc: 92 %\n",
      "Epoch [5/100], Iter [3130/3426] Loss: 0.2055 Acc: 92 %\n",
      "Epoch [5/100], Iter [3140/3426] Loss: 0.2066 Acc: 92 %\n",
      "Epoch [5/100], Iter [3150/3426] Loss: 0.2253 Acc: 92 %\n",
      "Epoch [5/100], Iter [3160/3426] Loss: 0.1859 Acc: 92 %\n",
      "Epoch [5/100], Iter [3170/3426] Loss: 0.1983 Acc: 92 %\n",
      "Epoch [5/100], Iter [3180/3426] Loss: 0.1840 Acc: 92 %\n",
      "Epoch [5/100], Iter [3190/3426] Loss: 0.2199 Acc: 92 %\n",
      "Epoch [5/100], Iter [3200/3426] Loss: 0.1811 Acc: 92 %\n",
      "Epoch [5/100], Iter [3210/3426] Loss: 0.2079 Acc: 92 %\n",
      "Epoch [5/100], Iter [3220/3426] Loss: 0.2274 Acc: 92 %\n",
      "Epoch [5/100], Iter [3230/3426] Loss: 0.2135 Acc: 92 %\n",
      "Epoch [5/100], Iter [3240/3426] Loss: 0.1741 Acc: 92 %\n",
      "Epoch [5/100], Iter [3250/3426] Loss: 0.1680 Acc: 92 %\n",
      "Epoch [5/100], Iter [3260/3426] Loss: 0.1737 Acc: 92 %\n",
      "Epoch [5/100], Iter [3270/3426] Loss: 0.1574 Acc: 92 %\n",
      "Epoch [5/100], Iter [3280/3426] Loss: 0.1998 Acc: 92 %\n",
      "Epoch [5/100], Iter [3290/3426] Loss: 0.2049 Acc: 92 %\n",
      "Epoch [5/100], Iter [3300/3426] Loss: 0.1883 Acc: 92 %\n",
      "Epoch [5/100], Iter [3310/3426] Loss: 0.1772 Acc: 92 %\n",
      "Epoch [5/100], Iter [3320/3426] Loss: 0.1997 Acc: 92 %\n",
      "Epoch [5/100], Iter [3330/3426] Loss: 0.1827 Acc: 92 %\n",
      "Epoch [5/100], Iter [3340/3426] Loss: 0.2045 Acc: 92 %\n",
      "Epoch [5/100], Iter [3350/3426] Loss: 0.2027 Acc: 92 %\n",
      "Epoch [5/100], Iter [3360/3426] Loss: 0.1720 Acc: 92 %\n",
      "Epoch [5/100], Iter [3370/3426] Loss: 0.1779 Acc: 92 %\n",
      "Epoch [5/100], Iter [3380/3426] Loss: 0.1773 Acc: 92 %\n",
      "Epoch [5/100], Iter [3390/3426] Loss: 0.2132 Acc: 92 %\n",
      "Epoch [5/100], Iter [3400/3426] Loss: 0.2357 Acc: 92 %\n",
      "Epoch [5/100], Iter [3410/3426] Loss: 0.1901 Acc: 92 %\n",
      "Epoch [5/100], Iter [3420/3426] Loss: 0.1959 Acc: 92 %\n",
      "Accuracy of the model on the neg seq: 75 %\n",
      "Accuracy of the model on the pos seq: 98 %\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch [6/100], Iter [10/3426] Loss: 0.2227 Acc: 92 %\n",
      "Epoch [6/100], Iter [20/3426] Loss: 0.1850 Acc: 92 %\n",
      "Epoch [6/100], Iter [30/3426] Loss: 0.1792 Acc: 92 %\n",
      "Epoch [6/100], Iter [40/3426] Loss: 0.2089 Acc: 92 %\n",
      "Epoch [6/100], Iter [50/3426] Loss: 0.2046 Acc: 92 %\n",
      "Epoch [6/100], Iter [60/3426] Loss: 0.1910 Acc: 92 %\n",
      "Epoch [6/100], Iter [70/3426] Loss: 0.1599 Acc: 92 %\n",
      "Epoch [6/100], Iter [80/3426] Loss: 0.2156 Acc: 92 %\n",
      "Epoch [6/100], Iter [90/3426] Loss: 0.1899 Acc: 92 %\n",
      "Epoch [6/100], Iter [100/3426] Loss: 0.2039 Acc: 92 %\n",
      "Epoch [6/100], Iter [110/3426] Loss: 0.1957 Acc: 92 %\n",
      "Epoch [6/100], Iter [120/3426] Loss: 0.1991 Acc: 92 %\n",
      "Epoch [6/100], Iter [130/3426] Loss: 0.2043 Acc: 92 %\n",
      "Epoch [6/100], Iter [140/3426] Loss: 0.1618 Acc: 92 %\n",
      "Epoch [6/100], Iter [150/3426] Loss: 0.1960 Acc: 92 %\n",
      "Epoch [6/100], Iter [160/3426] Loss: 0.1933 Acc: 92 %\n",
      "Epoch [6/100], Iter [170/3426] Loss: 0.1978 Acc: 92 %\n",
      "Epoch [6/100], Iter [180/3426] Loss: 0.1800 Acc: 92 %\n",
      "Epoch [6/100], Iter [190/3426] Loss: 0.1805 Acc: 92 %\n",
      "Epoch [6/100], Iter [200/3426] Loss: 0.1908 Acc: 92 %\n",
      "Epoch [6/100], Iter [210/3426] Loss: 0.1900 Acc: 92 %\n",
      "Epoch [6/100], Iter [220/3426] Loss: 0.1577 Acc: 92 %\n",
      "Epoch [6/100], Iter [230/3426] Loss: 0.1956 Acc: 92 %\n",
      "Epoch [6/100], Iter [240/3426] Loss: 0.1884 Acc: 92 %\n",
      "Epoch [6/100], Iter [250/3426] Loss: 0.1994 Acc: 92 %\n",
      "Epoch [6/100], Iter [260/3426] Loss: 0.2435 Acc: 92 %\n",
      "Epoch [6/100], Iter [270/3426] Loss: 0.1483 Acc: 92 %\n",
      "Epoch [6/100], Iter [280/3426] Loss: 0.2018 Acc: 92 %\n",
      "Epoch [6/100], Iter [290/3426] Loss: 0.1815 Acc: 92 %\n",
      "Epoch [6/100], Iter [300/3426] Loss: 0.2277 Acc: 92 %\n",
      "Epoch [6/100], Iter [310/3426] Loss: 0.1659 Acc: 92 %\n",
      "Epoch [6/100], Iter [320/3426] Loss: 0.1730 Acc: 92 %\n",
      "Epoch [6/100], Iter [330/3426] Loss: 0.2150 Acc: 92 %\n",
      "Epoch [6/100], Iter [340/3426] Loss: 0.2345 Acc: 92 %\n",
      "Epoch [6/100], Iter [350/3426] Loss: 0.1642 Acc: 92 %\n",
      "Epoch [6/100], Iter [360/3426] Loss: 0.1798 Acc: 92 %\n",
      "Epoch [6/100], Iter [370/3426] Loss: 0.1667 Acc: 92 %\n",
      "Epoch [6/100], Iter [380/3426] Loss: 0.1761 Acc: 92 %\n",
      "Epoch [6/100], Iter [390/3426] Loss: 0.1558 Acc: 92 %\n",
      "Epoch [6/100], Iter [400/3426] Loss: 0.2068 Acc: 92 %\n",
      "Epoch [6/100], Iter [410/3426] Loss: 0.1715 Acc: 92 %\n",
      "Epoch [6/100], Iter [420/3426] Loss: 0.1544 Acc: 92 %\n",
      "Epoch [6/100], Iter [430/3426] Loss: 0.1420 Acc: 92 %\n",
      "Epoch [6/100], Iter [440/3426] Loss: 0.1765 Acc: 92 %\n",
      "Epoch [6/100], Iter [450/3426] Loss: 0.1927 Acc: 92 %\n",
      "Epoch [6/100], Iter [460/3426] Loss: 0.1941 Acc: 92 %\n",
      "Epoch [6/100], Iter [470/3426] Loss: 0.1926 Acc: 92 %\n",
      "Epoch [6/100], Iter [480/3426] Loss: 0.1961 Acc: 92 %\n",
      "Epoch [6/100], Iter [490/3426] Loss: 0.2033 Acc: 92 %\n",
      "Epoch [6/100], Iter [500/3426] Loss: 0.2043 Acc: 92 %\n",
      "Epoch [6/100], Iter [510/3426] Loss: 0.1767 Acc: 92 %\n",
      "Epoch [6/100], Iter [520/3426] Loss: 0.1939 Acc: 92 %\n",
      "Epoch [6/100], Iter [530/3426] Loss: 0.1988 Acc: 92 %\n",
      "Epoch [6/100], Iter [540/3426] Loss: 0.2341 Acc: 92 %\n",
      "Epoch [6/100], Iter [550/3426] Loss: 0.1976 Acc: 92 %\n",
      "Epoch [6/100], Iter [560/3426] Loss: 0.1742 Acc: 92 %\n",
      "Epoch [6/100], Iter [570/3426] Loss: 0.1944 Acc: 92 %\n",
      "Epoch [6/100], Iter [580/3426] Loss: 0.1532 Acc: 92 %\n",
      "Epoch [6/100], Iter [590/3426] Loss: 0.1895 Acc: 92 %\n",
      "Epoch [6/100], Iter [600/3426] Loss: 0.1666 Acc: 92 %\n",
      "Epoch [6/100], Iter [610/3426] Loss: 0.1715 Acc: 92 %\n",
      "Epoch [6/100], Iter [620/3426] Loss: 0.2064 Acc: 92 %\n",
      "Epoch [6/100], Iter [630/3426] Loss: 0.2128 Acc: 92 %\n",
      "Epoch [6/100], Iter [640/3426] Loss: 0.1814 Acc: 92 %\n",
      "Epoch [6/100], Iter [650/3426] Loss: 0.1915 Acc: 92 %\n",
      "Epoch [6/100], Iter [660/3426] Loss: 0.1890 Acc: 92 %\n",
      "Epoch [6/100], Iter [670/3426] Loss: 0.1877 Acc: 92 %\n",
      "Epoch [6/100], Iter [680/3426] Loss: 0.1822 Acc: 92 %\n",
      "Epoch [6/100], Iter [690/3426] Loss: 0.1494 Acc: 92 %\n",
      "Epoch [6/100], Iter [700/3426] Loss: 0.1817 Acc: 92 %\n",
      "Epoch [6/100], Iter [710/3426] Loss: 0.1587 Acc: 92 %\n",
      "Epoch [6/100], Iter [720/3426] Loss: 0.1819 Acc: 92 %\n",
      "Epoch [6/100], Iter [730/3426] Loss: 0.1564 Acc: 92 %\n",
      "Epoch [6/100], Iter [740/3426] Loss: 0.1853 Acc: 92 %\n",
      "Epoch [6/100], Iter [750/3426] Loss: 0.1809 Acc: 92 %\n",
      "Epoch [6/100], Iter [760/3426] Loss: 0.1794 Acc: 92 %\n",
      "Epoch [6/100], Iter [770/3426] Loss: 0.2053 Acc: 92 %\n",
      "Epoch [6/100], Iter [780/3426] Loss: 0.1817 Acc: 92 %\n",
      "Epoch [6/100], Iter [790/3426] Loss: 0.1907 Acc: 92 %\n",
      "Epoch [6/100], Iter [800/3426] Loss: 0.1910 Acc: 92 %\n",
      "Epoch [6/100], Iter [810/3426] Loss: 0.1624 Acc: 92 %\n",
      "Epoch [6/100], Iter [820/3426] Loss: 0.1761 Acc: 92 %\n",
      "Epoch [6/100], Iter [830/3426] Loss: 0.1899 Acc: 92 %\n",
      "Epoch [6/100], Iter [840/3426] Loss: 0.1903 Acc: 92 %\n",
      "Epoch [6/100], Iter [850/3426] Loss: 0.1809 Acc: 92 %\n",
      "Epoch [6/100], Iter [860/3426] Loss: 0.1883 Acc: 92 %\n",
      "Epoch [6/100], Iter [870/3426] Loss: 0.1887 Acc: 92 %\n",
      "Epoch [6/100], Iter [880/3426] Loss: 0.1703 Acc: 92 %\n",
      "Epoch [6/100], Iter [890/3426] Loss: 0.1789 Acc: 92 %\n",
      "Epoch [6/100], Iter [900/3426] Loss: 0.1807 Acc: 92 %\n",
      "Epoch [6/100], Iter [910/3426] Loss: 0.1893 Acc: 92 %\n",
      "Epoch [6/100], Iter [920/3426] Loss: 0.1788 Acc: 92 %\n",
      "Epoch [6/100], Iter [930/3426] Loss: 0.1703 Acc: 92 %\n",
      "Epoch [6/100], Iter [940/3426] Loss: 0.1489 Acc: 92 %\n",
      "Epoch [6/100], Iter [950/3426] Loss: 0.1631 Acc: 92 %\n",
      "Epoch [6/100], Iter [960/3426] Loss: 0.1906 Acc: 92 %\n",
      "Epoch [6/100], Iter [970/3426] Loss: 0.1970 Acc: 92 %\n",
      "Epoch [6/100], Iter [980/3426] Loss: 0.1862 Acc: 92 %\n",
      "Epoch [6/100], Iter [990/3426] Loss: 0.2012 Acc: 92 %\n",
      "Epoch [6/100], Iter [1000/3426] Loss: 0.1873 Acc: 92 %\n",
      "Epoch [6/100], Iter [1010/3426] Loss: 0.2041 Acc: 92 %\n",
      "Epoch [6/100], Iter [1020/3426] Loss: 0.1811 Acc: 92 %\n",
      "Epoch [6/100], Iter [1030/3426] Loss: 0.1861 Acc: 92 %\n",
      "Epoch [6/100], Iter [1040/3426] Loss: 0.1864 Acc: 92 %\n",
      "Epoch [6/100], Iter [1050/3426] Loss: 0.1788 Acc: 92 %\n",
      "Epoch [6/100], Iter [1060/3426] Loss: 0.1904 Acc: 92 %\n",
      "Epoch [6/100], Iter [1070/3426] Loss: 0.1670 Acc: 92 %\n",
      "Epoch [6/100], Iter [1080/3426] Loss: 0.1890 Acc: 92 %\n",
      "Epoch [6/100], Iter [1090/3426] Loss: 0.2167 Acc: 92 %\n",
      "Epoch [6/100], Iter [1100/3426] Loss: 0.2069 Acc: 92 %\n",
      "Epoch [6/100], Iter [1110/3426] Loss: 0.1673 Acc: 92 %\n",
      "Epoch [6/100], Iter [1120/3426] Loss: 0.1837 Acc: 92 %\n",
      "Epoch [6/100], Iter [1130/3426] Loss: 0.1959 Acc: 92 %\n",
      "Epoch [6/100], Iter [1140/3426] Loss: 0.2130 Acc: 92 %\n",
      "Epoch [6/100], Iter [1150/3426] Loss: 0.1903 Acc: 92 %\n",
      "Epoch [6/100], Iter [1160/3426] Loss: 0.1829 Acc: 92 %\n",
      "Epoch [6/100], Iter [1170/3426] Loss: 0.1907 Acc: 92 %\n",
      "Epoch [6/100], Iter [1180/3426] Loss: 0.2080 Acc: 92 %\n",
      "Epoch [6/100], Iter [1190/3426] Loss: 0.1551 Acc: 92 %\n",
      "Epoch [6/100], Iter [1200/3426] Loss: 0.1870 Acc: 92 %\n",
      "Epoch [6/100], Iter [1210/3426] Loss: 0.1772 Acc: 92 %\n",
      "Epoch [6/100], Iter [1220/3426] Loss: 0.1889 Acc: 92 %\n",
      "Epoch [6/100], Iter [1230/3426] Loss: 0.1767 Acc: 92 %\n",
      "Epoch [6/100], Iter [1240/3426] Loss: 0.2160 Acc: 92 %\n",
      "Epoch [6/100], Iter [1250/3426] Loss: 0.1625 Acc: 92 %\n",
      "Epoch [6/100], Iter [1260/3426] Loss: 0.1804 Acc: 92 %\n",
      "Epoch [6/100], Iter [1270/3426] Loss: 0.1642 Acc: 92 %\n",
      "Epoch [6/100], Iter [1280/3426] Loss: 0.1917 Acc: 92 %\n",
      "Epoch [6/100], Iter [1290/3426] Loss: 0.2049 Acc: 92 %\n",
      "Epoch [6/100], Iter [1300/3426] Loss: 0.2057 Acc: 92 %\n",
      "Epoch [6/100], Iter [1310/3426] Loss: 0.1893 Acc: 92 %\n",
      "Epoch [6/100], Iter [1320/3426] Loss: 0.1839 Acc: 92 %\n",
      "Epoch [6/100], Iter [1330/3426] Loss: 0.1935 Acc: 92 %\n",
      "Epoch [6/100], Iter [1340/3426] Loss: 0.1987 Acc: 92 %\n",
      "Epoch [6/100], Iter [1350/3426] Loss: 0.2120 Acc: 92 %\n",
      "Epoch [6/100], Iter [1360/3426] Loss: 0.1881 Acc: 92 %\n",
      "Epoch [6/100], Iter [1370/3426] Loss: 0.1902 Acc: 92 %\n",
      "Epoch [6/100], Iter [1380/3426] Loss: 0.1549 Acc: 92 %\n",
      "Epoch [6/100], Iter [1390/3426] Loss: 0.1783 Acc: 92 %\n",
      "Epoch [6/100], Iter [1400/3426] Loss: 0.1976 Acc: 92 %\n",
      "Epoch [6/100], Iter [1410/3426] Loss: 0.1932 Acc: 92 %\n",
      "Epoch [6/100], Iter [1420/3426] Loss: 0.1956 Acc: 92 %\n",
      "Epoch [6/100], Iter [1430/3426] Loss: 0.1969 Acc: 92 %\n",
      "Epoch [6/100], Iter [1440/3426] Loss: 0.1796 Acc: 92 %\n",
      "Epoch [6/100], Iter [1450/3426] Loss: 0.1869 Acc: 92 %\n",
      "Epoch [6/100], Iter [1460/3426] Loss: 0.1775 Acc: 92 %\n",
      "Epoch [6/100], Iter [1470/3426] Loss: 0.1736 Acc: 92 %\n",
      "Epoch [6/100], Iter [1480/3426] Loss: 0.1996 Acc: 92 %\n",
      "Epoch [6/100], Iter [1490/3426] Loss: 0.1923 Acc: 92 %\n",
      "Epoch [6/100], Iter [1500/3426] Loss: 0.1949 Acc: 92 %\n",
      "Epoch [6/100], Iter [1510/3426] Loss: 0.1671 Acc: 92 %\n",
      "Epoch [6/100], Iter [1520/3426] Loss: 0.1902 Acc: 92 %\n",
      "Epoch [6/100], Iter [1530/3426] Loss: 0.1828 Acc: 92 %\n",
      "Epoch [6/100], Iter [1540/3426] Loss: 0.1829 Acc: 92 %\n",
      "Epoch [6/100], Iter [1550/3426] Loss: 0.1449 Acc: 92 %\n",
      "Epoch [6/100], Iter [1560/3426] Loss: 0.1819 Acc: 92 %\n",
      "Epoch [6/100], Iter [1570/3426] Loss: 0.1580 Acc: 92 %\n",
      "Epoch [6/100], Iter [1580/3426] Loss: 0.1712 Acc: 92 %\n",
      "Epoch [6/100], Iter [1590/3426] Loss: 0.1854 Acc: 92 %\n",
      "Epoch [6/100], Iter [1600/3426] Loss: 0.1738 Acc: 92 %\n",
      "Epoch [6/100], Iter [1610/3426] Loss: 0.1620 Acc: 92 %\n",
      "Epoch [6/100], Iter [1620/3426] Loss: 0.1889 Acc: 92 %\n",
      "Epoch [6/100], Iter [1630/3426] Loss: 0.1639 Acc: 92 %\n",
      "Epoch [6/100], Iter [1640/3426] Loss: 0.1624 Acc: 92 %\n",
      "Epoch [6/100], Iter [1650/3426] Loss: 0.1597 Acc: 92 %\n",
      "Epoch [6/100], Iter [1660/3426] Loss: 0.1886 Acc: 92 %\n",
      "Epoch [6/100], Iter [1670/3426] Loss: 0.1817 Acc: 92 %\n",
      "Epoch [6/100], Iter [1680/3426] Loss: 0.1811 Acc: 92 %\n",
      "Epoch [6/100], Iter [1690/3426] Loss: 0.1891 Acc: 92 %\n",
      "Epoch [6/100], Iter [1700/3426] Loss: 0.1810 Acc: 92 %\n",
      "Epoch [6/100], Iter [1710/3426] Loss: 0.1761 Acc: 92 %\n",
      "Epoch [6/100], Iter [1720/3426] Loss: 0.1523 Acc: 92 %\n",
      "Epoch [6/100], Iter [1730/3426] Loss: 0.2123 Acc: 92 %\n",
      "Epoch [6/100], Iter [1740/3426] Loss: 0.2028 Acc: 92 %\n",
      "Epoch [6/100], Iter [1750/3426] Loss: 0.1521 Acc: 92 %\n",
      "Epoch [6/100], Iter [1760/3426] Loss: 0.1986 Acc: 92 %\n",
      "Epoch [6/100], Iter [1770/3426] Loss: 0.1986 Acc: 92 %\n",
      "Epoch [6/100], Iter [1780/3426] Loss: 0.1995 Acc: 92 %\n",
      "Epoch [6/100], Iter [1790/3426] Loss: 0.1830 Acc: 92 %\n",
      "Epoch [6/100], Iter [1800/3426] Loss: 0.1642 Acc: 92 %\n",
      "Epoch [6/100], Iter [1810/3426] Loss: 0.1976 Acc: 92 %\n",
      "Epoch [6/100], Iter [1820/3426] Loss: 0.1813 Acc: 92 %\n",
      "Epoch [6/100], Iter [1830/3426] Loss: 0.1826 Acc: 92 %\n",
      "Epoch [6/100], Iter [1840/3426] Loss: 0.1692 Acc: 92 %\n",
      "Epoch [6/100], Iter [1850/3426] Loss: 0.1964 Acc: 92 %\n",
      "Epoch [6/100], Iter [1860/3426] Loss: 0.1614 Acc: 92 %\n",
      "Epoch [6/100], Iter [1870/3426] Loss: 0.1456 Acc: 92 %\n",
      "Epoch [6/100], Iter [1880/3426] Loss: 0.1920 Acc: 92 %\n",
      "Epoch [6/100], Iter [1890/3426] Loss: 0.2133 Acc: 92 %\n",
      "Epoch [6/100], Iter [1900/3426] Loss: 0.1628 Acc: 92 %\n",
      "Epoch [6/100], Iter [1910/3426] Loss: 0.2184 Acc: 92 %\n",
      "Epoch [6/100], Iter [1920/3426] Loss: 0.2063 Acc: 92 %\n",
      "Epoch [6/100], Iter [1930/3426] Loss: 0.1751 Acc: 92 %\n",
      "Epoch [6/100], Iter [1940/3426] Loss: 0.1872 Acc: 92 %\n",
      "Epoch [6/100], Iter [1950/3426] Loss: 0.1803 Acc: 92 %\n",
      "Epoch [6/100], Iter [1960/3426] Loss: 0.1809 Acc: 92 %\n",
      "Epoch [6/100], Iter [1970/3426] Loss: 0.1684 Acc: 92 %\n",
      "Epoch [6/100], Iter [1980/3426] Loss: 0.1547 Acc: 92 %\n",
      "Epoch [6/100], Iter [1990/3426] Loss: 0.1695 Acc: 92 %\n",
      "Epoch [6/100], Iter [2000/3426] Loss: 0.1745 Acc: 92 %\n",
      "Epoch [6/100], Iter [2010/3426] Loss: 0.1971 Acc: 92 %\n",
      "Epoch [6/100], Iter [2020/3426] Loss: 0.2210 Acc: 92 %\n",
      "Epoch [6/100], Iter [2030/3426] Loss: 0.1988 Acc: 92 %\n",
      "Epoch [6/100], Iter [2040/3426] Loss: 0.1960 Acc: 92 %\n",
      "Epoch [6/100], Iter [2050/3426] Loss: 0.1919 Acc: 92 %\n",
      "Epoch [6/100], Iter [2060/3426] Loss: 0.1847 Acc: 92 %\n",
      "Epoch [6/100], Iter [2070/3426] Loss: 0.1706 Acc: 92 %\n",
      "Epoch [6/100], Iter [2080/3426] Loss: 0.2068 Acc: 92 %\n",
      "Epoch [6/100], Iter [2090/3426] Loss: 0.1908 Acc: 92 %\n",
      "Epoch [6/100], Iter [2100/3426] Loss: 0.1757 Acc: 92 %\n",
      "Epoch [6/100], Iter [2110/3426] Loss: 0.2117 Acc: 92 %\n",
      "Epoch [6/100], Iter [2120/3426] Loss: 0.2163 Acc: 92 %\n",
      "Epoch [6/100], Iter [2130/3426] Loss: 0.1704 Acc: 92 %\n",
      "Epoch [6/100], Iter [2140/3426] Loss: 0.1812 Acc: 92 %\n",
      "Epoch [6/100], Iter [2150/3426] Loss: 0.1700 Acc: 92 %\n",
      "Epoch [6/100], Iter [2160/3426] Loss: 0.2020 Acc: 92 %\n",
      "Epoch [6/100], Iter [2170/3426] Loss: 0.1754 Acc: 92 %\n",
      "Epoch [6/100], Iter [2180/3426] Loss: 0.1854 Acc: 92 %\n",
      "Epoch [6/100], Iter [2190/3426] Loss: 0.1697 Acc: 92 %\n",
      "Epoch [6/100], Iter [2200/3426] Loss: 0.1780 Acc: 92 %\n",
      "Epoch [6/100], Iter [2210/3426] Loss: 0.1716 Acc: 92 %\n",
      "Epoch [6/100], Iter [2220/3426] Loss: 0.1684 Acc: 92 %\n",
      "Epoch [6/100], Iter [2230/3426] Loss: 0.1532 Acc: 92 %\n",
      "Epoch [6/100], Iter [2240/3426] Loss: 0.1531 Acc: 92 %\n",
      "Epoch [6/100], Iter [2250/3426] Loss: 0.1816 Acc: 92 %\n",
      "Epoch [6/100], Iter [2260/3426] Loss: 0.1775 Acc: 92 %\n",
      "Epoch [6/100], Iter [2270/3426] Loss: 0.1699 Acc: 92 %\n",
      "Epoch [6/100], Iter [2280/3426] Loss: 0.1638 Acc: 92 %\n",
      "Epoch [6/100], Iter [2290/3426] Loss: 0.1816 Acc: 92 %\n",
      "Epoch [6/100], Iter [2300/3426] Loss: 0.1860 Acc: 92 %\n",
      "Epoch [6/100], Iter [2310/3426] Loss: 0.1810 Acc: 92 %\n",
      "Epoch [6/100], Iter [2320/3426] Loss: 0.1925 Acc: 92 %\n",
      "Epoch [6/100], Iter [2330/3426] Loss: 0.1752 Acc: 92 %\n",
      "Epoch [6/100], Iter [2340/3426] Loss: 0.1738 Acc: 92 %\n",
      "Epoch [6/100], Iter [2350/3426] Loss: 0.1538 Acc: 92 %\n",
      "Epoch [6/100], Iter [2360/3426] Loss: 0.1632 Acc: 92 %\n",
      "Epoch [6/100], Iter [2370/3426] Loss: 0.1763 Acc: 92 %\n",
      "Epoch [6/100], Iter [2380/3426] Loss: 0.1890 Acc: 92 %\n",
      "Epoch [6/100], Iter [2390/3426] Loss: 0.1565 Acc: 92 %\n",
      "Epoch [6/100], Iter [2400/3426] Loss: 0.1883 Acc: 92 %\n",
      "Epoch [6/100], Iter [2410/3426] Loss: 0.1844 Acc: 92 %\n",
      "Epoch [6/100], Iter [2420/3426] Loss: 0.1982 Acc: 92 %\n",
      "Epoch [6/100], Iter [2430/3426] Loss: 0.1965 Acc: 92 %\n",
      "Epoch [6/100], Iter [2440/3426] Loss: 0.2065 Acc: 92 %\n",
      "Epoch [6/100], Iter [2450/3426] Loss: 0.2125 Acc: 92 %\n",
      "Epoch [6/100], Iter [2460/3426] Loss: 0.1746 Acc: 92 %\n",
      "Epoch [6/100], Iter [2470/3426] Loss: 0.1939 Acc: 92 %\n",
      "Epoch [6/100], Iter [2480/3426] Loss: 0.1878 Acc: 92 %\n",
      "Epoch [6/100], Iter [2490/3426] Loss: 0.1501 Acc: 92 %\n",
      "Epoch [6/100], Iter [2500/3426] Loss: 0.1890 Acc: 92 %\n",
      "Epoch [6/100], Iter [2510/3426] Loss: 0.1858 Acc: 92 %\n",
      "Epoch [6/100], Iter [2520/3426] Loss: 0.1649 Acc: 92 %\n",
      "Epoch [6/100], Iter [2530/3426] Loss: 0.1741 Acc: 92 %\n",
      "Epoch [6/100], Iter [2540/3426] Loss: 0.1828 Acc: 92 %\n",
      "Epoch [6/100], Iter [2550/3426] Loss: 0.1612 Acc: 92 %\n",
      "Epoch [6/100], Iter [2560/3426] Loss: 0.1940 Acc: 92 %\n",
      "Epoch [6/100], Iter [2570/3426] Loss: 0.2395 Acc: 92 %\n",
      "Epoch [6/100], Iter [2580/3426] Loss: 0.1649 Acc: 92 %\n",
      "Epoch [6/100], Iter [2590/3426] Loss: 0.1727 Acc: 92 %\n",
      "Epoch [6/100], Iter [2600/3426] Loss: 0.1660 Acc: 92 %\n",
      "Epoch [6/100], Iter [2610/3426] Loss: 0.1682 Acc: 92 %\n",
      "Epoch [6/100], Iter [2620/3426] Loss: 0.1694 Acc: 92 %\n",
      "Epoch [6/100], Iter [2630/3426] Loss: 0.1856 Acc: 92 %\n",
      "Epoch [6/100], Iter [2640/3426] Loss: 0.1695 Acc: 92 %\n",
      "Epoch [6/100], Iter [2650/3426] Loss: 0.1617 Acc: 92 %\n",
      "Epoch [6/100], Iter [2660/3426] Loss: 0.1874 Acc: 92 %\n",
      "Epoch [6/100], Iter [2670/3426] Loss: 0.2009 Acc: 92 %\n",
      "Epoch [6/100], Iter [2680/3426] Loss: 0.1695 Acc: 92 %\n",
      "Epoch [6/100], Iter [2690/3426] Loss: 0.1780 Acc: 92 %\n",
      "Epoch [6/100], Iter [2700/3426] Loss: 0.1805 Acc: 92 %\n",
      "Epoch [6/100], Iter [2710/3426] Loss: 0.1850 Acc: 92 %\n",
      "Epoch [6/100], Iter [2720/3426] Loss: 0.1878 Acc: 92 %\n",
      "Epoch [6/100], Iter [2730/3426] Loss: 0.1570 Acc: 92 %\n",
      "Epoch [6/100], Iter [2740/3426] Loss: 0.1922 Acc: 92 %\n",
      "Epoch [6/100], Iter [2750/3426] Loss: 0.1638 Acc: 92 %\n",
      "Epoch [6/100], Iter [2760/3426] Loss: 0.2057 Acc: 92 %\n",
      "Epoch [6/100], Iter [2770/3426] Loss: 0.1603 Acc: 92 %\n",
      "Epoch [6/100], Iter [2780/3426] Loss: 0.1644 Acc: 92 %\n",
      "Epoch [6/100], Iter [2790/3426] Loss: 0.1936 Acc: 92 %\n",
      "Epoch [6/100], Iter [2800/3426] Loss: 0.1918 Acc: 92 %\n",
      "Epoch [6/100], Iter [2810/3426] Loss: 0.1572 Acc: 92 %\n",
      "Epoch [6/100], Iter [2820/3426] Loss: 0.1606 Acc: 92 %\n",
      "Epoch [6/100], Iter [2830/3426] Loss: 0.1951 Acc: 92 %\n",
      "Epoch [6/100], Iter [2840/3426] Loss: 0.1903 Acc: 92 %\n",
      "Epoch [6/100], Iter [2850/3426] Loss: 0.2009 Acc: 92 %\n",
      "Epoch [6/100], Iter [2860/3426] Loss: 0.1791 Acc: 92 %\n",
      "Epoch [6/100], Iter [2870/3426] Loss: 0.1888 Acc: 92 %\n",
      "Epoch [6/100], Iter [2880/3426] Loss: 0.1822 Acc: 92 %\n",
      "Epoch [6/100], Iter [2890/3426] Loss: 0.1738 Acc: 92 %\n",
      "Epoch [6/100], Iter [2900/3426] Loss: 0.1854 Acc: 92 %\n",
      "Epoch [6/100], Iter [2910/3426] Loss: 0.1992 Acc: 92 %\n",
      "Epoch [6/100], Iter [2920/3426] Loss: 0.1903 Acc: 92 %\n",
      "Epoch [6/100], Iter [2930/3426] Loss: 0.1777 Acc: 92 %\n",
      "Epoch [6/100], Iter [2940/3426] Loss: 0.1942 Acc: 92 %\n",
      "Epoch [6/100], Iter [2950/3426] Loss: 0.1818 Acc: 92 %\n",
      "Epoch [6/100], Iter [2960/3426] Loss: 0.1760 Acc: 92 %\n",
      "Epoch [6/100], Iter [2970/3426] Loss: 0.1717 Acc: 92 %\n",
      "Epoch [6/100], Iter [2980/3426] Loss: 0.1869 Acc: 92 %\n",
      "Epoch [6/100], Iter [2990/3426] Loss: 0.1836 Acc: 92 %\n",
      "Epoch [6/100], Iter [3000/3426] Loss: 0.1698 Acc: 92 %\n",
      "Epoch [6/100], Iter [3010/3426] Loss: 0.1818 Acc: 92 %\n",
      "Epoch [6/100], Iter [3020/3426] Loss: 0.1715 Acc: 92 %\n",
      "Epoch [6/100], Iter [3030/3426] Loss: 0.2087 Acc: 92 %\n",
      "Epoch [6/100], Iter [3040/3426] Loss: 0.1923 Acc: 92 %\n",
      "Epoch [6/100], Iter [3050/3426] Loss: 0.1654 Acc: 92 %\n",
      "Epoch [6/100], Iter [3060/3426] Loss: 0.1625 Acc: 92 %\n",
      "Epoch [6/100], Iter [3070/3426] Loss: 0.1819 Acc: 92 %\n",
      "Epoch [6/100], Iter [3080/3426] Loss: 0.1603 Acc: 92 %\n",
      "Epoch [6/100], Iter [3090/3426] Loss: 0.1757 Acc: 92 %\n",
      "Epoch [6/100], Iter [3100/3426] Loss: 0.1931 Acc: 92 %\n",
      "Epoch [6/100], Iter [3110/3426] Loss: 0.1842 Acc: 92 %\n",
      "Epoch [6/100], Iter [3120/3426] Loss: 0.1919 Acc: 92 %\n",
      "Epoch [6/100], Iter [3130/3426] Loss: 0.1868 Acc: 92 %\n",
      "Epoch [6/100], Iter [3140/3426] Loss: 0.2185 Acc: 92 %\n",
      "Epoch [6/100], Iter [3150/3426] Loss: 0.1895 Acc: 92 %\n",
      "Epoch [6/100], Iter [3160/3426] Loss: 0.1696 Acc: 92 %\n",
      "Epoch [6/100], Iter [3170/3426] Loss: 0.1679 Acc: 92 %\n",
      "Epoch [6/100], Iter [3180/3426] Loss: 0.1587 Acc: 92 %\n",
      "Epoch [6/100], Iter [3190/3426] Loss: 0.1672 Acc: 92 %\n",
      "Epoch [6/100], Iter [3200/3426] Loss: 0.1877 Acc: 92 %\n",
      "Epoch [6/100], Iter [3210/3426] Loss: 0.1656 Acc: 92 %\n",
      "Epoch [6/100], Iter [3220/3426] Loss: 0.1945 Acc: 92 %\n",
      "Epoch [6/100], Iter [3230/3426] Loss: 0.2028 Acc: 92 %\n",
      "Epoch [6/100], Iter [3240/3426] Loss: 0.1836 Acc: 92 %\n",
      "Epoch [6/100], Iter [3250/3426] Loss: 0.1611 Acc: 92 %\n",
      "Epoch [6/100], Iter [3260/3426] Loss: 0.1767 Acc: 92 %\n",
      "Epoch [6/100], Iter [3270/3426] Loss: 0.1645 Acc: 92 %\n",
      "Epoch [6/100], Iter [3280/3426] Loss: 0.1535 Acc: 92 %\n",
      "Epoch [6/100], Iter [3290/3426] Loss: 0.1751 Acc: 92 %\n",
      "Epoch [6/100], Iter [3300/3426] Loss: 0.1921 Acc: 92 %\n",
      "Epoch [6/100], Iter [3310/3426] Loss: 0.1868 Acc: 92 %\n",
      "Epoch [6/100], Iter [3320/3426] Loss: 0.1458 Acc: 92 %\n",
      "Epoch [6/100], Iter [3330/3426] Loss: 0.1872 Acc: 92 %\n",
      "Epoch [6/100], Iter [3340/3426] Loss: 0.1989 Acc: 92 %\n",
      "Epoch [6/100], Iter [3350/3426] Loss: 0.1973 Acc: 92 %\n",
      "Epoch [6/100], Iter [3360/3426] Loss: 0.1696 Acc: 92 %\n",
      "Epoch [6/100], Iter [3370/3426] Loss: 0.1831 Acc: 92 %\n",
      "Epoch [6/100], Iter [3380/3426] Loss: 0.1802 Acc: 92 %\n",
      "Epoch [6/100], Iter [3390/3426] Loss: 0.1730 Acc: 92 %\n",
      "Epoch [6/100], Iter [3400/3426] Loss: 0.1843 Acc: 92 %\n",
      "Epoch [6/100], Iter [3410/3426] Loss: 0.2120 Acc: 92 %\n",
      "Epoch [6/100], Iter [3420/3426] Loss: 0.1677 Acc: 92 %\n",
      "Accuracy of the model on the neg seq: 77 %\n",
      "Accuracy of the model on the pos seq: 96 %\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch [7/100], Iter [10/3426] Loss: 0.1942 Acc: 93 %\n",
      "Epoch [7/100], Iter [20/3426] Loss: 0.1879 Acc: 93 %\n",
      "Epoch [7/100], Iter [30/3426] Loss: 0.1547 Acc: 93 %\n",
      "Epoch [7/100], Iter [40/3426] Loss: 0.2083 Acc: 93 %\n",
      "Epoch [7/100], Iter [50/3426] Loss: 0.1675 Acc: 93 %\n",
      "Epoch [7/100], Iter [60/3426] Loss: 0.1522 Acc: 93 %\n",
      "Epoch [7/100], Iter [70/3426] Loss: 0.1471 Acc: 93 %\n",
      "Epoch [7/100], Iter [80/3426] Loss: 0.2352 Acc: 93 %\n",
      "Epoch [7/100], Iter [90/3426] Loss: 0.1763 Acc: 93 %\n",
      "Epoch [7/100], Iter [100/3426] Loss: 0.1564 Acc: 93 %\n",
      "Epoch [7/100], Iter [110/3426] Loss: 0.1794 Acc: 93 %\n",
      "Epoch [7/100], Iter [120/3426] Loss: 0.1800 Acc: 93 %\n",
      "Epoch [7/100], Iter [130/3426] Loss: 0.1814 Acc: 93 %\n",
      "Epoch [7/100], Iter [140/3426] Loss: 0.1542 Acc: 93 %\n",
      "Epoch [7/100], Iter [150/3426] Loss: 0.1991 Acc: 93 %\n",
      "Epoch [7/100], Iter [160/3426] Loss: 0.1860 Acc: 93 %\n",
      "Epoch [7/100], Iter [170/3426] Loss: 0.1571 Acc: 93 %\n",
      "Epoch [7/100], Iter [180/3426] Loss: 0.1820 Acc: 93 %\n",
      "Epoch [7/100], Iter [190/3426] Loss: 0.1784 Acc: 93 %\n",
      "Epoch [7/100], Iter [200/3426] Loss: 0.1646 Acc: 93 %\n",
      "Epoch [7/100], Iter [210/3426] Loss: 0.1612 Acc: 93 %\n",
      "Epoch [7/100], Iter [220/3426] Loss: 0.1732 Acc: 93 %\n",
      "Epoch [7/100], Iter [230/3426] Loss: 0.2112 Acc: 93 %\n",
      "Epoch [7/100], Iter [240/3426] Loss: 0.1913 Acc: 92 %\n",
      "Epoch [7/100], Iter [250/3426] Loss: 0.1863 Acc: 92 %\n",
      "Epoch [7/100], Iter [260/3426] Loss: 0.2143 Acc: 92 %\n",
      "Epoch [7/100], Iter [270/3426] Loss: 0.1707 Acc: 92 %\n",
      "Epoch [7/100], Iter [280/3426] Loss: 0.1935 Acc: 92 %\n",
      "Epoch [7/100], Iter [290/3426] Loss: 0.1609 Acc: 92 %\n",
      "Epoch [7/100], Iter [300/3426] Loss: 0.2314 Acc: 92 %\n",
      "Epoch [7/100], Iter [310/3426] Loss: 0.1461 Acc: 92 %\n",
      "Epoch [7/100], Iter [320/3426] Loss: 0.1624 Acc: 93 %\n",
      "Epoch [7/100], Iter [330/3426] Loss: 0.1628 Acc: 93 %\n",
      "Epoch [7/100], Iter [340/3426] Loss: 0.1641 Acc: 93 %\n",
      "Epoch [7/100], Iter [350/3426] Loss: 0.1919 Acc: 93 %\n",
      "Epoch [7/100], Iter [360/3426] Loss: 0.1827 Acc: 93 %\n",
      "Epoch [7/100], Iter [370/3426] Loss: 0.1854 Acc: 93 %\n",
      "Epoch [7/100], Iter [380/3426] Loss: 0.2075 Acc: 93 %\n",
      "Epoch [7/100], Iter [390/3426] Loss: 0.1720 Acc: 93 %\n",
      "Epoch [7/100], Iter [400/3426] Loss: 0.1583 Acc: 93 %\n",
      "Epoch [7/100], Iter [410/3426] Loss: 0.1872 Acc: 93 %\n",
      "Epoch [7/100], Iter [420/3426] Loss: 0.2052 Acc: 93 %\n",
      "Epoch [7/100], Iter [430/3426] Loss: 0.1635 Acc: 93 %\n",
      "Epoch [7/100], Iter [440/3426] Loss: 0.1545 Acc: 93 %\n",
      "Epoch [7/100], Iter [450/3426] Loss: 0.1698 Acc: 93 %\n",
      "Epoch [7/100], Iter [460/3426] Loss: 0.2186 Acc: 93 %\n",
      "Epoch [7/100], Iter [470/3426] Loss: 0.1556 Acc: 93 %\n",
      "Epoch [7/100], Iter [480/3426] Loss: 0.1993 Acc: 93 %\n",
      "Epoch [7/100], Iter [490/3426] Loss: 0.1596 Acc: 93 %\n",
      "Epoch [7/100], Iter [500/3426] Loss: 0.1906 Acc: 93 %\n",
      "Epoch [7/100], Iter [510/3426] Loss: 0.1895 Acc: 92 %\n",
      "Epoch [7/100], Iter [520/3426] Loss: 0.1825 Acc: 92 %\n",
      "Epoch [7/100], Iter [530/3426] Loss: 0.1733 Acc: 92 %\n",
      "Epoch [7/100], Iter [540/3426] Loss: 0.1904 Acc: 92 %\n",
      "Epoch [7/100], Iter [550/3426] Loss: 0.1585 Acc: 93 %\n",
      "Epoch [7/100], Iter [560/3426] Loss: 0.1475 Acc: 93 %\n",
      "Epoch [7/100], Iter [570/3426] Loss: 0.1745 Acc: 93 %\n",
      "Epoch [7/100], Iter [580/3426] Loss: 0.1833 Acc: 93 %\n",
      "Epoch [7/100], Iter [590/3426] Loss: 0.1758 Acc: 93 %\n",
      "Epoch [7/100], Iter [600/3426] Loss: 0.1841 Acc: 93 %\n",
      "Epoch [7/100], Iter [610/3426] Loss: 0.1613 Acc: 93 %\n",
      "Epoch [7/100], Iter [620/3426] Loss: 0.1822 Acc: 93 %\n",
      "Epoch [7/100], Iter [630/3426] Loss: 0.1833 Acc: 93 %\n",
      "Epoch [7/100], Iter [640/3426] Loss: 0.1729 Acc: 93 %\n",
      "Epoch [7/100], Iter [650/3426] Loss: 0.1988 Acc: 93 %\n",
      "Epoch [7/100], Iter [660/3426] Loss: 0.1959 Acc: 93 %\n",
      "Epoch [7/100], Iter [670/3426] Loss: 0.1527 Acc: 93 %\n",
      "Epoch [7/100], Iter [680/3426] Loss: 0.1827 Acc: 93 %\n",
      "Epoch [7/100], Iter [690/3426] Loss: 0.1654 Acc: 93 %\n",
      "Epoch [7/100], Iter [700/3426] Loss: 0.1920 Acc: 93 %\n",
      "Epoch [7/100], Iter [710/3426] Loss: 0.1796 Acc: 93 %\n",
      "Epoch [7/100], Iter [720/3426] Loss: 0.2033 Acc: 93 %\n",
      "Epoch [7/100], Iter [730/3426] Loss: 0.1759 Acc: 93 %\n",
      "Epoch [7/100], Iter [740/3426] Loss: 0.1974 Acc: 93 %\n",
      "Epoch [7/100], Iter [750/3426] Loss: 0.1737 Acc: 93 %\n",
      "Epoch [7/100], Iter [760/3426] Loss: 0.1535 Acc: 93 %\n",
      "Epoch [7/100], Iter [770/3426] Loss: 0.2155 Acc: 93 %\n",
      "Epoch [7/100], Iter [780/3426] Loss: 0.1878 Acc: 93 %\n",
      "Epoch [7/100], Iter [790/3426] Loss: 0.1939 Acc: 93 %\n",
      "Epoch [7/100], Iter [800/3426] Loss: 0.1698 Acc: 93 %\n",
      "Epoch [7/100], Iter [810/3426] Loss: 0.1558 Acc: 93 %\n",
      "Epoch [7/100], Iter [820/3426] Loss: 0.1981 Acc: 93 %\n",
      "Epoch [7/100], Iter [830/3426] Loss: 0.1741 Acc: 93 %\n",
      "Epoch [7/100], Iter [840/3426] Loss: 0.1910 Acc: 93 %\n",
      "Epoch [7/100], Iter [850/3426] Loss: 0.1804 Acc: 93 %\n",
      "Epoch [7/100], Iter [860/3426] Loss: 0.1743 Acc: 93 %\n",
      "Epoch [7/100], Iter [870/3426] Loss: 0.1818 Acc: 93 %\n",
      "Epoch [7/100], Iter [880/3426] Loss: 0.1753 Acc: 93 %\n",
      "Epoch [7/100], Iter [890/3426] Loss: 0.1723 Acc: 93 %\n",
      "Epoch [7/100], Iter [900/3426] Loss: 0.1867 Acc: 93 %\n",
      "Epoch [7/100], Iter [910/3426] Loss: 0.1669 Acc: 93 %\n",
      "Epoch [7/100], Iter [920/3426] Loss: 0.1711 Acc: 93 %\n",
      "Epoch [7/100], Iter [930/3426] Loss: 0.1681 Acc: 93 %\n",
      "Epoch [7/100], Iter [940/3426] Loss: 0.1657 Acc: 93 %\n",
      "Epoch [7/100], Iter [950/3426] Loss: 0.1709 Acc: 93 %\n",
      "Epoch [7/100], Iter [960/3426] Loss: 0.1466 Acc: 93 %\n",
      "Epoch [7/100], Iter [970/3426] Loss: 0.1764 Acc: 93 %\n",
      "Epoch [7/100], Iter [980/3426] Loss: 0.1957 Acc: 93 %\n",
      "Epoch [7/100], Iter [990/3426] Loss: 0.1457 Acc: 93 %\n",
      "Epoch [7/100], Iter [1000/3426] Loss: 0.2203 Acc: 93 %\n",
      "Epoch [7/100], Iter [1010/3426] Loss: 0.1791 Acc: 93 %\n",
      "Epoch [7/100], Iter [1020/3426] Loss: 0.1708 Acc: 93 %\n",
      "Epoch [7/100], Iter [1030/3426] Loss: 0.1879 Acc: 93 %\n",
      "Epoch [7/100], Iter [1040/3426] Loss: 0.2101 Acc: 93 %\n",
      "Epoch [7/100], Iter [1050/3426] Loss: 0.1918 Acc: 93 %\n",
      "Epoch [7/100], Iter [1060/3426] Loss: 0.1984 Acc: 93 %\n",
      "Epoch [7/100], Iter [1070/3426] Loss: 0.1831 Acc: 93 %\n",
      "Epoch [7/100], Iter [1080/3426] Loss: 0.1737 Acc: 93 %\n",
      "Epoch [7/100], Iter [1090/3426] Loss: 0.1793 Acc: 93 %\n",
      "Epoch [7/100], Iter [1100/3426] Loss: 0.1690 Acc: 93 %\n",
      "Epoch [7/100], Iter [1110/3426] Loss: 0.1851 Acc: 93 %\n",
      "Epoch [7/100], Iter [1120/3426] Loss: 0.1868 Acc: 93 %\n",
      "Epoch [7/100], Iter [1130/3426] Loss: 0.1785 Acc: 93 %\n",
      "Epoch [7/100], Iter [1140/3426] Loss: 0.2083 Acc: 93 %\n",
      "Epoch [7/100], Iter [1150/3426] Loss: 0.1792 Acc: 93 %\n",
      "Epoch [7/100], Iter [1160/3426] Loss: 0.1452 Acc: 93 %\n",
      "Epoch [7/100], Iter [1170/3426] Loss: 0.1532 Acc: 93 %\n",
      "Epoch [7/100], Iter [1180/3426] Loss: 0.1738 Acc: 93 %\n",
      "Epoch [7/100], Iter [1190/3426] Loss: 0.1689 Acc: 93 %\n",
      "Epoch [7/100], Iter [1200/3426] Loss: 0.1707 Acc: 93 %\n",
      "Epoch [7/100], Iter [1210/3426] Loss: 0.1502 Acc: 93 %\n",
      "Epoch [7/100], Iter [1220/3426] Loss: 0.1821 Acc: 93 %\n",
      "Epoch [7/100], Iter [1230/3426] Loss: 0.1597 Acc: 93 %\n",
      "Epoch [7/100], Iter [1240/3426] Loss: 0.1664 Acc: 93 %\n",
      "Epoch [7/100], Iter [1250/3426] Loss: 0.2031 Acc: 93 %\n",
      "Epoch [7/100], Iter [1260/3426] Loss: 0.1795 Acc: 93 %\n",
      "Epoch [7/100], Iter [1270/3426] Loss: 0.1833 Acc: 93 %\n",
      "Epoch [7/100], Iter [1280/3426] Loss: 0.1851 Acc: 93 %\n",
      "Epoch [7/100], Iter [1290/3426] Loss: 0.1546 Acc: 93 %\n",
      "Epoch [7/100], Iter [1300/3426] Loss: 0.1659 Acc: 93 %\n",
      "Epoch [7/100], Iter [1310/3426] Loss: 0.1893 Acc: 93 %\n",
      "Epoch [7/100], Iter [1320/3426] Loss: 0.1768 Acc: 93 %\n",
      "Epoch [7/100], Iter [1330/3426] Loss: 0.2262 Acc: 93 %\n",
      "Epoch [7/100], Iter [1340/3426] Loss: 0.1754 Acc: 93 %\n",
      "Epoch [7/100], Iter [1350/3426] Loss: 0.1761 Acc: 93 %\n",
      "Epoch [7/100], Iter [1360/3426] Loss: 0.1904 Acc: 93 %\n",
      "Epoch [7/100], Iter [1370/3426] Loss: 0.1781 Acc: 93 %\n",
      "Epoch [7/100], Iter [1380/3426] Loss: 0.1697 Acc: 93 %\n",
      "Epoch [7/100], Iter [1390/3426] Loss: 0.1729 Acc: 93 %\n",
      "Epoch [7/100], Iter [1400/3426] Loss: 0.1455 Acc: 93 %\n",
      "Epoch [7/100], Iter [1410/3426] Loss: 0.1695 Acc: 93 %\n",
      "Epoch [7/100], Iter [1420/3426] Loss: 0.1682 Acc: 93 %\n",
      "Epoch [7/100], Iter [1430/3426] Loss: 0.1499 Acc: 93 %\n",
      "Epoch [7/100], Iter [1440/3426] Loss: 0.1542 Acc: 93 %\n",
      "Epoch [7/100], Iter [1450/3426] Loss: 0.1738 Acc: 93 %\n",
      "Epoch [7/100], Iter [1460/3426] Loss: 0.1623 Acc: 93 %\n",
      "Epoch [7/100], Iter [1470/3426] Loss: 0.1720 Acc: 93 %\n",
      "Epoch [7/100], Iter [1480/3426] Loss: 0.1559 Acc: 93 %\n",
      "Epoch [7/100], Iter [1490/3426] Loss: 0.1570 Acc: 93 %\n",
      "Epoch [7/100], Iter [1500/3426] Loss: 0.1704 Acc: 93 %\n",
      "Epoch [7/100], Iter [1510/3426] Loss: 0.1861 Acc: 93 %\n",
      "Epoch [7/100], Iter [1520/3426] Loss: 0.1876 Acc: 93 %\n",
      "Epoch [7/100], Iter [1530/3426] Loss: 0.1689 Acc: 93 %\n",
      "Epoch [7/100], Iter [1540/3426] Loss: 0.1667 Acc: 93 %\n",
      "Epoch [7/100], Iter [1550/3426] Loss: 0.1423 Acc: 93 %\n",
      "Epoch [7/100], Iter [1560/3426] Loss: 0.1692 Acc: 93 %\n",
      "Epoch [7/100], Iter [1570/3426] Loss: 0.1829 Acc: 93 %\n",
      "Epoch [7/100], Iter [1580/3426] Loss: 0.1813 Acc: 93 %\n",
      "Epoch [7/100], Iter [1590/3426] Loss: 0.1865 Acc: 93 %\n",
      "Epoch [7/100], Iter [1600/3426] Loss: 0.1916 Acc: 93 %\n",
      "Epoch [7/100], Iter [1610/3426] Loss: 0.1863 Acc: 93 %\n",
      "Epoch [7/100], Iter [1620/3426] Loss: 0.1914 Acc: 93 %\n",
      "Epoch [7/100], Iter [1630/3426] Loss: 0.1623 Acc: 93 %\n",
      "Epoch [7/100], Iter [1640/3426] Loss: 0.2138 Acc: 93 %\n",
      "Epoch [7/100], Iter [1650/3426] Loss: 0.2156 Acc: 93 %\n",
      "Epoch [7/100], Iter [1660/3426] Loss: 0.1911 Acc: 93 %\n",
      "Epoch [7/100], Iter [1670/3426] Loss: 0.1995 Acc: 93 %\n",
      "Epoch [7/100], Iter [1680/3426] Loss: 0.1772 Acc: 93 %\n",
      "Epoch [7/100], Iter [1690/3426] Loss: 0.2002 Acc: 93 %\n",
      "Epoch [7/100], Iter [1700/3426] Loss: 0.2078 Acc: 93 %\n",
      "Epoch [7/100], Iter [1710/3426] Loss: 0.1810 Acc: 93 %\n",
      "Epoch [7/100], Iter [1720/3426] Loss: 0.1667 Acc: 93 %\n",
      "Epoch [7/100], Iter [1730/3426] Loss: 0.1665 Acc: 93 %\n",
      "Epoch [7/100], Iter [1740/3426] Loss: 0.1701 Acc: 93 %\n",
      "Epoch [7/100], Iter [1750/3426] Loss: 0.1799 Acc: 93 %\n",
      "Epoch [7/100], Iter [1760/3426] Loss: 0.1895 Acc: 93 %\n",
      "Epoch [7/100], Iter [1770/3426] Loss: 0.1710 Acc: 93 %\n",
      "Epoch [7/100], Iter [1780/3426] Loss: 0.1469 Acc: 93 %\n",
      "Epoch [7/100], Iter [1790/3426] Loss: 0.1492 Acc: 93 %\n",
      "Epoch [7/100], Iter [1800/3426] Loss: 0.1695 Acc: 93 %\n",
      "Epoch [7/100], Iter [1810/3426] Loss: 0.1944 Acc: 93 %\n",
      "Epoch [7/100], Iter [1820/3426] Loss: 0.1732 Acc: 93 %\n",
      "Epoch [7/100], Iter [1830/3426] Loss: 0.1630 Acc: 93 %\n",
      "Epoch [7/100], Iter [1840/3426] Loss: 0.1841 Acc: 93 %\n",
      "Epoch [7/100], Iter [1850/3426] Loss: 0.2327 Acc: 93 %\n",
      "Epoch [7/100], Iter [1860/3426] Loss: 0.1932 Acc: 93 %\n",
      "Epoch [7/100], Iter [1870/3426] Loss: 0.1809 Acc: 93 %\n",
      "Epoch [7/100], Iter [1880/3426] Loss: 0.1756 Acc: 93 %\n",
      "Epoch [7/100], Iter [1890/3426] Loss: 0.1899 Acc: 93 %\n",
      "Epoch [7/100], Iter [1900/3426] Loss: 0.1718 Acc: 93 %\n",
      "Epoch [7/100], Iter [1910/3426] Loss: 0.2063 Acc: 93 %\n",
      "Epoch [7/100], Iter [1920/3426] Loss: 0.1829 Acc: 93 %\n",
      "Epoch [7/100], Iter [1930/3426] Loss: 0.1785 Acc: 93 %\n",
      "Epoch [7/100], Iter [1940/3426] Loss: 0.1715 Acc: 93 %\n",
      "Epoch [7/100], Iter [1950/3426] Loss: 0.1842 Acc: 93 %\n",
      "Epoch [7/100], Iter [1960/3426] Loss: 0.2054 Acc: 93 %\n",
      "Epoch [7/100], Iter [1970/3426] Loss: 0.1695 Acc: 93 %\n",
      "Epoch [7/100], Iter [1980/3426] Loss: 0.1478 Acc: 93 %\n",
      "Epoch [7/100], Iter [1990/3426] Loss: 0.1754 Acc: 93 %\n",
      "Epoch [7/100], Iter [2000/3426] Loss: 0.1773 Acc: 93 %\n",
      "Epoch [7/100], Iter [2010/3426] Loss: 0.1431 Acc: 93 %\n",
      "Epoch [7/100], Iter [2020/3426] Loss: 0.2066 Acc: 93 %\n",
      "Epoch [7/100], Iter [2030/3426] Loss: 0.1605 Acc: 93 %\n",
      "Epoch [7/100], Iter [2040/3426] Loss: 0.1870 Acc: 93 %\n",
      "Epoch [7/100], Iter [2050/3426] Loss: 0.2871 Acc: 93 %\n",
      "Epoch [7/100], Iter [2060/3426] Loss: 0.1632 Acc: 93 %\n",
      "Epoch [7/100], Iter [2070/3426] Loss: 0.1857 Acc: 93 %\n",
      "Epoch [7/100], Iter [2080/3426] Loss: 0.1617 Acc: 93 %\n",
      "Epoch [7/100], Iter [2090/3426] Loss: 0.1905 Acc: 93 %\n",
      "Epoch [7/100], Iter [2100/3426] Loss: 0.1883 Acc: 93 %\n",
      "Epoch [7/100], Iter [2110/3426] Loss: 0.1830 Acc: 93 %\n",
      "Epoch [7/100], Iter [2120/3426] Loss: 0.1518 Acc: 93 %\n",
      "Epoch [7/100], Iter [2130/3426] Loss: 0.1965 Acc: 93 %\n",
      "Epoch [7/100], Iter [2140/3426] Loss: 0.1803 Acc: 93 %\n",
      "Epoch [7/100], Iter [2150/3426] Loss: 0.2174 Acc: 93 %\n",
      "Epoch [7/100], Iter [2160/3426] Loss: 0.1747 Acc: 93 %\n",
      "Epoch [7/100], Iter [2170/3426] Loss: 0.1697 Acc: 93 %\n",
      "Epoch [7/100], Iter [2180/3426] Loss: 0.1571 Acc: 93 %\n",
      "Epoch [7/100], Iter [2190/3426] Loss: 0.1659 Acc: 93 %\n",
      "Epoch [7/100], Iter [2200/3426] Loss: 0.1640 Acc: 93 %\n",
      "Epoch [7/100], Iter [2210/3426] Loss: 0.2032 Acc: 93 %\n",
      "Epoch [7/100], Iter [2220/3426] Loss: 0.2076 Acc: 93 %\n",
      "Epoch [7/100], Iter [2230/3426] Loss: 0.1672 Acc: 93 %\n",
      "Epoch [7/100], Iter [2240/3426] Loss: 0.2012 Acc: 93 %\n",
      "Epoch [7/100], Iter [2250/3426] Loss: 0.1714 Acc: 93 %\n",
      "Epoch [7/100], Iter [2260/3426] Loss: 0.1745 Acc: 93 %\n",
      "Epoch [7/100], Iter [2270/3426] Loss: 0.1539 Acc: 93 %\n",
      "Epoch [7/100], Iter [2280/3426] Loss: 0.1566 Acc: 93 %\n",
      "Epoch [7/100], Iter [2290/3426] Loss: 0.2022 Acc: 93 %\n",
      "Epoch [7/100], Iter [2300/3426] Loss: 0.1677 Acc: 93 %\n",
      "Epoch [7/100], Iter [2310/3426] Loss: 0.1823 Acc: 93 %\n",
      "Epoch [7/100], Iter [2320/3426] Loss: 0.1880 Acc: 93 %\n",
      "Epoch [7/100], Iter [2330/3426] Loss: 0.1859 Acc: 93 %\n",
      "Epoch [7/100], Iter [2340/3426] Loss: 0.1804 Acc: 93 %\n",
      "Epoch [7/100], Iter [2350/3426] Loss: 0.1873 Acc: 93 %\n",
      "Epoch [7/100], Iter [2360/3426] Loss: 0.1891 Acc: 93 %\n",
      "Epoch [7/100], Iter [2370/3426] Loss: 0.1919 Acc: 93 %\n",
      "Epoch [7/100], Iter [2380/3426] Loss: 0.1839 Acc: 93 %\n",
      "Epoch [7/100], Iter [2390/3426] Loss: 0.1639 Acc: 93 %\n",
      "Epoch [7/100], Iter [2400/3426] Loss: 0.1763 Acc: 93 %\n",
      "Epoch [7/100], Iter [2410/3426] Loss: 0.2006 Acc: 93 %\n",
      "Epoch [7/100], Iter [2420/3426] Loss: 0.1628 Acc: 93 %\n",
      "Epoch [7/100], Iter [2430/3426] Loss: 0.1945 Acc: 93 %\n",
      "Epoch [7/100], Iter [2440/3426] Loss: 0.1731 Acc: 93 %\n",
      "Epoch [7/100], Iter [2450/3426] Loss: 0.1443 Acc: 93 %\n",
      "Epoch [7/100], Iter [2460/3426] Loss: 0.1639 Acc: 93 %\n",
      "Epoch [7/100], Iter [2470/3426] Loss: 0.1567 Acc: 93 %\n",
      "Epoch [7/100], Iter [2480/3426] Loss: 0.1839 Acc: 93 %\n",
      "Epoch [7/100], Iter [2490/3426] Loss: 0.1576 Acc: 93 %\n",
      "Epoch [7/100], Iter [2500/3426] Loss: 0.1432 Acc: 93 %\n",
      "Epoch [7/100], Iter [2510/3426] Loss: 0.1900 Acc: 93 %\n",
      "Epoch [7/100], Iter [2520/3426] Loss: 0.1634 Acc: 93 %\n",
      "Epoch [7/100], Iter [2530/3426] Loss: 0.1652 Acc: 93 %\n",
      "Epoch [7/100], Iter [2540/3426] Loss: 0.1900 Acc: 93 %\n",
      "Epoch [7/100], Iter [2550/3426] Loss: 0.1780 Acc: 93 %\n",
      "Epoch [7/100], Iter [2560/3426] Loss: 0.2083 Acc: 93 %\n",
      "Epoch [7/100], Iter [2570/3426] Loss: 0.1651 Acc: 93 %\n",
      "Epoch [7/100], Iter [2580/3426] Loss: 0.1932 Acc: 93 %\n",
      "Epoch [7/100], Iter [2590/3426] Loss: 0.1594 Acc: 93 %\n",
      "Epoch [7/100], Iter [2600/3426] Loss: 0.2073 Acc: 93 %\n",
      "Epoch [7/100], Iter [2610/3426] Loss: 0.2333 Acc: 93 %\n",
      "Epoch [7/100], Iter [2620/3426] Loss: 0.1807 Acc: 93 %\n",
      "Epoch [7/100], Iter [2630/3426] Loss: 0.1683 Acc: 93 %\n",
      "Epoch [7/100], Iter [2640/3426] Loss: 0.1900 Acc: 93 %\n",
      "Epoch [7/100], Iter [2650/3426] Loss: 0.1868 Acc: 93 %\n",
      "Epoch [7/100], Iter [2660/3426] Loss: 0.2026 Acc: 93 %\n",
      "Epoch [7/100], Iter [2670/3426] Loss: 0.1871 Acc: 93 %\n",
      "Epoch [7/100], Iter [2680/3426] Loss: 0.2079 Acc: 93 %\n",
      "Epoch [7/100], Iter [2690/3426] Loss: 0.1853 Acc: 93 %\n",
      "Epoch [7/100], Iter [2700/3426] Loss: 0.2047 Acc: 93 %\n",
      "Epoch [7/100], Iter [2710/3426] Loss: 0.1872 Acc: 93 %\n",
      "Epoch [7/100], Iter [2720/3426] Loss: 0.1859 Acc: 93 %\n",
      "Epoch [7/100], Iter [2730/3426] Loss: 0.1836 Acc: 93 %\n",
      "Epoch [7/100], Iter [2740/3426] Loss: 0.1591 Acc: 93 %\n",
      "Epoch [7/100], Iter [2750/3426] Loss: 0.1840 Acc: 93 %\n",
      "Epoch [7/100], Iter [2760/3426] Loss: 0.1656 Acc: 93 %\n",
      "Epoch [7/100], Iter [2770/3426] Loss: 0.1619 Acc: 93 %\n",
      "Epoch [7/100], Iter [2780/3426] Loss: 0.1851 Acc: 93 %\n",
      "Epoch [7/100], Iter [2790/3426] Loss: 0.1718 Acc: 93 %\n",
      "Epoch [7/100], Iter [2800/3426] Loss: 0.1863 Acc: 93 %\n",
      "Epoch [7/100], Iter [2810/3426] Loss: 0.1813 Acc: 93 %\n",
      "Epoch [7/100], Iter [2820/3426] Loss: 0.1928 Acc: 93 %\n",
      "Epoch [7/100], Iter [2830/3426] Loss: 0.1690 Acc: 93 %\n",
      "Epoch [7/100], Iter [2840/3426] Loss: 0.1657 Acc: 93 %\n",
      "Epoch [7/100], Iter [2850/3426] Loss: 0.2083 Acc: 93 %\n",
      "Epoch [7/100], Iter [2860/3426] Loss: 0.1794 Acc: 93 %\n",
      "Epoch [7/100], Iter [2870/3426] Loss: 0.1664 Acc: 93 %\n",
      "Epoch [7/100], Iter [2880/3426] Loss: 0.1795 Acc: 93 %\n",
      "Epoch [7/100], Iter [2890/3426] Loss: 0.1647 Acc: 93 %\n",
      "Epoch [7/100], Iter [2900/3426] Loss: 0.1639 Acc: 93 %\n",
      "Epoch [7/100], Iter [2910/3426] Loss: 0.1659 Acc: 93 %\n",
      "Epoch [7/100], Iter [2920/3426] Loss: 0.2233 Acc: 93 %\n",
      "Epoch [7/100], Iter [2930/3426] Loss: 0.1728 Acc: 93 %\n",
      "Epoch [7/100], Iter [2940/3426] Loss: 0.1668 Acc: 93 %\n",
      "Epoch [7/100], Iter [2950/3426] Loss: 0.1629 Acc: 93 %\n",
      "Epoch [7/100], Iter [2960/3426] Loss: 0.1868 Acc: 93 %\n",
      "Epoch [7/100], Iter [2970/3426] Loss: 0.1681 Acc: 93 %\n",
      "Epoch [7/100], Iter [2980/3426] Loss: 0.1934 Acc: 93 %\n",
      "Epoch [7/100], Iter [2990/3426] Loss: 0.1772 Acc: 93 %\n",
      "Epoch [7/100], Iter [3000/3426] Loss: 0.1940 Acc: 93 %\n",
      "Epoch [7/100], Iter [3010/3426] Loss: 0.1773 Acc: 93 %\n",
      "Epoch [7/100], Iter [3020/3426] Loss: 0.1870 Acc: 93 %\n",
      "Epoch [7/100], Iter [3030/3426] Loss: 0.1587 Acc: 93 %\n",
      "Epoch [7/100], Iter [3040/3426] Loss: 0.1675 Acc: 93 %\n",
      "Epoch [7/100], Iter [3050/3426] Loss: 0.1800 Acc: 93 %\n",
      "Epoch [7/100], Iter [3060/3426] Loss: 0.1934 Acc: 93 %\n",
      "Epoch [7/100], Iter [3070/3426] Loss: 0.1701 Acc: 93 %\n",
      "Epoch [7/100], Iter [3080/3426] Loss: 0.1799 Acc: 93 %\n",
      "Epoch [7/100], Iter [3090/3426] Loss: 0.1902 Acc: 93 %\n",
      "Epoch [7/100], Iter [3100/3426] Loss: 0.1854 Acc: 93 %\n",
      "Epoch [7/100], Iter [3110/3426] Loss: 0.1728 Acc: 93 %\n",
      "Epoch [7/100], Iter [3120/3426] Loss: 0.1776 Acc: 93 %\n",
      "Epoch [7/100], Iter [3130/3426] Loss: 0.1857 Acc: 93 %\n",
      "Epoch [7/100], Iter [3140/3426] Loss: 0.1527 Acc: 93 %\n",
      "Epoch [7/100], Iter [3150/3426] Loss: 0.1732 Acc: 93 %\n",
      "Epoch [7/100], Iter [3160/3426] Loss: 0.1786 Acc: 93 %\n",
      "Epoch [7/100], Iter [3170/3426] Loss: 0.1402 Acc: 93 %\n",
      "Epoch [7/100], Iter [3180/3426] Loss: 0.2125 Acc: 93 %\n",
      "Epoch [7/100], Iter [3190/3426] Loss: 0.2204 Acc: 93 %\n",
      "Epoch [7/100], Iter [3200/3426] Loss: 0.1694 Acc: 93 %\n",
      "Epoch [7/100], Iter [3210/3426] Loss: 0.1972 Acc: 93 %\n",
      "Epoch [7/100], Iter [3220/3426] Loss: 0.1904 Acc: 93 %\n",
      "Epoch [7/100], Iter [3230/3426] Loss: 0.1857 Acc: 93 %\n",
      "Epoch [7/100], Iter [3240/3426] Loss: 0.2254 Acc: 93 %\n",
      "Epoch [7/100], Iter [3250/3426] Loss: 0.1928 Acc: 93 %\n",
      "Epoch [7/100], Iter [3260/3426] Loss: 0.1673 Acc: 93 %\n",
      "Epoch [7/100], Iter [3270/3426] Loss: 0.1776 Acc: 93 %\n",
      "Epoch [7/100], Iter [3280/3426] Loss: 0.2189 Acc: 93 %\n",
      "Epoch [7/100], Iter [3290/3426] Loss: 0.1632 Acc: 93 %\n",
      "Epoch [7/100], Iter [3300/3426] Loss: 0.1462 Acc: 93 %\n",
      "Epoch [7/100], Iter [3310/3426] Loss: 0.1632 Acc: 93 %\n",
      "Epoch [7/100], Iter [3320/3426] Loss: 0.1715 Acc: 93 %\n",
      "Epoch [7/100], Iter [3330/3426] Loss: 0.2957 Acc: 93 %\n",
      "Epoch [7/100], Iter [3340/3426] Loss: 0.1695 Acc: 93 %\n",
      "Epoch [7/100], Iter [3350/3426] Loss: 0.1837 Acc: 93 %\n",
      "Epoch [7/100], Iter [3360/3426] Loss: 0.1829 Acc: 93 %\n",
      "Epoch [7/100], Iter [3370/3426] Loss: 0.2059 Acc: 93 %\n",
      "Epoch [7/100], Iter [3380/3426] Loss: 0.1774 Acc: 93 %\n",
      "Epoch [7/100], Iter [3390/3426] Loss: 0.1726 Acc: 93 %\n",
      "Epoch [7/100], Iter [3400/3426] Loss: 0.1745 Acc: 93 %\n",
      "Epoch [7/100], Iter [3410/3426] Loss: 0.1794 Acc: 93 %\n",
      "Epoch [7/100], Iter [3420/3426] Loss: 0.1712 Acc: 93 %\n",
      "Accuracy of the model on the neg seq: 65 %\n",
      "Accuracy of the model on the pos seq: 99 %\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch [8/100], Iter [10/3426] Loss: 0.1748 Acc: 93 %\n",
      "Epoch [8/100], Iter [20/3426] Loss: 0.1678 Acc: 93 %\n",
      "Epoch [8/100], Iter [30/3426] Loss: 0.1369 Acc: 93 %\n",
      "Epoch [8/100], Iter [40/3426] Loss: 0.1725 Acc: 93 %\n",
      "Epoch [8/100], Iter [50/3426] Loss: 0.1445 Acc: 93 %\n",
      "Epoch [8/100], Iter [60/3426] Loss: 0.1511 Acc: 93 %\n",
      "Epoch [8/100], Iter [70/3426] Loss: 0.1797 Acc: 93 %\n",
      "Epoch [8/100], Iter [80/3426] Loss: 0.1876 Acc: 93 %\n",
      "Epoch [8/100], Iter [90/3426] Loss: 0.1654 Acc: 93 %\n",
      "Epoch [8/100], Iter [100/3426] Loss: 0.1674 Acc: 93 %\n",
      "Epoch [8/100], Iter [110/3426] Loss: 0.1603 Acc: 93 %\n",
      "Epoch [8/100], Iter [120/3426] Loss: 0.1764 Acc: 93 %\n",
      "Epoch [8/100], Iter [130/3426] Loss: 0.1890 Acc: 93 %\n",
      "Epoch [8/100], Iter [140/3426] Loss: 0.1861 Acc: 93 %\n",
      "Epoch [8/100], Iter [150/3426] Loss: 0.1733 Acc: 93 %\n",
      "Epoch [8/100], Iter [160/3426] Loss: 0.1534 Acc: 93 %\n",
      "Epoch [8/100], Iter [170/3426] Loss: 0.1637 Acc: 93 %\n",
      "Epoch [8/100], Iter [180/3426] Loss: 0.1783 Acc: 93 %\n",
      "Epoch [8/100], Iter [190/3426] Loss: 0.1745 Acc: 93 %\n",
      "Epoch [8/100], Iter [200/3426] Loss: 0.1917 Acc: 93 %\n",
      "Epoch [8/100], Iter [210/3426] Loss: 0.1455 Acc: 93 %\n",
      "Epoch [8/100], Iter [220/3426] Loss: 0.1594 Acc: 93 %\n",
      "Epoch [8/100], Iter [230/3426] Loss: 0.1470 Acc: 93 %\n",
      "Epoch [8/100], Iter [240/3426] Loss: 0.1556 Acc: 93 %\n",
      "Epoch [8/100], Iter [250/3426] Loss: 0.1288 Acc: 93 %\n",
      "Epoch [8/100], Iter [260/3426] Loss: 0.1587 Acc: 93 %\n",
      "Epoch [8/100], Iter [270/3426] Loss: 0.1568 Acc: 93 %\n",
      "Epoch [8/100], Iter [280/3426] Loss: 0.1802 Acc: 93 %\n",
      "Epoch [8/100], Iter [290/3426] Loss: 0.1470 Acc: 93 %\n",
      "Epoch [8/100], Iter [300/3426] Loss: 0.1740 Acc: 93 %\n",
      "Epoch [8/100], Iter [310/3426] Loss: 0.2220 Acc: 93 %\n",
      "Epoch [8/100], Iter [320/3426] Loss: 0.1586 Acc: 93 %\n",
      "Epoch [8/100], Iter [330/3426] Loss: 0.1630 Acc: 93 %\n",
      "Epoch [8/100], Iter [340/3426] Loss: 0.1486 Acc: 93 %\n",
      "Epoch [8/100], Iter [350/3426] Loss: 0.1719 Acc: 93 %\n",
      "Epoch [8/100], Iter [360/3426] Loss: 0.1757 Acc: 93 %\n",
      "Epoch [8/100], Iter [370/3426] Loss: 0.1601 Acc: 93 %\n",
      "Epoch [8/100], Iter [380/3426] Loss: 0.1592 Acc: 93 %\n",
      "Epoch [8/100], Iter [390/3426] Loss: 0.1618 Acc: 93 %\n",
      "Epoch [8/100], Iter [400/3426] Loss: 0.1997 Acc: 93 %\n",
      "Epoch [8/100], Iter [410/3426] Loss: 0.1774 Acc: 93 %\n",
      "Epoch [8/100], Iter [420/3426] Loss: 0.1482 Acc: 93 %\n",
      "Epoch [8/100], Iter [430/3426] Loss: 0.1872 Acc: 93 %\n",
      "Epoch [8/100], Iter [440/3426] Loss: 0.1525 Acc: 93 %\n",
      "Epoch [8/100], Iter [450/3426] Loss: 0.1783 Acc: 93 %\n",
      "Epoch [8/100], Iter [460/3426] Loss: 0.1885 Acc: 93 %\n",
      "Epoch [8/100], Iter [470/3426] Loss: 0.1638 Acc: 93 %\n",
      "Epoch [8/100], Iter [480/3426] Loss: 0.1604 Acc: 93 %\n",
      "Epoch [8/100], Iter [490/3426] Loss: 0.1490 Acc: 93 %\n",
      "Epoch [8/100], Iter [500/3426] Loss: 0.1475 Acc: 93 %\n",
      "Epoch [8/100], Iter [510/3426] Loss: 0.1569 Acc: 93 %\n",
      "Epoch [8/100], Iter [520/3426] Loss: 0.1364 Acc: 93 %\n",
      "Epoch [8/100], Iter [530/3426] Loss: 0.1923 Acc: 93 %\n",
      "Epoch [8/100], Iter [540/3426] Loss: 0.1594 Acc: 93 %\n",
      "Epoch [8/100], Iter [550/3426] Loss: 0.1867 Acc: 93 %\n",
      "Epoch [8/100], Iter [560/3426] Loss: 0.1793 Acc: 93 %\n",
      "Epoch [8/100], Iter [570/3426] Loss: 0.1421 Acc: 93 %\n",
      "Epoch [8/100], Iter [580/3426] Loss: 0.1450 Acc: 93 %\n",
      "Epoch [8/100], Iter [590/3426] Loss: 0.1806 Acc: 93 %\n",
      "Epoch [8/100], Iter [600/3426] Loss: 0.1500 Acc: 93 %\n",
      "Epoch [8/100], Iter [610/3426] Loss: 0.1706 Acc: 93 %\n",
      "Epoch [8/100], Iter [620/3426] Loss: 0.1567 Acc: 93 %\n",
      "Epoch [8/100], Iter [630/3426] Loss: 0.1711 Acc: 93 %\n",
      "Epoch [8/100], Iter [640/3426] Loss: 0.1478 Acc: 93 %\n",
      "Epoch [8/100], Iter [650/3426] Loss: 0.1649 Acc: 93 %\n",
      "Epoch [8/100], Iter [660/3426] Loss: 0.1779 Acc: 93 %\n",
      "Epoch [8/100], Iter [670/3426] Loss: 0.1572 Acc: 93 %\n",
      "Epoch [8/100], Iter [680/3426] Loss: 0.1669 Acc: 93 %\n",
      "Epoch [8/100], Iter [690/3426] Loss: 0.1673 Acc: 93 %\n",
      "Epoch [8/100], Iter [700/3426] Loss: 0.1679 Acc: 93 %\n",
      "Epoch [8/100], Iter [710/3426] Loss: 0.1671 Acc: 93 %\n",
      "Epoch [8/100], Iter [720/3426] Loss: 0.1820 Acc: 93 %\n",
      "Epoch [8/100], Iter [730/3426] Loss: 0.1754 Acc: 93 %\n",
      "Epoch [8/100], Iter [740/3426] Loss: 0.1808 Acc: 93 %\n",
      "Epoch [8/100], Iter [750/3426] Loss: 0.1850 Acc: 93 %\n",
      "Epoch [8/100], Iter [760/3426] Loss: 0.1673 Acc: 93 %\n",
      "Epoch [8/100], Iter [770/3426] Loss: 0.1420 Acc: 93 %\n",
      "Epoch [8/100], Iter [780/3426] Loss: 0.1641 Acc: 93 %\n",
      "Epoch [8/100], Iter [790/3426] Loss: 0.1987 Acc: 93 %\n",
      "Epoch [8/100], Iter [800/3426] Loss: 0.1467 Acc: 93 %\n",
      "Epoch [8/100], Iter [810/3426] Loss: 0.1595 Acc: 93 %\n",
      "Epoch [8/100], Iter [820/3426] Loss: 0.1709 Acc: 93 %\n",
      "Epoch [8/100], Iter [830/3426] Loss: 0.1462 Acc: 93 %\n",
      "Epoch [8/100], Iter [840/3426] Loss: 0.1497 Acc: 93 %\n",
      "Epoch [8/100], Iter [850/3426] Loss: 0.1735 Acc: 93 %\n",
      "Epoch [8/100], Iter [860/3426] Loss: 0.1482 Acc: 93 %\n",
      "Epoch [8/100], Iter [870/3426] Loss: 0.1649 Acc: 93 %\n",
      "Epoch [8/100], Iter [880/3426] Loss: 0.1752 Acc: 93 %\n",
      "Epoch [8/100], Iter [890/3426] Loss: 0.1624 Acc: 93 %\n",
      "Epoch [8/100], Iter [900/3426] Loss: 0.1547 Acc: 93 %\n",
      "Epoch [8/100], Iter [910/3426] Loss: 0.1476 Acc: 93 %\n",
      "Epoch [8/100], Iter [920/3426] Loss: 0.1589 Acc: 93 %\n",
      "Epoch [8/100], Iter [930/3426] Loss: 0.1726 Acc: 93 %\n",
      "Epoch [8/100], Iter [940/3426] Loss: 0.1832 Acc: 93 %\n",
      "Epoch [8/100], Iter [950/3426] Loss: 0.1851 Acc: 93 %\n",
      "Epoch [8/100], Iter [960/3426] Loss: 0.1593 Acc: 93 %\n",
      "Epoch [8/100], Iter [970/3426] Loss: 0.1687 Acc: 93 %\n",
      "Epoch [8/100], Iter [980/3426] Loss: 0.1415 Acc: 93 %\n",
      "Epoch [8/100], Iter [990/3426] Loss: 0.1747 Acc: 93 %\n",
      "Epoch [8/100], Iter [1000/3426] Loss: 0.1832 Acc: 93 %\n",
      "Epoch [8/100], Iter [1010/3426] Loss: 0.1646 Acc: 93 %\n",
      "Epoch [8/100], Iter [1020/3426] Loss: 0.1704 Acc: 93 %\n",
      "Epoch [8/100], Iter [1030/3426] Loss: 0.1552 Acc: 93 %\n",
      "Epoch [8/100], Iter [1040/3426] Loss: 0.1510 Acc: 93 %\n",
      "Epoch [8/100], Iter [1050/3426] Loss: 0.1867 Acc: 93 %\n",
      "Epoch [8/100], Iter [1060/3426] Loss: 0.1588 Acc: 93 %\n",
      "Epoch [8/100], Iter [1070/3426] Loss: 0.1639 Acc: 93 %\n",
      "Epoch [8/100], Iter [1080/3426] Loss: 0.1521 Acc: 93 %\n",
      "Epoch [8/100], Iter [1090/3426] Loss: 0.1661 Acc: 93 %\n",
      "Epoch [8/100], Iter [1100/3426] Loss: 0.1708 Acc: 93 %\n",
      "Epoch [8/100], Iter [1110/3426] Loss: 0.1673 Acc: 93 %\n",
      "Epoch [8/100], Iter [1120/3426] Loss: 0.1689 Acc: 93 %\n",
      "Epoch [8/100], Iter [1130/3426] Loss: 0.1894 Acc: 93 %\n",
      "Epoch [8/100], Iter [1140/3426] Loss: 0.1772 Acc: 93 %\n",
      "Epoch [8/100], Iter [1150/3426] Loss: 0.1651 Acc: 93 %\n",
      "Epoch [8/100], Iter [1160/3426] Loss: 0.1653 Acc: 93 %\n",
      "Epoch [8/100], Iter [1170/3426] Loss: 0.1516 Acc: 93 %\n",
      "Epoch [8/100], Iter [1180/3426] Loss: 0.1540 Acc: 93 %\n",
      "Epoch [8/100], Iter [1190/3426] Loss: 0.1812 Acc: 93 %\n",
      "Epoch [8/100], Iter [1200/3426] Loss: 0.1519 Acc: 93 %\n",
      "Epoch [8/100], Iter [1210/3426] Loss: 0.1596 Acc: 93 %\n",
      "Epoch [8/100], Iter [1220/3426] Loss: 0.1862 Acc: 93 %\n",
      "Epoch [8/100], Iter [1230/3426] Loss: 0.1917 Acc: 93 %\n",
      "Epoch [8/100], Iter [1240/3426] Loss: 0.1513 Acc: 93 %\n",
      "Epoch [8/100], Iter [1250/3426] Loss: 0.1964 Acc: 93 %\n",
      "Epoch [8/100], Iter [1260/3426] Loss: 0.1705 Acc: 93 %\n",
      "Epoch [8/100], Iter [1270/3426] Loss: 0.1386 Acc: 93 %\n",
      "Epoch [8/100], Iter [1280/3426] Loss: 0.1490 Acc: 93 %\n",
      "Epoch [8/100], Iter [1290/3426] Loss: 0.1629 Acc: 93 %\n",
      "Epoch [8/100], Iter [1300/3426] Loss: 0.1761 Acc: 93 %\n",
      "Epoch [8/100], Iter [1310/3426] Loss: 0.1525 Acc: 93 %\n",
      "Epoch [8/100], Iter [1320/3426] Loss: 0.1729 Acc: 93 %\n",
      "Epoch [8/100], Iter [1330/3426] Loss: 0.1700 Acc: 93 %\n",
      "Epoch [8/100], Iter [1340/3426] Loss: 0.1897 Acc: 93 %\n",
      "Epoch [8/100], Iter [1350/3426] Loss: 0.1706 Acc: 93 %\n",
      "Epoch [8/100], Iter [1360/3426] Loss: 0.1565 Acc: 93 %\n",
      "Epoch [8/100], Iter [1370/3426] Loss: 0.1384 Acc: 93 %\n",
      "Epoch [8/100], Iter [1380/3426] Loss: 0.1788 Acc: 93 %\n",
      "Epoch [8/100], Iter [1390/3426] Loss: 0.1689 Acc: 93 %\n",
      "Epoch [8/100], Iter [1400/3426] Loss: 0.1684 Acc: 93 %\n",
      "Epoch [8/100], Iter [1410/3426] Loss: 0.1927 Acc: 93 %\n",
      "Epoch [8/100], Iter [1420/3426] Loss: 0.1809 Acc: 93 %\n",
      "Epoch [8/100], Iter [1430/3426] Loss: 0.1495 Acc: 93 %\n",
      "Epoch [8/100], Iter [1440/3426] Loss: 0.1673 Acc: 93 %\n",
      "Epoch [8/100], Iter [1450/3426] Loss: 0.1694 Acc: 93 %\n",
      "Epoch [8/100], Iter [1460/3426] Loss: 0.1684 Acc: 93 %\n",
      "Epoch [8/100], Iter [1470/3426] Loss: 0.1594 Acc: 93 %\n",
      "Epoch [8/100], Iter [1480/3426] Loss: 0.1563 Acc: 93 %\n",
      "Epoch [8/100], Iter [1490/3426] Loss: 0.1635 Acc: 93 %\n",
      "Epoch [8/100], Iter [1500/3426] Loss: 0.2031 Acc: 93 %\n",
      "Epoch [8/100], Iter [1510/3426] Loss: 0.1718 Acc: 93 %\n",
      "Epoch [8/100], Iter [1520/3426] Loss: 0.1457 Acc: 93 %\n",
      "Epoch [8/100], Iter [1530/3426] Loss: 0.1510 Acc: 93 %\n",
      "Epoch [8/100], Iter [1540/3426] Loss: 0.1309 Acc: 93 %\n",
      "Epoch [8/100], Iter [1550/3426] Loss: 0.1809 Acc: 93 %\n",
      "Epoch [8/100], Iter [1560/3426] Loss: 0.1514 Acc: 93 %\n",
      "Epoch [8/100], Iter [1570/3426] Loss: 0.1792 Acc: 93 %\n",
      "Epoch [8/100], Iter [1580/3426] Loss: 0.1545 Acc: 93 %\n",
      "Epoch [8/100], Iter [1590/3426] Loss: 0.1786 Acc: 93 %\n",
      "Epoch [8/100], Iter [1600/3426] Loss: 0.1750 Acc: 93 %\n",
      "Epoch [8/100], Iter [1610/3426] Loss: 0.2152 Acc: 93 %\n",
      "Epoch [8/100], Iter [1620/3426] Loss: 0.1531 Acc: 93 %\n",
      "Epoch [8/100], Iter [1630/3426] Loss: 0.1562 Acc: 93 %\n",
      "Epoch [8/100], Iter [1640/3426] Loss: 0.1648 Acc: 93 %\n",
      "Epoch [8/100], Iter [1650/3426] Loss: 0.1605 Acc: 93 %\n",
      "Epoch [8/100], Iter [1660/3426] Loss: 0.1690 Acc: 93 %\n",
      "Epoch [8/100], Iter [1670/3426] Loss: 0.1714 Acc: 93 %\n",
      "Epoch [8/100], Iter [1680/3426] Loss: 0.1609 Acc: 93 %\n",
      "Epoch [8/100], Iter [1690/3426] Loss: 0.1681 Acc: 93 %\n",
      "Epoch [8/100], Iter [1700/3426] Loss: 0.1650 Acc: 93 %\n",
      "Epoch [8/100], Iter [1710/3426] Loss: 0.1649 Acc: 93 %\n",
      "Epoch [8/100], Iter [1720/3426] Loss: 0.1465 Acc: 93 %\n",
      "Epoch [8/100], Iter [1730/3426] Loss: 0.1587 Acc: 93 %\n",
      "Epoch [8/100], Iter [1740/3426] Loss: 0.1461 Acc: 93 %\n",
      "Epoch [8/100], Iter [1750/3426] Loss: 0.1426 Acc: 93 %\n",
      "Epoch [8/100], Iter [1760/3426] Loss: 0.1644 Acc: 93 %\n",
      "Epoch [8/100], Iter [1770/3426] Loss: 0.1686 Acc: 93 %\n",
      "Epoch [8/100], Iter [1780/3426] Loss: 0.1803 Acc: 93 %\n",
      "Epoch [8/100], Iter [1790/3426] Loss: 0.1626 Acc: 93 %\n",
      "Epoch [8/100], Iter [1800/3426] Loss: 0.1847 Acc: 93 %\n",
      "Epoch [8/100], Iter [1810/3426] Loss: 0.1864 Acc: 93 %\n",
      "Epoch [8/100], Iter [1820/3426] Loss: 0.1620 Acc: 93 %\n",
      "Epoch [8/100], Iter [1830/3426] Loss: 0.1452 Acc: 93 %\n",
      "Epoch [8/100], Iter [1840/3426] Loss: 0.1534 Acc: 93 %\n",
      "Epoch [8/100], Iter [1850/3426] Loss: 0.1570 Acc: 93 %\n",
      "Epoch [8/100], Iter [1860/3426] Loss: 0.1438 Acc: 93 %\n",
      "Epoch [8/100], Iter [1870/3426] Loss: 0.1372 Acc: 93 %\n",
      "Epoch [8/100], Iter [1880/3426] Loss: 0.1607 Acc: 93 %\n",
      "Epoch [8/100], Iter [1890/3426] Loss: 0.1436 Acc: 93 %\n",
      "Epoch [8/100], Iter [1900/3426] Loss: 0.1744 Acc: 93 %\n",
      "Epoch [8/100], Iter [1910/3426] Loss: 0.1563 Acc: 93 %\n",
      "Epoch [8/100], Iter [1920/3426] Loss: 0.1712 Acc: 93 %\n",
      "Epoch [8/100], Iter [1930/3426] Loss: 0.1608 Acc: 93 %\n",
      "Epoch [8/100], Iter [1940/3426] Loss: 0.1483 Acc: 93 %\n",
      "Epoch [8/100], Iter [1950/3426] Loss: 0.1334 Acc: 93 %\n",
      "Epoch [8/100], Iter [1960/3426] Loss: 0.1418 Acc: 93 %\n",
      "Epoch [8/100], Iter [1970/3426] Loss: 0.1324 Acc: 93 %\n",
      "Epoch [8/100], Iter [1980/3426] Loss: 0.1428 Acc: 93 %\n",
      "Epoch [8/100], Iter [1990/3426] Loss: 0.1443 Acc: 93 %\n",
      "Epoch [8/100], Iter [2000/3426] Loss: 0.1486 Acc: 93 %\n",
      "Epoch [8/100], Iter [2010/3426] Loss: 0.1567 Acc: 93 %\n",
      "Epoch [8/100], Iter [2020/3426] Loss: 0.1394 Acc: 93 %\n",
      "Epoch [8/100], Iter [2030/3426] Loss: 0.1842 Acc: 93 %\n",
      "Epoch [8/100], Iter [2040/3426] Loss: 0.1604 Acc: 93 %\n",
      "Epoch [8/100], Iter [2050/3426] Loss: 0.1753 Acc: 93 %\n",
      "Epoch [8/100], Iter [2060/3426] Loss: 0.1436 Acc: 93 %\n",
      "Epoch [8/100], Iter [2070/3426] Loss: 0.1384 Acc: 93 %\n",
      "Epoch [8/100], Iter [2080/3426] Loss: 0.1449 Acc: 93 %\n",
      "Epoch [8/100], Iter [2090/3426] Loss: 0.1532 Acc: 93 %\n",
      "Epoch [8/100], Iter [2100/3426] Loss: 0.1635 Acc: 93 %\n",
      "Epoch [8/100], Iter [2110/3426] Loss: 0.1726 Acc: 93 %\n",
      "Epoch [8/100], Iter [2120/3426] Loss: 0.1655 Acc: 93 %\n",
      "Epoch [8/100], Iter [2130/3426] Loss: 0.1659 Acc: 93 %\n",
      "Epoch [8/100], Iter [2140/3426] Loss: 0.1631 Acc: 93 %\n",
      "Epoch [8/100], Iter [2150/3426] Loss: 0.1756 Acc: 93 %\n",
      "Epoch [8/100], Iter [2160/3426] Loss: 0.1627 Acc: 93 %\n",
      "Epoch [8/100], Iter [2170/3426] Loss: 0.1632 Acc: 93 %\n",
      "Epoch [8/100], Iter [2180/3426] Loss: 0.1769 Acc: 93 %\n",
      "Epoch [8/100], Iter [2190/3426] Loss: 0.1342 Acc: 93 %\n",
      "Epoch [8/100], Iter [2200/3426] Loss: 0.1783 Acc: 93 %\n",
      "Epoch [8/100], Iter [2210/3426] Loss: 0.1505 Acc: 93 %\n",
      "Epoch [8/100], Iter [2220/3426] Loss: 0.1949 Acc: 93 %\n",
      "Epoch [8/100], Iter [2230/3426] Loss: 0.1616 Acc: 93 %\n",
      "Epoch [8/100], Iter [2240/3426] Loss: 0.2098 Acc: 93 %\n",
      "Epoch [8/100], Iter [2250/3426] Loss: 0.1681 Acc: 93 %\n",
      "Epoch [8/100], Iter [2260/3426] Loss: 0.1426 Acc: 93 %\n",
      "Epoch [8/100], Iter [2270/3426] Loss: 0.1600 Acc: 93 %\n",
      "Epoch [8/100], Iter [2280/3426] Loss: 0.1493 Acc: 93 %\n",
      "Epoch [8/100], Iter [2290/3426] Loss: 0.1564 Acc: 93 %\n",
      "Epoch [8/100], Iter [2300/3426] Loss: 0.1442 Acc: 93 %\n",
      "Epoch [8/100], Iter [2310/3426] Loss: 0.2003 Acc: 93 %\n",
      "Epoch [8/100], Iter [2320/3426] Loss: 0.1980 Acc: 93 %\n",
      "Epoch [8/100], Iter [2330/3426] Loss: 0.1456 Acc: 93 %\n",
      "Epoch [8/100], Iter [2340/3426] Loss: 0.1379 Acc: 93 %\n",
      "Epoch [8/100], Iter [2350/3426] Loss: 0.1608 Acc: 93 %\n",
      "Epoch [8/100], Iter [2360/3426] Loss: 0.1763 Acc: 93 %\n",
      "Epoch [8/100], Iter [2370/3426] Loss: 0.1576 Acc: 93 %\n",
      "Epoch [8/100], Iter [2380/3426] Loss: 0.1789 Acc: 93 %\n",
      "Epoch [8/100], Iter [2390/3426] Loss: 0.1720 Acc: 93 %\n",
      "Epoch [8/100], Iter [2400/3426] Loss: 0.1765 Acc: 93 %\n",
      "Epoch [8/100], Iter [2410/3426] Loss: 0.1604 Acc: 93 %\n",
      "Epoch [8/100], Iter [2420/3426] Loss: 0.1738 Acc: 93 %\n",
      "Epoch [8/100], Iter [2430/3426] Loss: 0.1605 Acc: 93 %\n",
      "Epoch [8/100], Iter [2440/3426] Loss: 0.1899 Acc: 93 %\n",
      "Epoch [8/100], Iter [2450/3426] Loss: 0.1628 Acc: 93 %\n",
      "Epoch [8/100], Iter [2460/3426] Loss: 0.1414 Acc: 93 %\n",
      "Epoch [8/100], Iter [2470/3426] Loss: 0.1867 Acc: 93 %\n",
      "Epoch [8/100], Iter [2480/3426] Loss: 0.1846 Acc: 93 %\n",
      "Epoch [8/100], Iter [2490/3426] Loss: 0.1758 Acc: 93 %\n",
      "Epoch [8/100], Iter [2500/3426] Loss: 0.1721 Acc: 93 %\n",
      "Epoch [8/100], Iter [2510/3426] Loss: 0.2027 Acc: 93 %\n",
      "Epoch [8/100], Iter [2520/3426] Loss: 0.1674 Acc: 93 %\n",
      "Epoch [8/100], Iter [2530/3426] Loss: 0.1639 Acc: 93 %\n",
      "Epoch [8/100], Iter [2540/3426] Loss: 0.1561 Acc: 93 %\n",
      "Epoch [8/100], Iter [2550/3426] Loss: 0.1697 Acc: 93 %\n",
      "Epoch [8/100], Iter [2560/3426] Loss: 0.1588 Acc: 93 %\n",
      "Epoch [8/100], Iter [2570/3426] Loss: 0.1587 Acc: 93 %\n",
      "Epoch [8/100], Iter [2580/3426] Loss: 0.1530 Acc: 93 %\n",
      "Epoch [8/100], Iter [2590/3426] Loss: 0.1612 Acc: 93 %\n",
      "Epoch [8/100], Iter [2600/3426] Loss: 0.1496 Acc: 93 %\n",
      "Epoch [8/100], Iter [2610/3426] Loss: 0.1736 Acc: 93 %\n",
      "Epoch [8/100], Iter [2620/3426] Loss: 0.1785 Acc: 93 %\n",
      "Epoch [8/100], Iter [2630/3426] Loss: 0.1698 Acc: 93 %\n",
      "Epoch [8/100], Iter [2640/3426] Loss: 0.1501 Acc: 93 %\n",
      "Epoch [8/100], Iter [2650/3426] Loss: 0.1651 Acc: 93 %\n",
      "Epoch [8/100], Iter [2660/3426] Loss: 0.1472 Acc: 93 %\n",
      "Epoch [8/100], Iter [2670/3426] Loss: 0.1504 Acc: 93 %\n",
      "Epoch [8/100], Iter [2680/3426] Loss: 0.1860 Acc: 93 %\n",
      "Epoch [8/100], Iter [2690/3426] Loss: 0.1524 Acc: 93 %\n",
      "Epoch [8/100], Iter [2700/3426] Loss: 0.1553 Acc: 93 %\n",
      "Epoch [8/100], Iter [2710/3426] Loss: 0.1610 Acc: 93 %\n",
      "Epoch [8/100], Iter [2720/3426] Loss: 0.1794 Acc: 93 %\n",
      "Epoch [8/100], Iter [2730/3426] Loss: 0.1711 Acc: 93 %\n",
      "Epoch [8/100], Iter [2740/3426] Loss: 0.1690 Acc: 93 %\n",
      "Epoch [8/100], Iter [2750/3426] Loss: 0.1759 Acc: 93 %\n",
      "Epoch [8/100], Iter [2760/3426] Loss: 0.1647 Acc: 93 %\n",
      "Epoch [8/100], Iter [2770/3426] Loss: 0.1629 Acc: 93 %\n",
      "Epoch [8/100], Iter [2780/3426] Loss: 0.1401 Acc: 93 %\n",
      "Epoch [8/100], Iter [2790/3426] Loss: 0.1960 Acc: 93 %\n",
      "Epoch [8/100], Iter [2800/3426] Loss: 0.2009 Acc: 93 %\n",
      "Epoch [8/100], Iter [2810/3426] Loss: 0.1731 Acc: 93 %\n",
      "Epoch [8/100], Iter [2820/3426] Loss: 0.1546 Acc: 93 %\n",
      "Epoch [8/100], Iter [2830/3426] Loss: 0.1484 Acc: 93 %\n",
      "Epoch [8/100], Iter [2840/3426] Loss: 0.1565 Acc: 93 %\n",
      "Epoch [8/100], Iter [2850/3426] Loss: 0.1735 Acc: 93 %\n",
      "Epoch [8/100], Iter [2860/3426] Loss: 0.1688 Acc: 93 %\n",
      "Epoch [8/100], Iter [2870/3426] Loss: 0.1748 Acc: 93 %\n",
      "Epoch [8/100], Iter [2880/3426] Loss: 0.1511 Acc: 93 %\n",
      "Epoch [8/100], Iter [2890/3426] Loss: 0.1631 Acc: 93 %\n",
      "Epoch [8/100], Iter [2900/3426] Loss: 0.1649 Acc: 93 %\n",
      "Epoch [8/100], Iter [2910/3426] Loss: 0.1738 Acc: 93 %\n",
      "Epoch [8/100], Iter [2920/3426] Loss: 0.1592 Acc: 93 %\n",
      "Epoch [8/100], Iter [2930/3426] Loss: 0.1859 Acc: 93 %\n",
      "Epoch [8/100], Iter [2940/3426] Loss: 0.1696 Acc: 93 %\n",
      "Epoch [8/100], Iter [2950/3426] Loss: 0.1571 Acc: 93 %\n",
      "Epoch [8/100], Iter [2960/3426] Loss: 0.1690 Acc: 93 %\n",
      "Epoch [8/100], Iter [2970/3426] Loss: 0.2596 Acc: 93 %\n",
      "Epoch [8/100], Iter [2980/3426] Loss: 0.1559 Acc: 93 %\n",
      "Epoch [8/100], Iter [2990/3426] Loss: 0.1771 Acc: 93 %\n",
      "Epoch [8/100], Iter [3000/3426] Loss: 0.1633 Acc: 93 %\n",
      "Epoch [8/100], Iter [3010/3426] Loss: 0.1523 Acc: 93 %\n",
      "Epoch [8/100], Iter [3020/3426] Loss: 0.1684 Acc: 93 %\n",
      "Epoch [8/100], Iter [3030/3426] Loss: 0.1531 Acc: 93 %\n",
      "Epoch [8/100], Iter [3040/3426] Loss: 0.1692 Acc: 93 %\n",
      "Epoch [8/100], Iter [3050/3426] Loss: 0.1663 Acc: 93 %\n",
      "Epoch [8/100], Iter [3060/3426] Loss: 0.1772 Acc: 93 %\n",
      "Epoch [8/100], Iter [3070/3426] Loss: 0.1480 Acc: 93 %\n",
      "Epoch [8/100], Iter [3080/3426] Loss: 0.2085 Acc: 93 %\n",
      "Epoch [8/100], Iter [3090/3426] Loss: 0.1643 Acc: 93 %\n",
      "Epoch [8/100], Iter [3100/3426] Loss: 0.1640 Acc: 93 %\n",
      "Epoch [8/100], Iter [3110/3426] Loss: 0.1647 Acc: 93 %\n",
      "Epoch [8/100], Iter [3120/3426] Loss: 0.1669 Acc: 93 %\n",
      "Epoch [8/100], Iter [3130/3426] Loss: 0.1630 Acc: 93 %\n",
      "Epoch [8/100], Iter [3140/3426] Loss: 0.1407 Acc: 93 %\n",
      "Epoch [8/100], Iter [3150/3426] Loss: 0.1495 Acc: 93 %\n",
      "Epoch [8/100], Iter [3160/3426] Loss: 0.1469 Acc: 93 %\n",
      "Epoch [8/100], Iter [3170/3426] Loss: 0.1664 Acc: 93 %\n",
      "Epoch [8/100], Iter [3180/3426] Loss: 0.1657 Acc: 93 %\n",
      "Epoch [8/100], Iter [3190/3426] Loss: 0.1815 Acc: 93 %\n",
      "Epoch [8/100], Iter [3200/3426] Loss: 0.1691 Acc: 93 %\n",
      "Epoch [8/100], Iter [3210/3426] Loss: 0.1501 Acc: 93 %\n",
      "Epoch [8/100], Iter [3220/3426] Loss: 0.1663 Acc: 93 %\n",
      "Epoch [8/100], Iter [3230/3426] Loss: 0.1726 Acc: 93 %\n",
      "Epoch [8/100], Iter [3240/3426] Loss: 0.1439 Acc: 93 %\n",
      "Epoch [8/100], Iter [3250/3426] Loss: 0.1812 Acc: 93 %\n",
      "Epoch [8/100], Iter [3260/3426] Loss: 0.1718 Acc: 93 %\n",
      "Epoch [8/100], Iter [3270/3426] Loss: 0.1480 Acc: 93 %\n",
      "Epoch [8/100], Iter [3280/3426] Loss: 0.1300 Acc: 93 %\n",
      "Epoch [8/100], Iter [3290/3426] Loss: 0.1385 Acc: 93 %\n",
      "Epoch [8/100], Iter [3300/3426] Loss: 0.1448 Acc: 93 %\n",
      "Epoch [8/100], Iter [3310/3426] Loss: 0.1434 Acc: 93 %\n",
      "Epoch [8/100], Iter [3320/3426] Loss: 0.1514 Acc: 93 %\n",
      "Epoch [8/100], Iter [3330/3426] Loss: 0.1445 Acc: 93 %\n",
      "Epoch [8/100], Iter [3340/3426] Loss: 0.1923 Acc: 93 %\n",
      "Epoch [8/100], Iter [3350/3426] Loss: 0.1611 Acc: 93 %\n",
      "Epoch [8/100], Iter [3360/3426] Loss: 0.1565 Acc: 93 %\n",
      "Epoch [8/100], Iter [3370/3426] Loss: 0.1764 Acc: 93 %\n",
      "Epoch [8/100], Iter [3380/3426] Loss: 0.1756 Acc: 93 %\n",
      "Epoch [8/100], Iter [3390/3426] Loss: 0.1841 Acc: 93 %\n",
      "Epoch [8/100], Iter [3400/3426] Loss: 0.1844 Acc: 93 %\n",
      "Epoch [8/100], Iter [3410/3426] Loss: 0.1465 Acc: 93 %\n",
      "Epoch [8/100], Iter [3420/3426] Loss: 0.1503 Acc: 93 %\n",
      "Accuracy of the model on the neg seq: 90 %\n",
      "Accuracy of the model on the pos seq: 95 %\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch [9/100], Iter [10/3426] Loss: 0.1304 Acc: 93 %\n",
      "Epoch [9/100], Iter [20/3426] Loss: 0.2004 Acc: 93 %\n",
      "Epoch [9/100], Iter [30/3426] Loss: 0.1433 Acc: 94 %\n",
      "Epoch [9/100], Iter [40/3426] Loss: 0.1691 Acc: 94 %\n",
      "Epoch [9/100], Iter [50/3426] Loss: 0.1621 Acc: 94 %\n",
      "Epoch [9/100], Iter [60/3426] Loss: 0.1602 Acc: 94 %\n",
      "Epoch [9/100], Iter [70/3426] Loss: 0.1503 Acc: 94 %\n",
      "Epoch [9/100], Iter [80/3426] Loss: 0.1535 Acc: 94 %\n",
      "Epoch [9/100], Iter [90/3426] Loss: 0.1411 Acc: 94 %\n",
      "Epoch [9/100], Iter [100/3426] Loss: 0.1682 Acc: 94 %\n",
      "Epoch [9/100], Iter [110/3426] Loss: 0.1489 Acc: 94 %\n",
      "Epoch [9/100], Iter [120/3426] Loss: 0.1642 Acc: 94 %\n",
      "Epoch [9/100], Iter [130/3426] Loss: 0.1804 Acc: 94 %\n",
      "Epoch [9/100], Iter [140/3426] Loss: 0.1720 Acc: 94 %\n",
      "Epoch [9/100], Iter [150/3426] Loss: 0.1497 Acc: 94 %\n",
      "Epoch [9/100], Iter [160/3426] Loss: 0.1590 Acc: 94 %\n",
      "Epoch [9/100], Iter [170/3426] Loss: 0.2130 Acc: 94 %\n",
      "Epoch [9/100], Iter [180/3426] Loss: 0.1750 Acc: 94 %\n",
      "Epoch [9/100], Iter [190/3426] Loss: 0.1614 Acc: 94 %\n",
      "Epoch [9/100], Iter [200/3426] Loss: 0.1774 Acc: 94 %\n",
      "Epoch [9/100], Iter [210/3426] Loss: 0.1614 Acc: 94 %\n",
      "Epoch [9/100], Iter [220/3426] Loss: 0.1436 Acc: 94 %\n",
      "Epoch [9/100], Iter [230/3426] Loss: 0.1522 Acc: 94 %\n",
      "Epoch [9/100], Iter [240/3426] Loss: 0.1679 Acc: 94 %\n",
      "Epoch [9/100], Iter [250/3426] Loss: 0.1754 Acc: 94 %\n",
      "Epoch [9/100], Iter [260/3426] Loss: 0.1355 Acc: 94 %\n",
      "Epoch [9/100], Iter [270/3426] Loss: 0.1512 Acc: 94 %\n",
      "Epoch [9/100], Iter [280/3426] Loss: 0.1543 Acc: 94 %\n",
      "Epoch [9/100], Iter [290/3426] Loss: 0.1302 Acc: 94 %\n",
      "Epoch [9/100], Iter [300/3426] Loss: 0.1871 Acc: 94 %\n",
      "Epoch [9/100], Iter [310/3426] Loss: 0.1867 Acc: 94 %\n",
      "Epoch [9/100], Iter [320/3426] Loss: 0.1701 Acc: 94 %\n",
      "Epoch [9/100], Iter [330/3426] Loss: 0.1665 Acc: 94 %\n",
      "Epoch [9/100], Iter [340/3426] Loss: 0.1557 Acc: 94 %\n",
      "Epoch [9/100], Iter [350/3426] Loss: 0.1596 Acc: 94 %\n",
      "Epoch [9/100], Iter [360/3426] Loss: 0.1834 Acc: 94 %\n",
      "Epoch [9/100], Iter [370/3426] Loss: 0.1581 Acc: 94 %\n",
      "Epoch [9/100], Iter [380/3426] Loss: 0.1508 Acc: 94 %\n",
      "Epoch [9/100], Iter [390/3426] Loss: 0.1512 Acc: 94 %\n",
      "Epoch [9/100], Iter [400/3426] Loss: 0.1500 Acc: 94 %\n",
      "Epoch [9/100], Iter [410/3426] Loss: 0.1389 Acc: 94 %\n",
      "Epoch [9/100], Iter [420/3426] Loss: 0.1433 Acc: 94 %\n",
      "Epoch [9/100], Iter [430/3426] Loss: 0.1855 Acc: 94 %\n",
      "Epoch [9/100], Iter [440/3426] Loss: 0.1561 Acc: 94 %\n",
      "Epoch [9/100], Iter [450/3426] Loss: 0.1485 Acc: 94 %\n",
      "Epoch [9/100], Iter [460/3426] Loss: 0.1995 Acc: 94 %\n",
      "Epoch [9/100], Iter [470/3426] Loss: 0.1949 Acc: 94 %\n",
      "Epoch [9/100], Iter [480/3426] Loss: 0.1353 Acc: 94 %\n",
      "Epoch [9/100], Iter [490/3426] Loss: 0.1626 Acc: 94 %\n",
      "Epoch [9/100], Iter [500/3426] Loss: 0.1309 Acc: 94 %\n",
      "Epoch [9/100], Iter [510/3426] Loss: 0.1484 Acc: 94 %\n",
      "Epoch [9/100], Iter [520/3426] Loss: 0.1733 Acc: 94 %\n",
      "Epoch [9/100], Iter [530/3426] Loss: 0.1813 Acc: 94 %\n",
      "Epoch [9/100], Iter [540/3426] Loss: 0.1459 Acc: 94 %\n",
      "Epoch [9/100], Iter [550/3426] Loss: 0.1619 Acc: 94 %\n",
      "Epoch [9/100], Iter [560/3426] Loss: 0.1569 Acc: 94 %\n",
      "Epoch [9/100], Iter [570/3426] Loss: 0.1592 Acc: 94 %\n",
      "Epoch [9/100], Iter [580/3426] Loss: 0.1401 Acc: 94 %\n",
      "Epoch [9/100], Iter [590/3426] Loss: 0.1521 Acc: 94 %\n",
      "Epoch [9/100], Iter [600/3426] Loss: 0.1514 Acc: 94 %\n",
      "Epoch [9/100], Iter [610/3426] Loss: 0.1388 Acc: 94 %\n",
      "Epoch [9/100], Iter [620/3426] Loss: 0.1425 Acc: 94 %\n",
      "Epoch [9/100], Iter [630/3426] Loss: 0.1431 Acc: 94 %\n",
      "Epoch [9/100], Iter [640/3426] Loss: 0.1648 Acc: 94 %\n",
      "Epoch [9/100], Iter [650/3426] Loss: 0.1331 Acc: 94 %\n",
      "Epoch [9/100], Iter [660/3426] Loss: 0.1515 Acc: 94 %\n",
      "Epoch [9/100], Iter [670/3426] Loss: 0.1555 Acc: 94 %\n",
      "Epoch [9/100], Iter [680/3426] Loss: 0.1566 Acc: 94 %\n",
      "Epoch [9/100], Iter [690/3426] Loss: 0.1370 Acc: 94 %\n",
      "Epoch [9/100], Iter [700/3426] Loss: 0.1859 Acc: 94 %\n",
      "Epoch [9/100], Iter [710/3426] Loss: 0.1534 Acc: 94 %\n",
      "Epoch [9/100], Iter [720/3426] Loss: 0.1586 Acc: 94 %\n",
      "Epoch [9/100], Iter [730/3426] Loss: 0.1973 Acc: 94 %\n",
      "Epoch [9/100], Iter [740/3426] Loss: 0.1544 Acc: 94 %\n",
      "Epoch [9/100], Iter [750/3426] Loss: 0.1476 Acc: 94 %\n",
      "Epoch [9/100], Iter [760/3426] Loss: 0.1774 Acc: 94 %\n",
      "Epoch [9/100], Iter [770/3426] Loss: 0.1705 Acc: 94 %\n",
      "Epoch [9/100], Iter [780/3426] Loss: 0.1767 Acc: 94 %\n",
      "Epoch [9/100], Iter [790/3426] Loss: 0.1299 Acc: 94 %\n",
      "Epoch [9/100], Iter [800/3426] Loss: 0.1542 Acc: 94 %\n",
      "Epoch [9/100], Iter [810/3426] Loss: 0.1860 Acc: 94 %\n",
      "Epoch [9/100], Iter [820/3426] Loss: 0.1736 Acc: 94 %\n",
      "Epoch [9/100], Iter [830/3426] Loss: 0.1629 Acc: 94 %\n",
      "Epoch [9/100], Iter [840/3426] Loss: 0.1403 Acc: 94 %\n",
      "Epoch [9/100], Iter [850/3426] Loss: 0.1838 Acc: 94 %\n",
      "Epoch [9/100], Iter [860/3426] Loss: 0.1547 Acc: 94 %\n",
      "Epoch [9/100], Iter [870/3426] Loss: 0.1428 Acc: 94 %\n",
      "Epoch [9/100], Iter [880/3426] Loss: 0.1495 Acc: 94 %\n",
      "Epoch [9/100], Iter [890/3426] Loss: 0.1599 Acc: 94 %\n",
      "Epoch [9/100], Iter [900/3426] Loss: 0.1795 Acc: 94 %\n",
      "Epoch [9/100], Iter [910/3426] Loss: 0.1625 Acc: 94 %\n",
      "Epoch [9/100], Iter [920/3426] Loss: 0.1483 Acc: 94 %\n",
      "Epoch [9/100], Iter [930/3426] Loss: 0.1503 Acc: 94 %\n",
      "Epoch [9/100], Iter [940/3426] Loss: 0.1513 Acc: 94 %\n",
      "Epoch [9/100], Iter [950/3426] Loss: 0.1723 Acc: 94 %\n",
      "Epoch [9/100], Iter [960/3426] Loss: 0.1677 Acc: 94 %\n",
      "Epoch [9/100], Iter [970/3426] Loss: 0.1681 Acc: 94 %\n",
      "Epoch [9/100], Iter [980/3426] Loss: 0.1704 Acc: 94 %\n",
      "Epoch [9/100], Iter [990/3426] Loss: 0.1909 Acc: 94 %\n",
      "Epoch [9/100], Iter [1000/3426] Loss: 0.1516 Acc: 94 %\n",
      "Epoch [9/100], Iter [1010/3426] Loss: 0.1783 Acc: 94 %\n",
      "Epoch [9/100], Iter [1020/3426] Loss: 0.1558 Acc: 94 %\n",
      "Epoch [9/100], Iter [1030/3426] Loss: 0.1594 Acc: 94 %\n",
      "Epoch [9/100], Iter [1040/3426] Loss: 0.1506 Acc: 94 %\n",
      "Epoch [9/100], Iter [1050/3426] Loss: 0.1477 Acc: 94 %\n",
      "Epoch [9/100], Iter [1060/3426] Loss: 0.1381 Acc: 94 %\n",
      "Epoch [9/100], Iter [1070/3426] Loss: 0.1719 Acc: 94 %\n",
      "Epoch [9/100], Iter [1080/3426] Loss: 0.1821 Acc: 94 %\n",
      "Epoch [9/100], Iter [1090/3426] Loss: 0.1561 Acc: 94 %\n",
      "Epoch [9/100], Iter [1100/3426] Loss: 0.1445 Acc: 94 %\n",
      "Epoch [9/100], Iter [1110/3426] Loss: 0.1565 Acc: 94 %\n",
      "Epoch [9/100], Iter [1120/3426] Loss: 0.1488 Acc: 94 %\n",
      "Epoch [9/100], Iter [1130/3426] Loss: 0.1638 Acc: 94 %\n",
      "Epoch [9/100], Iter [1140/3426] Loss: 0.1685 Acc: 94 %\n",
      "Epoch [9/100], Iter [1150/3426] Loss: 0.1649 Acc: 94 %\n",
      "Epoch [9/100], Iter [1160/3426] Loss: 0.1604 Acc: 94 %\n",
      "Epoch [9/100], Iter [1170/3426] Loss: 0.1910 Acc: 94 %\n",
      "Epoch [9/100], Iter [1180/3426] Loss: 0.1801 Acc: 94 %\n",
      "Epoch [9/100], Iter [1190/3426] Loss: 0.1602 Acc: 94 %\n",
      "Epoch [9/100], Iter [1200/3426] Loss: 0.1788 Acc: 94 %\n",
      "Epoch [9/100], Iter [1210/3426] Loss: 0.1657 Acc: 94 %\n",
      "Epoch [9/100], Iter [1220/3426] Loss: 0.1608 Acc: 94 %\n",
      "Epoch [9/100], Iter [1230/3426] Loss: 0.1540 Acc: 94 %\n",
      "Epoch [9/100], Iter [1240/3426] Loss: 0.1698 Acc: 94 %\n",
      "Epoch [9/100], Iter [1250/3426] Loss: 0.1508 Acc: 94 %\n",
      "Epoch [9/100], Iter [1260/3426] Loss: 0.1695 Acc: 94 %\n",
      "Epoch [9/100], Iter [1270/3426] Loss: 0.1655 Acc: 94 %\n",
      "Epoch [9/100], Iter [1280/3426] Loss: 0.1486 Acc: 94 %\n",
      "Epoch [9/100], Iter [1290/3426] Loss: 0.1466 Acc: 94 %\n",
      "Epoch [9/100], Iter [1300/3426] Loss: 0.1839 Acc: 94 %\n",
      "Epoch [9/100], Iter [1310/3426] Loss: 0.1449 Acc: 94 %\n",
      "Epoch [9/100], Iter [1320/3426] Loss: 0.1522 Acc: 94 %\n",
      "Epoch [9/100], Iter [1330/3426] Loss: 0.1742 Acc: 94 %\n",
      "Epoch [9/100], Iter [1340/3426] Loss: 0.1365 Acc: 94 %\n",
      "Epoch [9/100], Iter [1350/3426] Loss: 0.1712 Acc: 94 %\n",
      "Epoch [9/100], Iter [1360/3426] Loss: 0.1644 Acc: 94 %\n",
      "Epoch [9/100], Iter [1370/3426] Loss: 0.1662 Acc: 94 %\n",
      "Epoch [9/100], Iter [1380/3426] Loss: 0.1739 Acc: 94 %\n",
      "Epoch [9/100], Iter [1390/3426] Loss: 0.1606 Acc: 94 %\n",
      "Epoch [9/100], Iter [1400/3426] Loss: 0.1900 Acc: 94 %\n",
      "Epoch [9/100], Iter [1410/3426] Loss: 0.1443 Acc: 94 %\n",
      "Epoch [9/100], Iter [1420/3426] Loss: 0.1530 Acc: 94 %\n",
      "Epoch [9/100], Iter [1430/3426] Loss: 0.1571 Acc: 94 %\n",
      "Epoch [9/100], Iter [1440/3426] Loss: 0.1676 Acc: 94 %\n",
      "Epoch [9/100], Iter [1450/3426] Loss: 0.1732 Acc: 94 %\n",
      "Epoch [9/100], Iter [1460/3426] Loss: 0.1763 Acc: 94 %\n",
      "Epoch [9/100], Iter [1470/3426] Loss: 0.1798 Acc: 94 %\n",
      "Epoch [9/100], Iter [1480/3426] Loss: 0.1694 Acc: 94 %\n",
      "Epoch [9/100], Iter [1490/3426] Loss: 0.1707 Acc: 94 %\n",
      "Epoch [9/100], Iter [1500/3426] Loss: 0.1781 Acc: 94 %\n",
      "Epoch [9/100], Iter [1510/3426] Loss: 0.1766 Acc: 94 %\n",
      "Epoch [9/100], Iter [1520/3426] Loss: 0.1581 Acc: 94 %\n",
      "Epoch [9/100], Iter [1530/3426] Loss: 0.1776 Acc: 94 %\n",
      "Epoch [9/100], Iter [1540/3426] Loss: 0.1467 Acc: 94 %\n",
      "Epoch [9/100], Iter [1550/3426] Loss: 0.1715 Acc: 94 %\n",
      "Epoch [9/100], Iter [1560/3426] Loss: 0.1651 Acc: 94 %\n",
      "Epoch [9/100], Iter [1570/3426] Loss: 0.2026 Acc: 94 %\n",
      "Epoch [9/100], Iter [1580/3426] Loss: 0.1718 Acc: 94 %\n",
      "Epoch [9/100], Iter [1590/3426] Loss: 0.1753 Acc: 94 %\n",
      "Epoch [9/100], Iter [1600/3426] Loss: 0.1789 Acc: 94 %\n",
      "Epoch [9/100], Iter [1610/3426] Loss: 0.1493 Acc: 94 %\n",
      "Epoch [9/100], Iter [1620/3426] Loss: 0.1842 Acc: 94 %\n",
      "Epoch [9/100], Iter [1630/3426] Loss: 0.1341 Acc: 94 %\n",
      "Epoch [9/100], Iter [1640/3426] Loss: 0.1540 Acc: 94 %\n",
      "Epoch [9/100], Iter [1650/3426] Loss: 0.1768 Acc: 94 %\n",
      "Epoch [9/100], Iter [1660/3426] Loss: 0.1497 Acc: 94 %\n",
      "Epoch [9/100], Iter [1670/3426] Loss: 0.1744 Acc: 94 %\n",
      "Epoch [9/100], Iter [1680/3426] Loss: 0.1540 Acc: 94 %\n",
      "Epoch [9/100], Iter [1690/3426] Loss: 0.1575 Acc: 94 %\n",
      "Epoch [9/100], Iter [1700/3426] Loss: 0.1771 Acc: 94 %\n",
      "Epoch [9/100], Iter [1710/3426] Loss: 0.1423 Acc: 94 %\n",
      "Epoch [9/100], Iter [1720/3426] Loss: 0.1721 Acc: 94 %\n",
      "Epoch [9/100], Iter [1730/3426] Loss: 0.1969 Acc: 94 %\n",
      "Epoch [9/100], Iter [1740/3426] Loss: 0.1578 Acc: 94 %\n",
      "Epoch [9/100], Iter [1750/3426] Loss: 0.1640 Acc: 94 %\n",
      "Epoch [9/100], Iter [1760/3426] Loss: 0.1601 Acc: 94 %\n",
      "Epoch [9/100], Iter [1770/3426] Loss: 0.1685 Acc: 94 %\n",
      "Epoch [9/100], Iter [1780/3426] Loss: 0.1657 Acc: 94 %\n",
      "Epoch [9/100], Iter [1790/3426] Loss: 0.1333 Acc: 94 %\n",
      "Epoch [9/100], Iter [1800/3426] Loss: 0.1401 Acc: 94 %\n",
      "Epoch [9/100], Iter [1810/3426] Loss: 0.1744 Acc: 94 %\n",
      "Epoch [9/100], Iter [1820/3426] Loss: 0.1601 Acc: 94 %\n",
      "Epoch [9/100], Iter [1830/3426] Loss: 0.1538 Acc: 94 %\n",
      "Epoch [9/100], Iter [1840/3426] Loss: 0.1532 Acc: 94 %\n",
      "Epoch [9/100], Iter [1850/3426] Loss: 0.1309 Acc: 94 %\n",
      "Epoch [9/100], Iter [1860/3426] Loss: 0.1502 Acc: 94 %\n",
      "Epoch [9/100], Iter [1870/3426] Loss: 0.1485 Acc: 94 %\n",
      "Epoch [9/100], Iter [1880/3426] Loss: 0.1547 Acc: 94 %\n",
      "Epoch [9/100], Iter [1890/3426] Loss: 0.1494 Acc: 94 %\n",
      "Epoch [9/100], Iter [1900/3426] Loss: 0.1696 Acc: 94 %\n",
      "Epoch [9/100], Iter [1910/3426] Loss: 0.1734 Acc: 94 %\n",
      "Epoch [9/100], Iter [1920/3426] Loss: 0.1381 Acc: 94 %\n",
      "Epoch [9/100], Iter [1930/3426] Loss: 0.1428 Acc: 94 %\n",
      "Epoch [9/100], Iter [1940/3426] Loss: 0.1681 Acc: 94 %\n",
      "Epoch [9/100], Iter [1950/3426] Loss: 0.1462 Acc: 94 %\n",
      "Epoch [9/100], Iter [1960/3426] Loss: 0.1884 Acc: 94 %\n",
      "Epoch [9/100], Iter [1970/3426] Loss: 0.1635 Acc: 94 %\n",
      "Epoch [9/100], Iter [1980/3426] Loss: 0.1682 Acc: 94 %\n",
      "Epoch [9/100], Iter [1990/3426] Loss: 0.1693 Acc: 94 %\n",
      "Epoch [9/100], Iter [2000/3426] Loss: 0.1502 Acc: 94 %\n",
      "Epoch [9/100], Iter [2010/3426] Loss: 0.1599 Acc: 94 %\n",
      "Epoch [9/100], Iter [2020/3426] Loss: 0.1338 Acc: 94 %\n",
      "Epoch [9/100], Iter [2030/3426] Loss: 0.1360 Acc: 94 %\n",
      "Epoch [9/100], Iter [2040/3426] Loss: 0.1384 Acc: 94 %\n",
      "Epoch [9/100], Iter [2050/3426] Loss: 0.1302 Acc: 94 %\n",
      "Epoch [9/100], Iter [2060/3426] Loss: 0.1550 Acc: 94 %\n",
      "Epoch [9/100], Iter [2070/3426] Loss: 0.1498 Acc: 94 %\n",
      "Epoch [9/100], Iter [2080/3426] Loss: 0.1522 Acc: 94 %\n",
      "Epoch [9/100], Iter [2090/3426] Loss: 0.1648 Acc: 94 %\n",
      "Epoch [9/100], Iter [2100/3426] Loss: 0.1790 Acc: 94 %\n",
      "Epoch [9/100], Iter [2110/3426] Loss: 0.1673 Acc: 94 %\n",
      "Epoch [9/100], Iter [2120/3426] Loss: 0.1414 Acc: 94 %\n",
      "Epoch [9/100], Iter [2130/3426] Loss: 0.1585 Acc: 94 %\n",
      "Epoch [9/100], Iter [2140/3426] Loss: 0.1671 Acc: 94 %\n",
      "Epoch [9/100], Iter [2150/3426] Loss: 0.1646 Acc: 94 %\n",
      "Epoch [9/100], Iter [2160/3426] Loss: 0.1745 Acc: 94 %\n",
      "Epoch [9/100], Iter [2170/3426] Loss: 0.1714 Acc: 94 %\n",
      "Epoch [9/100], Iter [2180/3426] Loss: 0.1495 Acc: 94 %\n",
      "Epoch [9/100], Iter [2190/3426] Loss: 0.1642 Acc: 94 %\n",
      "Epoch [9/100], Iter [2200/3426] Loss: 0.1282 Acc: 94 %\n",
      "Epoch [9/100], Iter [2210/3426] Loss: 0.1879 Acc: 94 %\n",
      "Epoch [9/100], Iter [2220/3426] Loss: 0.1353 Acc: 94 %\n",
      "Epoch [9/100], Iter [2230/3426] Loss: 0.1655 Acc: 94 %\n",
      "Epoch [9/100], Iter [2240/3426] Loss: 0.1750 Acc: 94 %\n",
      "Epoch [9/100], Iter [2250/3426] Loss: 0.1672 Acc: 94 %\n",
      "Epoch [9/100], Iter [2260/3426] Loss: 0.1695 Acc: 94 %\n",
      "Epoch [9/100], Iter [2270/3426] Loss: 0.1448 Acc: 94 %\n",
      "Epoch [9/100], Iter [2280/3426] Loss: 0.1523 Acc: 94 %\n",
      "Epoch [9/100], Iter [2290/3426] Loss: 0.1870 Acc: 94 %\n",
      "Epoch [9/100], Iter [2300/3426] Loss: 0.1264 Acc: 94 %\n",
      "Epoch [9/100], Iter [2310/3426] Loss: 0.1479 Acc: 94 %\n",
      "Epoch [9/100], Iter [2320/3426] Loss: 0.1653 Acc: 94 %\n",
      "Epoch [9/100], Iter [2330/3426] Loss: 0.1693 Acc: 94 %\n",
      "Epoch [9/100], Iter [2340/3426] Loss: 0.1828 Acc: 94 %\n",
      "Epoch [9/100], Iter [2350/3426] Loss: 0.1603 Acc: 94 %\n",
      "Epoch [9/100], Iter [2360/3426] Loss: 0.1717 Acc: 94 %\n",
      "Epoch [9/100], Iter [2370/3426] Loss: 0.1768 Acc: 94 %\n",
      "Epoch [9/100], Iter [2380/3426] Loss: 0.1691 Acc: 94 %\n",
      "Epoch [9/100], Iter [2390/3426] Loss: 0.1521 Acc: 94 %\n",
      "Epoch [9/100], Iter [2400/3426] Loss: 0.1679 Acc: 94 %\n",
      "Epoch [9/100], Iter [2410/3426] Loss: 0.1625 Acc: 94 %\n",
      "Epoch [9/100], Iter [2420/3426] Loss: 0.1775 Acc: 94 %\n",
      "Epoch [9/100], Iter [2430/3426] Loss: 0.1884 Acc: 94 %\n",
      "Epoch [9/100], Iter [2440/3426] Loss: 0.1332 Acc: 94 %\n",
      "Epoch [9/100], Iter [2450/3426] Loss: 0.1410 Acc: 94 %\n",
      "Epoch [9/100], Iter [2460/3426] Loss: 0.1524 Acc: 94 %\n",
      "Epoch [9/100], Iter [2470/3426] Loss: 0.1658 Acc: 94 %\n",
      "Epoch [9/100], Iter [2480/3426] Loss: 0.1529 Acc: 94 %\n",
      "Epoch [9/100], Iter [2490/3426] Loss: 0.1759 Acc: 94 %\n",
      "Epoch [9/100], Iter [2500/3426] Loss: 0.1639 Acc: 94 %\n",
      "Epoch [9/100], Iter [2510/3426] Loss: 0.1789 Acc: 94 %\n",
      "Epoch [9/100], Iter [2520/3426] Loss: 0.1733 Acc: 94 %\n",
      "Epoch [9/100], Iter [2530/3426] Loss: 0.1419 Acc: 94 %\n",
      "Epoch [9/100], Iter [2540/3426] Loss: 0.1465 Acc: 94 %\n",
      "Epoch [9/100], Iter [2550/3426] Loss: 0.1587 Acc: 94 %\n",
      "Epoch [9/100], Iter [2560/3426] Loss: 0.1462 Acc: 94 %\n",
      "Epoch [9/100], Iter [2570/3426] Loss: 0.1758 Acc: 94 %\n",
      "Epoch [9/100], Iter [2580/3426] Loss: 0.1395 Acc: 94 %\n",
      "Epoch [9/100], Iter [2590/3426] Loss: 0.1727 Acc: 94 %\n",
      "Epoch [9/100], Iter [2600/3426] Loss: 0.1399 Acc: 94 %\n",
      "Epoch [9/100], Iter [2610/3426] Loss: 0.1626 Acc: 94 %\n",
      "Epoch [9/100], Iter [2620/3426] Loss: 0.1535 Acc: 94 %\n",
      "Epoch [9/100], Iter [2630/3426] Loss: 0.1408 Acc: 94 %\n",
      "Epoch [9/100], Iter [2640/3426] Loss: 0.1404 Acc: 94 %\n",
      "Epoch [9/100], Iter [2650/3426] Loss: 0.1458 Acc: 94 %\n",
      "Epoch [9/100], Iter [2660/3426] Loss: 0.1562 Acc: 94 %\n",
      "Epoch [9/100], Iter [2670/3426] Loss: 0.1873 Acc: 94 %\n",
      "Epoch [9/100], Iter [2680/3426] Loss: 0.1740 Acc: 94 %\n",
      "Epoch [9/100], Iter [2690/3426] Loss: 0.1908 Acc: 94 %\n",
      "Epoch [9/100], Iter [2700/3426] Loss: 0.1463 Acc: 94 %\n",
      "Epoch [9/100], Iter [2710/3426] Loss: 0.1674 Acc: 94 %\n",
      "Epoch [9/100], Iter [2720/3426] Loss: 0.1714 Acc: 94 %\n",
      "Epoch [9/100], Iter [2730/3426] Loss: 0.1338 Acc: 94 %\n",
      "Epoch [9/100], Iter [2740/3426] Loss: 0.1560 Acc: 94 %\n",
      "Epoch [9/100], Iter [2750/3426] Loss: 0.1525 Acc: 94 %\n",
      "Epoch [9/100], Iter [2760/3426] Loss: 0.1698 Acc: 94 %\n",
      "Epoch [9/100], Iter [2770/3426] Loss: 0.1860 Acc: 94 %\n",
      "Epoch [9/100], Iter [2780/3426] Loss: 0.1645 Acc: 94 %\n",
      "Epoch [9/100], Iter [2790/3426] Loss: 0.1758 Acc: 94 %\n",
      "Epoch [9/100], Iter [2800/3426] Loss: 0.1561 Acc: 94 %\n",
      "Epoch [9/100], Iter [2810/3426] Loss: 0.1589 Acc: 94 %\n",
      "Epoch [9/100], Iter [2820/3426] Loss: 0.1545 Acc: 94 %\n",
      "Epoch [9/100], Iter [2830/3426] Loss: 0.1754 Acc: 94 %\n",
      "Epoch [9/100], Iter [2840/3426] Loss: 0.1619 Acc: 94 %\n",
      "Epoch [9/100], Iter [2850/3426] Loss: 0.1625 Acc: 94 %\n",
      "Epoch [9/100], Iter [2860/3426] Loss: 0.1601 Acc: 94 %\n",
      "Epoch [9/100], Iter [2870/3426] Loss: 0.1663 Acc: 94 %\n",
      "Epoch [9/100], Iter [2880/3426] Loss: 0.1734 Acc: 94 %\n",
      "Epoch [9/100], Iter [2890/3426] Loss: 0.1416 Acc: 94 %\n",
      "Epoch [9/100], Iter [2900/3426] Loss: 0.1837 Acc: 94 %\n",
      "Epoch [9/100], Iter [2910/3426] Loss: 0.1834 Acc: 94 %\n",
      "Epoch [9/100], Iter [2920/3426] Loss: 0.1640 Acc: 94 %\n",
      "Epoch [9/100], Iter [2930/3426] Loss: 0.1326 Acc: 94 %\n",
      "Epoch [9/100], Iter [2940/3426] Loss: 0.1719 Acc: 94 %\n",
      "Epoch [9/100], Iter [2950/3426] Loss: 0.1678 Acc: 94 %\n",
      "Epoch [9/100], Iter [2960/3426] Loss: 0.1703 Acc: 94 %\n",
      "Epoch [9/100], Iter [2970/3426] Loss: 0.1549 Acc: 94 %\n",
      "Epoch [9/100], Iter [2980/3426] Loss: 0.1544 Acc: 94 %\n",
      "Epoch [9/100], Iter [2990/3426] Loss: 0.1379 Acc: 94 %\n",
      "Epoch [9/100], Iter [3000/3426] Loss: 0.1432 Acc: 94 %\n",
      "Epoch [9/100], Iter [3010/3426] Loss: 0.1554 Acc: 94 %\n",
      "Epoch [9/100], Iter [3020/3426] Loss: 0.1661 Acc: 94 %\n",
      "Epoch [9/100], Iter [3030/3426] Loss: 0.1600 Acc: 94 %\n",
      "Epoch [9/100], Iter [3040/3426] Loss: 0.1657 Acc: 94 %\n",
      "Epoch [9/100], Iter [3050/3426] Loss: 0.1702 Acc: 94 %\n",
      "Epoch [9/100], Iter [3060/3426] Loss: 0.1649 Acc: 94 %\n",
      "Epoch [9/100], Iter [3070/3426] Loss: 0.1502 Acc: 94 %\n",
      "Epoch [9/100], Iter [3080/3426] Loss: 0.1593 Acc: 94 %\n",
      "Epoch [9/100], Iter [3090/3426] Loss: 0.1689 Acc: 94 %\n",
      "Epoch [9/100], Iter [3100/3426] Loss: 0.1490 Acc: 94 %\n",
      "Epoch [9/100], Iter [3110/3426] Loss: 0.1433 Acc: 94 %\n",
      "Epoch [9/100], Iter [3120/3426] Loss: 0.1587 Acc: 94 %\n",
      "Epoch [9/100], Iter [3130/3426] Loss: 0.1317 Acc: 94 %\n",
      "Epoch [9/100], Iter [3140/3426] Loss: 0.1581 Acc: 94 %\n",
      "Epoch [9/100], Iter [3150/3426] Loss: 0.1799 Acc: 94 %\n",
      "Epoch [9/100], Iter [3160/3426] Loss: 0.1682 Acc: 94 %\n",
      "Epoch [9/100], Iter [3170/3426] Loss: 0.1743 Acc: 94 %\n",
      "Epoch [9/100], Iter [3180/3426] Loss: 0.1589 Acc: 94 %\n",
      "Epoch [9/100], Iter [3190/3426] Loss: 0.1888 Acc: 94 %\n",
      "Epoch [9/100], Iter [3200/3426] Loss: 0.1768 Acc: 94 %\n",
      "Epoch [9/100], Iter [3210/3426] Loss: 0.1564 Acc: 94 %\n",
      "Epoch [9/100], Iter [3220/3426] Loss: 0.1713 Acc: 94 %\n",
      "Epoch [9/100], Iter [3230/3426] Loss: 0.1436 Acc: 94 %\n",
      "Epoch [9/100], Iter [3240/3426] Loss: 0.1453 Acc: 94 %\n",
      "Epoch [9/100], Iter [3250/3426] Loss: 0.1801 Acc: 94 %\n",
      "Epoch [9/100], Iter [3260/3426] Loss: 0.1487 Acc: 94 %\n",
      "Epoch [9/100], Iter [3270/3426] Loss: 0.1712 Acc: 94 %\n",
      "Epoch [9/100], Iter [3280/3426] Loss: 0.1561 Acc: 94 %\n",
      "Epoch [9/100], Iter [3290/3426] Loss: 0.1486 Acc: 94 %\n",
      "Epoch [9/100], Iter [3300/3426] Loss: 0.1568 Acc: 94 %\n",
      "Epoch [9/100], Iter [3310/3426] Loss: 0.1523 Acc: 94 %\n",
      "Epoch [9/100], Iter [3320/3426] Loss: 0.1698 Acc: 94 %\n",
      "Epoch [9/100], Iter [3330/3426] Loss: 0.1854 Acc: 94 %\n",
      "Epoch [9/100], Iter [3340/3426] Loss: 0.1655 Acc: 94 %\n",
      "Epoch [9/100], Iter [3350/3426] Loss: 0.1533 Acc: 94 %\n",
      "Epoch [9/100], Iter [3360/3426] Loss: 0.1836 Acc: 94 %\n",
      "Epoch [9/100], Iter [3370/3426] Loss: 0.1489 Acc: 94 %\n",
      "Epoch [9/100], Iter [3380/3426] Loss: 0.1705 Acc: 94 %\n",
      "Epoch [9/100], Iter [3390/3426] Loss: 0.1650 Acc: 94 %\n",
      "Epoch [9/100], Iter [3400/3426] Loss: 0.1500 Acc: 94 %\n",
      "Epoch [9/100], Iter [3410/3426] Loss: 0.1572 Acc: 94 %\n",
      "Epoch [9/100], Iter [3420/3426] Loss: 0.1513 Acc: 94 %\n",
      "Accuracy of the model on the neg seq: 75 %\n",
      "Accuracy of the model on the pos seq: 99 %\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch [10/100], Iter [10/3426] Loss: 0.1647 Acc: 93 %\n",
      "Epoch [10/100], Iter [20/3426] Loss: 0.1648 Acc: 93 %\n",
      "Epoch [10/100], Iter [30/3426] Loss: 0.1620 Acc: 94 %\n",
      "Epoch [10/100], Iter [40/3426] Loss: 0.1497 Acc: 94 %\n",
      "Epoch [10/100], Iter [50/3426] Loss: 0.1446 Acc: 94 %\n",
      "Epoch [10/100], Iter [60/3426] Loss: 0.1727 Acc: 94 %\n",
      "Epoch [10/100], Iter [70/3426] Loss: 0.1492 Acc: 94 %\n",
      "Epoch [10/100], Iter [80/3426] Loss: 0.1503 Acc: 94 %\n",
      "Epoch [10/100], Iter [90/3426] Loss: 0.1604 Acc: 94 %\n",
      "Epoch [10/100], Iter [100/3426] Loss: 0.1549 Acc: 94 %\n",
      "Epoch [10/100], Iter [110/3426] Loss: 0.1584 Acc: 94 %\n",
      "Epoch [10/100], Iter [120/3426] Loss: 0.1510 Acc: 94 %\n",
      "Epoch [10/100], Iter [130/3426] Loss: 0.1561 Acc: 94 %\n",
      "Epoch [10/100], Iter [140/3426] Loss: 0.1530 Acc: 94 %\n",
      "Epoch [10/100], Iter [150/3426] Loss: 0.1743 Acc: 94 %\n",
      "Epoch [10/100], Iter [160/3426] Loss: 0.1622 Acc: 94 %\n",
      "Epoch [10/100], Iter [170/3426] Loss: 0.1598 Acc: 94 %\n",
      "Epoch [10/100], Iter [180/3426] Loss: 0.1545 Acc: 94 %\n",
      "Epoch [10/100], Iter [190/3426] Loss: 0.1588 Acc: 94 %\n",
      "Epoch [10/100], Iter [200/3426] Loss: 0.1710 Acc: 94 %\n",
      "Epoch [10/100], Iter [210/3426] Loss: 0.1449 Acc: 94 %\n",
      "Epoch [10/100], Iter [220/3426] Loss: 0.1617 Acc: 94 %\n",
      "Epoch [10/100], Iter [230/3426] Loss: 0.1744 Acc: 94 %\n",
      "Epoch [10/100], Iter [240/3426] Loss: 0.1890 Acc: 94 %\n",
      "Epoch [10/100], Iter [250/3426] Loss: 0.1759 Acc: 94 %\n",
      "Epoch [10/100], Iter [260/3426] Loss: 0.1516 Acc: 94 %\n",
      "Epoch [10/100], Iter [270/3426] Loss: 0.1851 Acc: 94 %\n",
      "Epoch [10/100], Iter [280/3426] Loss: 0.1739 Acc: 94 %\n",
      "Epoch [10/100], Iter [290/3426] Loss: 0.1483 Acc: 94 %\n",
      "Epoch [10/100], Iter [300/3426] Loss: 0.1583 Acc: 94 %\n",
      "Epoch [10/100], Iter [310/3426] Loss: 0.1462 Acc: 94 %\n",
      "Epoch [10/100], Iter [320/3426] Loss: 0.1932 Acc: 94 %\n",
      "Epoch [10/100], Iter [330/3426] Loss: 0.1527 Acc: 94 %\n",
      "Epoch [10/100], Iter [340/3426] Loss: 0.1637 Acc: 94 %\n",
      "Epoch [10/100], Iter [350/3426] Loss: 0.1478 Acc: 94 %\n",
      "Epoch [10/100], Iter [360/3426] Loss: 0.1562 Acc: 94 %\n",
      "Epoch [10/100], Iter [370/3426] Loss: 0.1710 Acc: 94 %\n",
      "Epoch [10/100], Iter [380/3426] Loss: 0.1618 Acc: 94 %\n",
      "Epoch [10/100], Iter [390/3426] Loss: 0.1446 Acc: 94 %\n",
      "Epoch [10/100], Iter [400/3426] Loss: 0.1309 Acc: 94 %\n",
      "Epoch [10/100], Iter [410/3426] Loss: 0.1749 Acc: 94 %\n",
      "Epoch [10/100], Iter [420/3426] Loss: 0.1208 Acc: 94 %\n",
      "Epoch [10/100], Iter [430/3426] Loss: 0.1409 Acc: 94 %\n",
      "Epoch [10/100], Iter [440/3426] Loss: 0.1505 Acc: 94 %\n",
      "Epoch [10/100], Iter [450/3426] Loss: 0.1405 Acc: 94 %\n",
      "Epoch [10/100], Iter [460/3426] Loss: 0.1535 Acc: 94 %\n",
      "Epoch [10/100], Iter [470/3426] Loss: 0.1623 Acc: 94 %\n",
      "Epoch [10/100], Iter [480/3426] Loss: 0.1625 Acc: 94 %\n",
      "Epoch [10/100], Iter [490/3426] Loss: 0.1745 Acc: 94 %\n",
      "Epoch [10/100], Iter [500/3426] Loss: 0.1664 Acc: 94 %\n",
      "Epoch [10/100], Iter [510/3426] Loss: 0.1716 Acc: 94 %\n",
      "Epoch [10/100], Iter [520/3426] Loss: 0.1671 Acc: 94 %\n",
      "Epoch [10/100], Iter [530/3426] Loss: 0.1544 Acc: 94 %\n",
      "Epoch [10/100], Iter [540/3426] Loss: 0.1493 Acc: 94 %\n",
      "Epoch [10/100], Iter [550/3426] Loss: 0.1634 Acc: 94 %\n",
      "Epoch [10/100], Iter [560/3426] Loss: 0.2154 Acc: 94 %\n",
      "Epoch [10/100], Iter [570/3426] Loss: 0.1772 Acc: 94 %\n",
      "Epoch [10/100], Iter [580/3426] Loss: 0.1630 Acc: 94 %\n",
      "Epoch [10/100], Iter [590/3426] Loss: 0.1753 Acc: 94 %\n",
      "Epoch [10/100], Iter [600/3426] Loss: 0.1495 Acc: 94 %\n",
      "Epoch [10/100], Iter [610/3426] Loss: 0.1584 Acc: 94 %\n",
      "Epoch [10/100], Iter [620/3426] Loss: 0.1624 Acc: 94 %\n",
      "Epoch [10/100], Iter [630/3426] Loss: 0.1616 Acc: 94 %\n",
      "Epoch [10/100], Iter [640/3426] Loss: 0.1681 Acc: 94 %\n",
      "Epoch [10/100], Iter [650/3426] Loss: 0.1484 Acc: 94 %\n",
      "Epoch [10/100], Iter [660/3426] Loss: 0.1831 Acc: 94 %\n",
      "Epoch [10/100], Iter [670/3426] Loss: 0.1722 Acc: 94 %\n",
      "Epoch [10/100], Iter [680/3426] Loss: 0.1303 Acc: 94 %\n",
      "Epoch [10/100], Iter [690/3426] Loss: 0.1210 Acc: 94 %\n",
      "Epoch [10/100], Iter [700/3426] Loss: 0.1585 Acc: 94 %\n",
      "Epoch [10/100], Iter [710/3426] Loss: 0.1820 Acc: 94 %\n",
      "Epoch [10/100], Iter [720/3426] Loss: 0.1613 Acc: 94 %\n",
      "Epoch [10/100], Iter [730/3426] Loss: 0.1571 Acc: 94 %\n",
      "Epoch [10/100], Iter [740/3426] Loss: 0.1526 Acc: 94 %\n",
      "Epoch [10/100], Iter [750/3426] Loss: 0.1413 Acc: 94 %\n",
      "Epoch [10/100], Iter [760/3426] Loss: 0.1473 Acc: 94 %\n",
      "Epoch [10/100], Iter [770/3426] Loss: 0.1683 Acc: 94 %\n",
      "Epoch [10/100], Iter [780/3426] Loss: 0.1712 Acc: 94 %\n",
      "Epoch [10/100], Iter [790/3426] Loss: 0.1404 Acc: 94 %\n",
      "Epoch [10/100], Iter [800/3426] Loss: 0.1417 Acc: 94 %\n",
      "Epoch [10/100], Iter [810/3426] Loss: 0.1527 Acc: 94 %\n",
      "Epoch [10/100], Iter [820/3426] Loss: 0.1438 Acc: 94 %\n",
      "Epoch [10/100], Iter [830/3426] Loss: 0.1399 Acc: 94 %\n",
      "Epoch [10/100], Iter [840/3426] Loss: 0.1804 Acc: 94 %\n",
      "Epoch [10/100], Iter [850/3426] Loss: 0.1743 Acc: 94 %\n",
      "Epoch [10/100], Iter [860/3426] Loss: 0.1524 Acc: 94 %\n",
      "Epoch [10/100], Iter [870/3426] Loss: 0.1643 Acc: 94 %\n",
      "Epoch [10/100], Iter [880/3426] Loss: 0.1424 Acc: 94 %\n",
      "Epoch [10/100], Iter [890/3426] Loss: 0.1586 Acc: 94 %\n",
      "Epoch [10/100], Iter [900/3426] Loss: 0.1533 Acc: 94 %\n",
      "Epoch [10/100], Iter [910/3426] Loss: 0.1612 Acc: 94 %\n",
      "Epoch [10/100], Iter [920/3426] Loss: 0.1368 Acc: 94 %\n",
      "Epoch [10/100], Iter [930/3426] Loss: 0.1693 Acc: 94 %\n",
      "Epoch [10/100], Iter [940/3426] Loss: 0.1678 Acc: 94 %\n",
      "Epoch [10/100], Iter [950/3426] Loss: 0.1404 Acc: 94 %\n",
      "Epoch [10/100], Iter [960/3426] Loss: 0.1384 Acc: 94 %\n",
      "Epoch [10/100], Iter [970/3426] Loss: 0.1602 Acc: 94 %\n",
      "Epoch [10/100], Iter [980/3426] Loss: 0.1615 Acc: 94 %\n",
      "Epoch [10/100], Iter [990/3426] Loss: 0.1417 Acc: 94 %\n",
      "Epoch [10/100], Iter [1000/3426] Loss: 0.1746 Acc: 94 %\n",
      "Epoch [10/100], Iter [1010/3426] Loss: 0.1911 Acc: 94 %\n",
      "Epoch [10/100], Iter [1020/3426] Loss: 0.1448 Acc: 94 %\n",
      "Epoch [10/100], Iter [1030/3426] Loss: 0.1823 Acc: 94 %\n",
      "Epoch [10/100], Iter [1040/3426] Loss: 0.1621 Acc: 94 %\n",
      "Epoch [10/100], Iter [1050/3426] Loss: 0.1552 Acc: 94 %\n",
      "Epoch [10/100], Iter [1060/3426] Loss: 0.1498 Acc: 94 %\n",
      "Epoch [10/100], Iter [1070/3426] Loss: 0.1448 Acc: 94 %\n",
      "Epoch [10/100], Iter [1080/3426] Loss: 0.1503 Acc: 94 %\n",
      "Epoch [10/100], Iter [1090/3426] Loss: 0.1268 Acc: 94 %\n",
      "Epoch [10/100], Iter [1100/3426] Loss: 0.1482 Acc: 94 %\n",
      "Epoch [10/100], Iter [1110/3426] Loss: 0.1612 Acc: 94 %\n",
      "Epoch [10/100], Iter [1120/3426] Loss: 0.1667 Acc: 94 %\n",
      "Epoch [10/100], Iter [1130/3426] Loss: 0.1594 Acc: 94 %\n",
      "Epoch [10/100], Iter [1140/3426] Loss: 0.1334 Acc: 94 %\n",
      "Epoch [10/100], Iter [1150/3426] Loss: 0.1586 Acc: 94 %\n",
      "Epoch [10/100], Iter [1160/3426] Loss: 0.1638 Acc: 94 %\n",
      "Epoch [10/100], Iter [1170/3426] Loss: 0.1632 Acc: 94 %\n",
      "Epoch [10/100], Iter [1180/3426] Loss: 0.1489 Acc: 94 %\n",
      "Epoch [10/100], Iter [1190/3426] Loss: 0.1777 Acc: 94 %\n",
      "Epoch [10/100], Iter [1200/3426] Loss: 0.1513 Acc: 94 %\n",
      "Epoch [10/100], Iter [1210/3426] Loss: 0.1632 Acc: 94 %\n",
      "Epoch [10/100], Iter [1220/3426] Loss: 0.1275 Acc: 94 %\n",
      "Epoch [10/100], Iter [1230/3426] Loss: 0.1785 Acc: 94 %\n",
      "Epoch [10/100], Iter [1240/3426] Loss: 0.2066 Acc: 94 %\n",
      "Epoch [10/100], Iter [1250/3426] Loss: 0.1848 Acc: 94 %\n",
      "Epoch [10/100], Iter [1260/3426] Loss: 0.1955 Acc: 94 %\n",
      "Epoch [10/100], Iter [1270/3426] Loss: 0.1940 Acc: 94 %\n",
      "Epoch [10/100], Iter [1280/3426] Loss: 0.1650 Acc: 94 %\n",
      "Epoch [10/100], Iter [1290/3426] Loss: 0.1679 Acc: 94 %\n",
      "Epoch [10/100], Iter [1300/3426] Loss: 0.1517 Acc: 94 %\n",
      "Epoch [10/100], Iter [1310/3426] Loss: 0.1493 Acc: 94 %\n",
      "Epoch [10/100], Iter [1320/3426] Loss: 0.1375 Acc: 94 %\n",
      "Epoch [10/100], Iter [1330/3426] Loss: 0.1891 Acc: 94 %\n",
      "Epoch [10/100], Iter [1340/3426] Loss: 0.1778 Acc: 94 %\n",
      "Epoch [10/100], Iter [1350/3426] Loss: 0.1575 Acc: 94 %\n",
      "Epoch [10/100], Iter [1360/3426] Loss: 0.1557 Acc: 94 %\n",
      "Epoch [10/100], Iter [1370/3426] Loss: 0.1630 Acc: 94 %\n",
      "Epoch [10/100], Iter [1380/3426] Loss: 0.1596 Acc: 94 %\n",
      "Epoch [10/100], Iter [1390/3426] Loss: 0.1366 Acc: 94 %\n",
      "Epoch [10/100], Iter [1400/3426] Loss: 0.1328 Acc: 94 %\n",
      "Epoch [10/100], Iter [1410/3426] Loss: 0.1607 Acc: 94 %\n",
      "Epoch [10/100], Iter [1420/3426] Loss: 0.1543 Acc: 94 %\n",
      "Epoch [10/100], Iter [1430/3426] Loss: 0.1585 Acc: 94 %\n",
      "Epoch [10/100], Iter [1440/3426] Loss: 0.1460 Acc: 94 %\n",
      "Epoch [10/100], Iter [1450/3426] Loss: 0.1760 Acc: 94 %\n",
      "Epoch [10/100], Iter [1460/3426] Loss: 0.1466 Acc: 94 %\n",
      "Epoch [10/100], Iter [1470/3426] Loss: 0.1800 Acc: 94 %\n",
      "Epoch [10/100], Iter [1480/3426] Loss: 0.1384 Acc: 94 %\n",
      "Epoch [10/100], Iter [1490/3426] Loss: 0.1482 Acc: 94 %\n",
      "Epoch [10/100], Iter [1500/3426] Loss: 0.1361 Acc: 94 %\n",
      "Epoch [10/100], Iter [1510/3426] Loss: 0.1617 Acc: 94 %\n",
      "Epoch [10/100], Iter [1520/3426] Loss: 0.1600 Acc: 94 %\n",
      "Epoch [10/100], Iter [1530/3426] Loss: 0.1568 Acc: 94 %\n",
      "Epoch [10/100], Iter [1540/3426] Loss: 0.1244 Acc: 94 %\n",
      "Epoch [10/100], Iter [1550/3426] Loss: 0.1396 Acc: 94 %\n",
      "Epoch [10/100], Iter [1560/3426] Loss: 0.1687 Acc: 94 %\n",
      "Epoch [10/100], Iter [1570/3426] Loss: 0.1454 Acc: 94 %\n",
      "Epoch [10/100], Iter [1580/3426] Loss: 0.1420 Acc: 94 %\n",
      "Epoch [10/100], Iter [1590/3426] Loss: 0.1982 Acc: 94 %\n",
      "Epoch [10/100], Iter [1600/3426] Loss: 0.1684 Acc: 94 %\n",
      "Epoch [10/100], Iter [1610/3426] Loss: 0.1427 Acc: 94 %\n",
      "Epoch [10/100], Iter [1620/3426] Loss: 0.1488 Acc: 94 %\n",
      "Epoch [10/100], Iter [1630/3426] Loss: 0.1709 Acc: 94 %\n",
      "Epoch [10/100], Iter [1640/3426] Loss: 0.1571 Acc: 94 %\n",
      "Epoch [10/100], Iter [1650/3426] Loss: 0.1260 Acc: 94 %\n",
      "Epoch [10/100], Iter [1660/3426] Loss: 0.1673 Acc: 94 %\n",
      "Epoch [10/100], Iter [1670/3426] Loss: 0.1650 Acc: 94 %\n",
      "Epoch [10/100], Iter [1680/3426] Loss: 0.1664 Acc: 94 %\n",
      "Epoch [10/100], Iter [1690/3426] Loss: 0.1360 Acc: 94 %\n",
      "Epoch [10/100], Iter [1700/3426] Loss: 0.1419 Acc: 94 %\n",
      "Epoch [10/100], Iter [1710/3426] Loss: 0.1704 Acc: 94 %\n",
      "Epoch [10/100], Iter [1720/3426] Loss: 0.1527 Acc: 94 %\n",
      "Epoch [10/100], Iter [1730/3426] Loss: 0.1635 Acc: 94 %\n",
      "Epoch [10/100], Iter [1740/3426] Loss: 0.1458 Acc: 94 %\n",
      "Epoch [10/100], Iter [1750/3426] Loss: 0.1732 Acc: 94 %\n",
      "Epoch [10/100], Iter [1760/3426] Loss: 0.1688 Acc: 94 %\n",
      "Epoch [10/100], Iter [1770/3426] Loss: 0.1481 Acc: 94 %\n",
      "Epoch [10/100], Iter [1780/3426] Loss: 0.1581 Acc: 94 %\n",
      "Epoch [10/100], Iter [1790/3426] Loss: 0.1538 Acc: 94 %\n",
      "Epoch [10/100], Iter [1800/3426] Loss: 0.1481 Acc: 94 %\n",
      "Epoch [10/100], Iter [1810/3426] Loss: 0.1773 Acc: 94 %\n",
      "Epoch [10/100], Iter [1820/3426] Loss: 0.1432 Acc: 94 %\n",
      "Epoch [10/100], Iter [1830/3426] Loss: 0.1686 Acc: 94 %\n",
      "Epoch [10/100], Iter [1840/3426] Loss: 0.1758 Acc: 94 %\n",
      "Epoch [10/100], Iter [1850/3426] Loss: 0.1858 Acc: 94 %\n",
      "Epoch [10/100], Iter [1860/3426] Loss: 0.1499 Acc: 94 %\n",
      "Epoch [10/100], Iter [1870/3426] Loss: 0.1560 Acc: 94 %\n",
      "Epoch [10/100], Iter [1880/3426] Loss: 0.1346 Acc: 94 %\n",
      "Epoch [10/100], Iter [1890/3426] Loss: 0.1673 Acc: 94 %\n",
      "Epoch [10/100], Iter [1900/3426] Loss: 0.1502 Acc: 94 %\n",
      "Epoch [10/100], Iter [1910/3426] Loss: 0.1507 Acc: 94 %\n",
      "Epoch [10/100], Iter [1920/3426] Loss: 0.1484 Acc: 94 %\n",
      "Epoch [10/100], Iter [1930/3426] Loss: 0.1701 Acc: 94 %\n",
      "Epoch [10/100], Iter [1940/3426] Loss: 0.1565 Acc: 94 %\n",
      "Epoch [10/100], Iter [1950/3426] Loss: 0.1582 Acc: 94 %\n",
      "Epoch [10/100], Iter [1960/3426] Loss: 0.1864 Acc: 94 %\n",
      "Epoch [10/100], Iter [1970/3426] Loss: 0.1748 Acc: 94 %\n",
      "Epoch [10/100], Iter [1980/3426] Loss: 0.2837 Acc: 94 %\n",
      "Epoch [10/100], Iter [1990/3426] Loss: 0.1605 Acc: 94 %\n",
      "Epoch [10/100], Iter [2000/3426] Loss: 0.1589 Acc: 94 %\n",
      "Epoch [10/100], Iter [2010/3426] Loss: 0.1919 Acc: 94 %\n",
      "Epoch [10/100], Iter [2020/3426] Loss: 0.1641 Acc: 94 %\n",
      "Epoch [10/100], Iter [2030/3426] Loss: 0.1467 Acc: 94 %\n",
      "Epoch [10/100], Iter [2040/3426] Loss: 0.1539 Acc: 94 %\n",
      "Epoch [10/100], Iter [2050/3426] Loss: 0.1587 Acc: 94 %\n",
      "Epoch [10/100], Iter [2060/3426] Loss: 0.1537 Acc: 94 %\n",
      "Epoch [10/100], Iter [2070/3426] Loss: 0.1670 Acc: 94 %\n",
      "Epoch [10/100], Iter [2080/3426] Loss: 0.1481 Acc: 94 %\n",
      "Epoch [10/100], Iter [2090/3426] Loss: 0.1506 Acc: 94 %\n",
      "Epoch [10/100], Iter [2100/3426] Loss: 0.1669 Acc: 94 %\n",
      "Epoch [10/100], Iter [2110/3426] Loss: 0.1491 Acc: 94 %\n",
      "Epoch [10/100], Iter [2120/3426] Loss: 0.1522 Acc: 94 %\n",
      "Epoch [10/100], Iter [2130/3426] Loss: 0.1798 Acc: 94 %\n",
      "Epoch [10/100], Iter [2140/3426] Loss: 0.1707 Acc: 94 %\n",
      "Epoch [10/100], Iter [2150/3426] Loss: 0.1603 Acc: 94 %\n",
      "Epoch [10/100], Iter [2160/3426] Loss: 0.1611 Acc: 94 %\n",
      "Epoch [10/100], Iter [2170/3426] Loss: 0.1551 Acc: 94 %\n",
      "Epoch [10/100], Iter [2180/3426] Loss: 0.1462 Acc: 94 %\n",
      "Epoch [10/100], Iter [2190/3426] Loss: 0.1754 Acc: 94 %\n",
      "Epoch [10/100], Iter [2200/3426] Loss: 0.1251 Acc: 94 %\n",
      "Epoch [10/100], Iter [2210/3426] Loss: 0.1733 Acc: 94 %\n",
      "Epoch [10/100], Iter [2220/3426] Loss: 0.1321 Acc: 94 %\n",
      "Epoch [10/100], Iter [2230/3426] Loss: 0.1777 Acc: 94 %\n",
      "Epoch [10/100], Iter [2240/3426] Loss: 0.1660 Acc: 94 %\n",
      "Epoch [10/100], Iter [2250/3426] Loss: 0.1398 Acc: 94 %\n",
      "Epoch [10/100], Iter [2260/3426] Loss: 0.1581 Acc: 94 %\n",
      "Epoch [10/100], Iter [2270/3426] Loss: 0.1604 Acc: 94 %\n",
      "Epoch [10/100], Iter [2280/3426] Loss: 0.1819 Acc: 94 %\n",
      "Epoch [10/100], Iter [2290/3426] Loss: 0.1588 Acc: 94 %\n",
      "Epoch [10/100], Iter [2300/3426] Loss: 0.1715 Acc: 94 %\n",
      "Epoch [10/100], Iter [2310/3426] Loss: 0.1583 Acc: 94 %\n",
      "Epoch [10/100], Iter [2320/3426] Loss: 0.1594 Acc: 94 %\n",
      "Epoch [10/100], Iter [2330/3426] Loss: 0.1375 Acc: 94 %\n",
      "Epoch [10/100], Iter [2340/3426] Loss: 0.1532 Acc: 94 %\n",
      "Epoch [10/100], Iter [2350/3426] Loss: 0.1272 Acc: 94 %\n",
      "Epoch [10/100], Iter [2360/3426] Loss: 0.1625 Acc: 94 %\n",
      "Epoch [10/100], Iter [2370/3426] Loss: 0.1295 Acc: 94 %\n",
      "Epoch [10/100], Iter [2380/3426] Loss: 0.1835 Acc: 94 %\n",
      "Epoch [10/100], Iter [2390/3426] Loss: 0.1617 Acc: 94 %\n",
      "Epoch [10/100], Iter [2400/3426] Loss: 0.1779 Acc: 94 %\n",
      "Epoch [10/100], Iter [2410/3426] Loss: 0.1632 Acc: 94 %\n",
      "Epoch [10/100], Iter [2420/3426] Loss: 0.1550 Acc: 94 %\n",
      "Epoch [10/100], Iter [2430/3426] Loss: 0.1437 Acc: 94 %\n",
      "Epoch [10/100], Iter [2440/3426] Loss: 0.1425 Acc: 94 %\n",
      "Epoch [10/100], Iter [2450/3426] Loss: 0.1626 Acc: 94 %\n",
      "Epoch [10/100], Iter [2460/3426] Loss: 0.1534 Acc: 94 %\n",
      "Epoch [10/100], Iter [2470/3426] Loss: 0.1329 Acc: 94 %\n",
      "Epoch [10/100], Iter [2480/3426] Loss: 0.1569 Acc: 94 %\n",
      "Epoch [10/100], Iter [2490/3426] Loss: 0.1594 Acc: 94 %\n",
      "Epoch [10/100], Iter [2500/3426] Loss: 0.1700 Acc: 94 %\n",
      "Epoch [10/100], Iter [2510/3426] Loss: 0.1767 Acc: 94 %\n",
      "Epoch [10/100], Iter [2520/3426] Loss: 0.1526 Acc: 94 %\n",
      "Epoch [10/100], Iter [2530/3426] Loss: 0.1936 Acc: 94 %\n",
      "Epoch [10/100], Iter [2540/3426] Loss: 0.1492 Acc: 94 %\n",
      "Epoch [10/100], Iter [2550/3426] Loss: 0.1886 Acc: 94 %\n",
      "Epoch [10/100], Iter [2560/3426] Loss: 0.1552 Acc: 94 %\n",
      "Epoch [10/100], Iter [2570/3426] Loss: 0.1355 Acc: 94 %\n",
      "Epoch [10/100], Iter [2580/3426] Loss: 0.1831 Acc: 94 %\n",
      "Epoch [10/100], Iter [2590/3426] Loss: 0.1626 Acc: 94 %\n",
      "Epoch [10/100], Iter [2600/3426] Loss: 0.1643 Acc: 94 %\n",
      "Epoch [10/100], Iter [2610/3426] Loss: 0.1725 Acc: 94 %\n",
      "Epoch [10/100], Iter [2620/3426] Loss: 0.1318 Acc: 94 %\n",
      "Epoch [10/100], Iter [2630/3426] Loss: 0.1405 Acc: 94 %\n",
      "Epoch [10/100], Iter [2640/3426] Loss: 0.1528 Acc: 94 %\n",
      "Epoch [10/100], Iter [2650/3426] Loss: 0.1706 Acc: 94 %\n",
      "Epoch [10/100], Iter [2660/3426] Loss: 0.1686 Acc: 94 %\n",
      "Epoch [10/100], Iter [2670/3426] Loss: 0.1654 Acc: 94 %\n",
      "Epoch [10/100], Iter [2680/3426] Loss: 0.1837 Acc: 94 %\n",
      "Epoch [10/100], Iter [2690/3426] Loss: 0.1812 Acc: 94 %\n",
      "Epoch [10/100], Iter [2700/3426] Loss: 0.1364 Acc: 94 %\n",
      "Epoch [10/100], Iter [2710/3426] Loss: 0.1554 Acc: 94 %\n",
      "Epoch [10/100], Iter [2720/3426] Loss: 0.1454 Acc: 94 %\n",
      "Epoch [10/100], Iter [2730/3426] Loss: 0.1585 Acc: 94 %\n",
      "Epoch [10/100], Iter [2740/3426] Loss: 0.1814 Acc: 94 %\n",
      "Epoch [10/100], Iter [2750/3426] Loss: 0.1712 Acc: 94 %\n",
      "Epoch [10/100], Iter [2760/3426] Loss: 0.1845 Acc: 94 %\n",
      "Epoch [10/100], Iter [2770/3426] Loss: 0.1566 Acc: 94 %\n",
      "Epoch [10/100], Iter [2780/3426] Loss: 0.1501 Acc: 94 %\n",
      "Epoch [10/100], Iter [2790/3426] Loss: 0.1725 Acc: 94 %\n",
      "Epoch [10/100], Iter [2800/3426] Loss: 0.1566 Acc: 94 %\n",
      "Epoch [10/100], Iter [2810/3426] Loss: 0.1509 Acc: 94 %\n",
      "Epoch [10/100], Iter [2820/3426] Loss: 0.1433 Acc: 94 %\n",
      "Epoch [10/100], Iter [2830/3426] Loss: 0.1881 Acc: 94 %\n",
      "Epoch [10/100], Iter [2840/3426] Loss: 0.1701 Acc: 94 %\n",
      "Epoch [10/100], Iter [2850/3426] Loss: 0.1427 Acc: 94 %\n",
      "Epoch [10/100], Iter [2860/3426] Loss: 0.1795 Acc: 94 %\n",
      "Epoch [10/100], Iter [2870/3426] Loss: 0.1429 Acc: 94 %\n",
      "Epoch [10/100], Iter [2880/3426] Loss: 0.1754 Acc: 94 %\n",
      "Epoch [10/100], Iter [2890/3426] Loss: 0.1650 Acc: 94 %\n",
      "Epoch [10/100], Iter [2900/3426] Loss: 0.1565 Acc: 94 %\n",
      "Epoch [10/100], Iter [2910/3426] Loss: 0.1575 Acc: 94 %\n",
      "Epoch [10/100], Iter [2920/3426] Loss: 0.1494 Acc: 94 %\n",
      "Epoch [10/100], Iter [2930/3426] Loss: 0.1812 Acc: 94 %\n",
      "Epoch [10/100], Iter [2940/3426] Loss: 0.1639 Acc: 94 %\n",
      "Epoch [10/100], Iter [2950/3426] Loss: 0.1954 Acc: 94 %\n",
      "Epoch [10/100], Iter [2960/3426] Loss: 0.1578 Acc: 94 %\n",
      "Epoch [10/100], Iter [2970/3426] Loss: 0.1581 Acc: 94 %\n",
      "Epoch [10/100], Iter [2980/3426] Loss: 0.1485 Acc: 94 %\n",
      "Epoch [10/100], Iter [2990/3426] Loss: 0.1496 Acc: 94 %\n",
      "Epoch [10/100], Iter [3000/3426] Loss: 0.1556 Acc: 94 %\n",
      "Epoch [10/100], Iter [3010/3426] Loss: 0.1635 Acc: 94 %\n",
      "Epoch [10/100], Iter [3020/3426] Loss: 0.1195 Acc: 94 %\n",
      "Epoch [10/100], Iter [3030/3426] Loss: 0.1661 Acc: 94 %\n",
      "Epoch [10/100], Iter [3040/3426] Loss: 0.1609 Acc: 94 %\n",
      "Epoch [10/100], Iter [3050/3426] Loss: 0.1455 Acc: 94 %\n",
      "Epoch [10/100], Iter [3060/3426] Loss: 0.1640 Acc: 94 %\n",
      "Epoch [10/100], Iter [3070/3426] Loss: 0.1825 Acc: 94 %\n",
      "Epoch [10/100], Iter [3080/3426] Loss: 0.1697 Acc: 94 %\n",
      "Epoch [10/100], Iter [3090/3426] Loss: 0.1458 Acc: 94 %\n",
      "Epoch [10/100], Iter [3100/3426] Loss: 0.1645 Acc: 94 %\n",
      "Epoch [10/100], Iter [3110/3426] Loss: 0.1574 Acc: 94 %\n",
      "Epoch [10/100], Iter [3120/3426] Loss: 0.1450 Acc: 94 %\n",
      "Epoch [10/100], Iter [3130/3426] Loss: 0.1697 Acc: 94 %\n",
      "Epoch [10/100], Iter [3140/3426] Loss: 0.1718 Acc: 94 %\n",
      "Epoch [10/100], Iter [3150/3426] Loss: 0.1639 Acc: 94 %\n",
      "Epoch [10/100], Iter [3160/3426] Loss: 0.1625 Acc: 94 %\n",
      "Epoch [10/100], Iter [3170/3426] Loss: 0.1585 Acc: 94 %\n",
      "Epoch [10/100], Iter [3180/3426] Loss: 0.1725 Acc: 94 %\n",
      "Epoch [10/100], Iter [3190/3426] Loss: 0.1597 Acc: 94 %\n",
      "Epoch [10/100], Iter [3200/3426] Loss: 0.1813 Acc: 94 %\n",
      "Epoch [10/100], Iter [3210/3426] Loss: 0.1613 Acc: 94 %\n",
      "Epoch [10/100], Iter [3220/3426] Loss: 0.1646 Acc: 94 %\n",
      "Epoch [10/100], Iter [3230/3426] Loss: 0.1880 Acc: 94 %\n",
      "Epoch [10/100], Iter [3240/3426] Loss: 0.1547 Acc: 94 %\n",
      "Epoch [10/100], Iter [3250/3426] Loss: 0.1644 Acc: 94 %\n",
      "Epoch [10/100], Iter [3260/3426] Loss: 0.1548 Acc: 94 %\n",
      "Epoch [10/100], Iter [3270/3426] Loss: 0.1512 Acc: 94 %\n",
      "Epoch [10/100], Iter [3280/3426] Loss: 0.1341 Acc: 94 %\n",
      "Epoch [10/100], Iter [3290/3426] Loss: 0.1454 Acc: 94 %\n",
      "Epoch [10/100], Iter [3300/3426] Loss: 0.1763 Acc: 94 %\n",
      "Epoch [10/100], Iter [3310/3426] Loss: 0.1630 Acc: 94 %\n",
      "Epoch [10/100], Iter [3320/3426] Loss: 0.1713 Acc: 94 %\n",
      "Epoch [10/100], Iter [3330/3426] Loss: 0.1654 Acc: 94 %\n",
      "Epoch [10/100], Iter [3340/3426] Loss: 0.1227 Acc: 94 %\n",
      "Epoch [10/100], Iter [3350/3426] Loss: 0.1581 Acc: 94 %\n",
      "Epoch [10/100], Iter [3360/3426] Loss: 0.1801 Acc: 94 %\n",
      "Epoch [10/100], Iter [3370/3426] Loss: 0.1528 Acc: 94 %\n",
      "Epoch [10/100], Iter [3380/3426] Loss: 0.1451 Acc: 94 %\n",
      "Epoch [10/100], Iter [3390/3426] Loss: 0.1675 Acc: 94 %\n",
      "Epoch [10/100], Iter [3400/3426] Loss: 0.1718 Acc: 94 %\n",
      "Epoch [10/100], Iter [3410/3426] Loss: 0.1533 Acc: 94 %\n",
      "Epoch [10/100], Iter [3420/3426] Loss: 0.1645 Acc: 94 %\n",
      "Accuracy of the model on the neg seq: 83 %\n",
      "Accuracy of the model on the pos seq: 97 %\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch [11/100], Iter [10/3426] Loss: 0.1863 Acc: 93 %\n",
      "Epoch [11/100], Iter [20/3426] Loss: 0.1554 Acc: 93 %\n",
      "Epoch [11/100], Iter [30/3426] Loss: 0.1510 Acc: 94 %\n",
      "Epoch [11/100], Iter [40/3426] Loss: 0.1668 Acc: 94 %\n",
      "Epoch [11/100], Iter [50/3426] Loss: 0.1288 Acc: 94 %\n",
      "Epoch [11/100], Iter [60/3426] Loss: 0.1585 Acc: 94 %\n",
      "Epoch [11/100], Iter [70/3426] Loss: 0.1673 Acc: 94 %\n",
      "Epoch [11/100], Iter [80/3426] Loss: 0.1821 Acc: 94 %\n",
      "Epoch [11/100], Iter [90/3426] Loss: 0.1553 Acc: 94 %\n",
      "Epoch [11/100], Iter [100/3426] Loss: 0.1486 Acc: 94 %\n",
      "Epoch [11/100], Iter [110/3426] Loss: 0.1352 Acc: 93 %\n",
      "Epoch [11/100], Iter [120/3426] Loss: 0.1623 Acc: 93 %\n",
      "Epoch [11/100], Iter [130/3426] Loss: 0.1681 Acc: 94 %\n",
      "Epoch [11/100], Iter [140/3426] Loss: 0.1597 Acc: 94 %\n",
      "Epoch [11/100], Iter [150/3426] Loss: 0.1497 Acc: 94 %\n",
      "Epoch [11/100], Iter [160/3426] Loss: 0.1931 Acc: 94 %\n",
      "Epoch [11/100], Iter [170/3426] Loss: 0.1746 Acc: 94 %\n",
      "Epoch [11/100], Iter [180/3426] Loss: 0.1595 Acc: 94 %\n",
      "Epoch [11/100], Iter [190/3426] Loss: 0.1687 Acc: 94 %\n",
      "Epoch [11/100], Iter [200/3426] Loss: 0.1445 Acc: 94 %\n",
      "Epoch [11/100], Iter [210/3426] Loss: 0.1523 Acc: 94 %\n",
      "Epoch [11/100], Iter [220/3426] Loss: 0.1764 Acc: 94 %\n",
      "Epoch [11/100], Iter [230/3426] Loss: 0.1459 Acc: 94 %\n",
      "Epoch [11/100], Iter [240/3426] Loss: 0.1581 Acc: 94 %\n",
      "Epoch [11/100], Iter [250/3426] Loss: 0.1673 Acc: 94 %\n",
      "Epoch [11/100], Iter [260/3426] Loss: 0.1507 Acc: 94 %\n",
      "Epoch [11/100], Iter [270/3426] Loss: 0.1436 Acc: 94 %\n",
      "Epoch [11/100], Iter [280/3426] Loss: 0.1566 Acc: 94 %\n",
      "Epoch [11/100], Iter [290/3426] Loss: 0.1684 Acc: 94 %\n",
      "Epoch [11/100], Iter [300/3426] Loss: 0.1379 Acc: 94 %\n",
      "Epoch [11/100], Iter [310/3426] Loss: 0.1392 Acc: 94 %\n",
      "Epoch [11/100], Iter [320/3426] Loss: 0.1738 Acc: 94 %\n",
      "Epoch [11/100], Iter [330/3426] Loss: 0.1581 Acc: 94 %\n",
      "Epoch [11/100], Iter [340/3426] Loss: 0.1658 Acc: 94 %\n",
      "Epoch [11/100], Iter [350/3426] Loss: 0.1651 Acc: 94 %\n",
      "Epoch [11/100], Iter [360/3426] Loss: 0.1522 Acc: 94 %\n",
      "Epoch [11/100], Iter [370/3426] Loss: 0.1505 Acc: 94 %\n",
      "Epoch [11/100], Iter [380/3426] Loss: 0.1693 Acc: 94 %\n",
      "Epoch [11/100], Iter [390/3426] Loss: 0.1557 Acc: 94 %\n",
      "Epoch [11/100], Iter [400/3426] Loss: 0.1950 Acc: 94 %\n",
      "Epoch [11/100], Iter [410/3426] Loss: 0.1561 Acc: 94 %\n",
      "Epoch [11/100], Iter [420/3426] Loss: 0.1638 Acc: 94 %\n",
      "Epoch [11/100], Iter [430/3426] Loss: 0.1567 Acc: 94 %\n",
      "Epoch [11/100], Iter [440/3426] Loss: 0.1511 Acc: 94 %\n",
      "Epoch [11/100], Iter [450/3426] Loss: 0.1541 Acc: 94 %\n",
      "Epoch [11/100], Iter [460/3426] Loss: 0.1675 Acc: 94 %\n",
      "Epoch [11/100], Iter [470/3426] Loss: 0.1532 Acc: 94 %\n",
      "Epoch [11/100], Iter [480/3426] Loss: 0.1348 Acc: 94 %\n",
      "Epoch [11/100], Iter [490/3426] Loss: 0.1506 Acc: 94 %\n",
      "Epoch [11/100], Iter [500/3426] Loss: 0.1521 Acc: 94 %\n",
      "Epoch [11/100], Iter [510/3426] Loss: 0.1605 Acc: 94 %\n",
      "Epoch [11/100], Iter [520/3426] Loss: 0.1734 Acc: 94 %\n",
      "Epoch [11/100], Iter [530/3426] Loss: 0.1498 Acc: 94 %\n",
      "Epoch [11/100], Iter [540/3426] Loss: 0.1461 Acc: 94 %\n",
      "Epoch [11/100], Iter [550/3426] Loss: 0.1592 Acc: 94 %\n",
      "Epoch [11/100], Iter [560/3426] Loss: 0.1610 Acc: 94 %\n",
      "Epoch [11/100], Iter [570/3426] Loss: 0.1614 Acc: 94 %\n",
      "Epoch [11/100], Iter [580/3426] Loss: 0.1679 Acc: 94 %\n",
      "Epoch [11/100], Iter [590/3426] Loss: 0.1561 Acc: 94 %\n",
      "Epoch [11/100], Iter [600/3426] Loss: 0.1555 Acc: 94 %\n",
      "Epoch [11/100], Iter [610/3426] Loss: 0.1648 Acc: 94 %\n",
      "Epoch [11/100], Iter [620/3426] Loss: 0.1759 Acc: 94 %\n",
      "Epoch [11/100], Iter [630/3426] Loss: 0.1732 Acc: 94 %\n",
      "Epoch [11/100], Iter [640/3426] Loss: 0.1548 Acc: 94 %\n",
      "Epoch [11/100], Iter [650/3426] Loss: 0.1662 Acc: 94 %\n",
      "Epoch [11/100], Iter [660/3426] Loss: 0.1283 Acc: 94 %\n",
      "Epoch [11/100], Iter [670/3426] Loss: 0.1644 Acc: 94 %\n",
      "Epoch [11/100], Iter [680/3426] Loss: 0.1676 Acc: 94 %\n",
      "Epoch [11/100], Iter [690/3426] Loss: 0.1528 Acc: 94 %\n",
      "Epoch [11/100], Iter [700/3426] Loss: 0.1439 Acc: 94 %\n",
      "Epoch [11/100], Iter [710/3426] Loss: 0.1677 Acc: 94 %\n",
      "Epoch [11/100], Iter [720/3426] Loss: 0.1582 Acc: 94 %\n",
      "Epoch [11/100], Iter [730/3426] Loss: 0.1708 Acc: 94 %\n",
      "Epoch [11/100], Iter [740/3426] Loss: 0.1649 Acc: 94 %\n",
      "Epoch [11/100], Iter [750/3426] Loss: 0.1593 Acc: 94 %\n",
      "Epoch [11/100], Iter [760/3426] Loss: 0.1549 Acc: 94 %\n",
      "Epoch [11/100], Iter [770/3426] Loss: 0.1539 Acc: 94 %\n",
      "Epoch [11/100], Iter [780/3426] Loss: 0.1476 Acc: 94 %\n",
      "Epoch [11/100], Iter [790/3426] Loss: 0.1362 Acc: 94 %\n",
      "Epoch [11/100], Iter [800/3426] Loss: 0.1532 Acc: 94 %\n",
      "Epoch [11/100], Iter [810/3426] Loss: 0.1359 Acc: 94 %\n",
      "Epoch [11/100], Iter [820/3426] Loss: 0.1798 Acc: 94 %\n",
      "Epoch [11/100], Iter [830/3426] Loss: 0.1483 Acc: 94 %\n",
      "Epoch [11/100], Iter [840/3426] Loss: 0.1507 Acc: 94 %\n",
      "Epoch [11/100], Iter [850/3426] Loss: 0.1779 Acc: 94 %\n",
      "Epoch [11/100], Iter [860/3426] Loss: 0.1474 Acc: 94 %\n",
      "Epoch [11/100], Iter [870/3426] Loss: 0.1568 Acc: 94 %\n",
      "Epoch [11/100], Iter [880/3426] Loss: 0.1357 Acc: 94 %\n",
      "Epoch [11/100], Iter [890/3426] Loss: 0.1656 Acc: 94 %\n",
      "Epoch [11/100], Iter [900/3426] Loss: 0.1688 Acc: 94 %\n",
      "Epoch [11/100], Iter [910/3426] Loss: 0.1573 Acc: 94 %\n",
      "Epoch [11/100], Iter [920/3426] Loss: 0.1515 Acc: 94 %\n",
      "Epoch [11/100], Iter [930/3426] Loss: 0.1471 Acc: 94 %\n",
      "Epoch [11/100], Iter [940/3426] Loss: 0.1633 Acc: 94 %\n",
      "Epoch [11/100], Iter [950/3426] Loss: 0.1591 Acc: 94 %\n",
      "Epoch [11/100], Iter [960/3426] Loss: 0.1687 Acc: 94 %\n",
      "Epoch [11/100], Iter [970/3426] Loss: 0.1584 Acc: 94 %\n",
      "Epoch [11/100], Iter [980/3426] Loss: 0.1877 Acc: 94 %\n",
      "Epoch [11/100], Iter [990/3426] Loss: 0.1289 Acc: 94 %\n",
      "Epoch [11/100], Iter [1000/3426] Loss: 0.1440 Acc: 94 %\n",
      "Epoch [11/100], Iter [1010/3426] Loss: 0.1687 Acc: 94 %\n",
      "Epoch [11/100], Iter [1020/3426] Loss: 0.1520 Acc: 94 %\n",
      "Epoch [11/100], Iter [1030/3426] Loss: 0.1669 Acc: 94 %\n",
      "Epoch [11/100], Iter [1040/3426] Loss: 0.1528 Acc: 94 %\n",
      "Epoch [11/100], Iter [1050/3426] Loss: 0.1565 Acc: 94 %\n",
      "Epoch [11/100], Iter [1060/3426] Loss: 0.1555 Acc: 94 %\n",
      "Epoch [11/100], Iter [1070/3426] Loss: 0.1430 Acc: 94 %\n",
      "Epoch [11/100], Iter [1080/3426] Loss: 0.1611 Acc: 94 %\n",
      "Epoch [11/100], Iter [1090/3426] Loss: 0.1495 Acc: 94 %\n",
      "Epoch [11/100], Iter [1100/3426] Loss: 0.1445 Acc: 94 %\n",
      "Epoch [11/100], Iter [1110/3426] Loss: 0.1446 Acc: 94 %\n",
      "Epoch [11/100], Iter [1120/3426] Loss: 0.2379 Acc: 94 %\n",
      "Epoch [11/100], Iter [1130/3426] Loss: 0.1769 Acc: 94 %\n",
      "Epoch [11/100], Iter [1140/3426] Loss: 0.1805 Acc: 94 %\n",
      "Epoch [11/100], Iter [1150/3426] Loss: 0.1670 Acc: 94 %\n",
      "Epoch [11/100], Iter [1160/3426] Loss: 0.1552 Acc: 94 %\n",
      "Epoch [11/100], Iter [1170/3426] Loss: 0.1460 Acc: 94 %\n",
      "Epoch [11/100], Iter [1180/3426] Loss: 0.1348 Acc: 94 %\n",
      "Epoch [11/100], Iter [1190/3426] Loss: 0.1540 Acc: 94 %\n",
      "Epoch [11/100], Iter [1200/3426] Loss: 0.1798 Acc: 94 %\n",
      "Epoch [11/100], Iter [1210/3426] Loss: 0.1639 Acc: 94 %\n",
      "Epoch [11/100], Iter [1220/3426] Loss: 0.1683 Acc: 94 %\n",
      "Epoch [11/100], Iter [1230/3426] Loss: 0.1616 Acc: 94 %\n",
      "Epoch [11/100], Iter [1240/3426] Loss: 0.1572 Acc: 94 %\n",
      "Epoch [11/100], Iter [1250/3426] Loss: 0.1493 Acc: 94 %\n",
      "Epoch [11/100], Iter [1260/3426] Loss: 0.1447 Acc: 94 %\n",
      "Epoch [11/100], Iter [1270/3426] Loss: 0.1538 Acc: 94 %\n",
      "Epoch [11/100], Iter [1280/3426] Loss: 0.1593 Acc: 94 %\n",
      "Epoch [11/100], Iter [1290/3426] Loss: 0.1515 Acc: 94 %\n",
      "Epoch [11/100], Iter [1300/3426] Loss: 0.1641 Acc: 94 %\n",
      "Epoch [11/100], Iter [1310/3426] Loss: 0.1377 Acc: 94 %\n",
      "Epoch [11/100], Iter [1320/3426] Loss: 0.1419 Acc: 94 %\n",
      "Epoch [11/100], Iter [1330/3426] Loss: 0.1517 Acc: 94 %\n",
      "Epoch [11/100], Iter [1340/3426] Loss: 0.1616 Acc: 94 %\n",
      "Epoch [11/100], Iter [1350/3426] Loss: 0.1583 Acc: 94 %\n",
      "Epoch [11/100], Iter [1360/3426] Loss: 0.1718 Acc: 94 %\n",
      "Epoch [11/100], Iter [1370/3426] Loss: 0.1687 Acc: 94 %\n",
      "Epoch [11/100], Iter [1380/3426] Loss: 0.1686 Acc: 94 %\n",
      "Epoch [11/100], Iter [1390/3426] Loss: 0.1713 Acc: 94 %\n",
      "Epoch [11/100], Iter [1400/3426] Loss: 0.1372 Acc: 94 %\n",
      "Epoch [11/100], Iter [1410/3426] Loss: 0.1496 Acc: 94 %\n",
      "Epoch [11/100], Iter [1420/3426] Loss: 0.1486 Acc: 94 %\n",
      "Epoch [11/100], Iter [1430/3426] Loss: 0.1702 Acc: 94 %\n",
      "Epoch [11/100], Iter [1440/3426] Loss: 0.1492 Acc: 94 %\n",
      "Epoch [11/100], Iter [1450/3426] Loss: 0.1503 Acc: 94 %\n",
      "Epoch [11/100], Iter [1460/3426] Loss: 0.1559 Acc: 94 %\n",
      "Epoch [11/100], Iter [1470/3426] Loss: 0.1574 Acc: 94 %\n",
      "Epoch [11/100], Iter [1480/3426] Loss: 0.1774 Acc: 94 %\n",
      "Epoch [11/100], Iter [1490/3426] Loss: 0.1453 Acc: 94 %\n",
      "Epoch [11/100], Iter [1500/3426] Loss: 0.1556 Acc: 94 %\n",
      "Epoch [11/100], Iter [1510/3426] Loss: 0.1500 Acc: 94 %\n",
      "Epoch [11/100], Iter [1520/3426] Loss: 0.1788 Acc: 94 %\n",
      "Epoch [11/100], Iter [1530/3426] Loss: 0.1812 Acc: 94 %\n",
      "Epoch [11/100], Iter [1540/3426] Loss: 0.1465 Acc: 94 %\n",
      "Epoch [11/100], Iter [1550/3426] Loss: 0.1466 Acc: 94 %\n",
      "Epoch [11/100], Iter [1560/3426] Loss: 0.1845 Acc: 94 %\n",
      "Epoch [11/100], Iter [1570/3426] Loss: 0.1545 Acc: 94 %\n",
      "Epoch [11/100], Iter [1580/3426] Loss: 0.1459 Acc: 94 %\n",
      "Epoch [11/100], Iter [1590/3426] Loss: 0.1518 Acc: 94 %\n",
      "Epoch [11/100], Iter [1600/3426] Loss: 0.1664 Acc: 94 %\n",
      "Epoch [11/100], Iter [1610/3426] Loss: 0.1737 Acc: 94 %\n",
      "Epoch [11/100], Iter [1620/3426] Loss: 0.1523 Acc: 94 %\n",
      "Epoch [11/100], Iter [1630/3426] Loss: 0.1733 Acc: 94 %\n",
      "Epoch [11/100], Iter [1640/3426] Loss: 0.1638 Acc: 94 %\n",
      "Epoch [11/100], Iter [1650/3426] Loss: 0.1746 Acc: 94 %\n",
      "Epoch [11/100], Iter [1660/3426] Loss: 0.1334 Acc: 94 %\n",
      "Epoch [11/100], Iter [1670/3426] Loss: 0.1439 Acc: 94 %\n",
      "Epoch [11/100], Iter [1680/3426] Loss: 0.1649 Acc: 94 %\n",
      "Epoch [11/100], Iter [1690/3426] Loss: 0.1573 Acc: 94 %\n",
      "Epoch [11/100], Iter [1700/3426] Loss: 0.1548 Acc: 94 %\n",
      "Epoch [11/100], Iter [1710/3426] Loss: 0.1916 Acc: 94 %\n",
      "Epoch [11/100], Iter [1720/3426] Loss: 0.1431 Acc: 94 %\n",
      "Epoch [11/100], Iter [1730/3426] Loss: 0.1868 Acc: 94 %\n",
      "Epoch [11/100], Iter [1740/3426] Loss: 0.1751 Acc: 94 %\n",
      "Epoch [11/100], Iter [1750/3426] Loss: 0.1466 Acc: 94 %\n",
      "Epoch [11/100], Iter [1760/3426] Loss: 0.1595 Acc: 94 %\n",
      "Epoch [11/100], Iter [1770/3426] Loss: 0.1577 Acc: 94 %\n",
      "Epoch [11/100], Iter [1780/3426] Loss: 0.1595 Acc: 94 %\n",
      "Epoch [11/100], Iter [1790/3426] Loss: 0.1494 Acc: 94 %\n",
      "Epoch [11/100], Iter [1800/3426] Loss: 0.1852 Acc: 94 %\n",
      "Epoch [11/100], Iter [1810/3426] Loss: 0.1677 Acc: 94 %\n",
      "Epoch [11/100], Iter [1820/3426] Loss: 0.1616 Acc: 94 %\n",
      "Epoch [11/100], Iter [1830/3426] Loss: 0.1856 Acc: 94 %\n",
      "Epoch [11/100], Iter [1840/3426] Loss: 0.1594 Acc: 94 %\n",
      "Epoch [11/100], Iter [1850/3426] Loss: 0.1622 Acc: 94 %\n",
      "Epoch [11/100], Iter [1860/3426] Loss: 0.1715 Acc: 94 %\n",
      "Epoch [11/100], Iter [1870/3426] Loss: 0.1732 Acc: 94 %\n",
      "Epoch [11/100], Iter [1880/3426] Loss: 0.1528 Acc: 94 %\n",
      "Epoch [11/100], Iter [1890/3426] Loss: 0.1547 Acc: 94 %\n",
      "Epoch [11/100], Iter [1900/3426] Loss: 0.1510 Acc: 94 %\n",
      "Epoch [11/100], Iter [1910/3426] Loss: 0.1642 Acc: 94 %\n",
      "Epoch [11/100], Iter [1920/3426] Loss: 0.1467 Acc: 94 %\n",
      "Epoch [11/100], Iter [1930/3426] Loss: 0.1420 Acc: 94 %\n",
      "Epoch [11/100], Iter [1940/3426] Loss: 0.1578 Acc: 94 %\n",
      "Epoch [11/100], Iter [1950/3426] Loss: 0.1730 Acc: 94 %\n",
      "Epoch [11/100], Iter [1960/3426] Loss: 0.1483 Acc: 94 %\n",
      "Epoch [11/100], Iter [1970/3426] Loss: 0.1428 Acc: 94 %\n",
      "Epoch [11/100], Iter [1980/3426] Loss: 0.1516 Acc: 94 %\n",
      "Epoch [11/100], Iter [1990/3426] Loss: 0.1375 Acc: 94 %\n",
      "Epoch [11/100], Iter [2000/3426] Loss: 0.1630 Acc: 94 %\n",
      "Epoch [11/100], Iter [2010/3426] Loss: 0.1908 Acc: 94 %\n",
      "Epoch [11/100], Iter [2020/3426] Loss: 0.1538 Acc: 94 %\n",
      "Epoch [11/100], Iter [2030/3426] Loss: 0.1463 Acc: 94 %\n",
      "Epoch [11/100], Iter [2040/3426] Loss: 0.1544 Acc: 94 %\n",
      "Epoch [11/100], Iter [2050/3426] Loss: 0.1577 Acc: 94 %\n",
      "Epoch [11/100], Iter [2060/3426] Loss: 0.1782 Acc: 94 %\n",
      "Epoch [11/100], Iter [2070/3426] Loss: 0.1252 Acc: 94 %\n",
      "Epoch [11/100], Iter [2080/3426] Loss: 0.1339 Acc: 94 %\n",
      "Epoch [11/100], Iter [2090/3426] Loss: 0.1541 Acc: 94 %\n",
      "Epoch [11/100], Iter [2100/3426] Loss: 0.1491 Acc: 94 %\n",
      "Epoch [11/100], Iter [2110/3426] Loss: 0.1633 Acc: 94 %\n",
      "Epoch [11/100], Iter [2120/3426] Loss: 0.1385 Acc: 94 %\n",
      "Epoch [11/100], Iter [2130/3426] Loss: 0.1429 Acc: 94 %\n",
      "Epoch [11/100], Iter [2140/3426] Loss: 0.1884 Acc: 94 %\n",
      "Epoch [11/100], Iter [2150/3426] Loss: 0.1603 Acc: 94 %\n",
      "Epoch [11/100], Iter [2160/3426] Loss: 0.1673 Acc: 94 %\n",
      "Epoch [11/100], Iter [2170/3426] Loss: 0.1668 Acc: 94 %\n",
      "Epoch [11/100], Iter [2180/3426] Loss: 0.1676 Acc: 94 %\n",
      "Epoch [11/100], Iter [2190/3426] Loss: 0.1536 Acc: 94 %\n",
      "Epoch [11/100], Iter [2200/3426] Loss: 0.1500 Acc: 94 %\n",
      "Epoch [11/100], Iter [2210/3426] Loss: 0.1662 Acc: 94 %\n",
      "Epoch [11/100], Iter [2220/3426] Loss: 0.1509 Acc: 94 %\n",
      "Epoch [11/100], Iter [2230/3426] Loss: 0.1961 Acc: 94 %\n",
      "Epoch [11/100], Iter [2240/3426] Loss: 0.1371 Acc: 94 %\n",
      "Epoch [11/100], Iter [2250/3426] Loss: 0.1673 Acc: 94 %\n",
      "Epoch [11/100], Iter [2260/3426] Loss: 0.1606 Acc: 94 %\n",
      "Epoch [11/100], Iter [2270/3426] Loss: 0.1837 Acc: 94 %\n",
      "Epoch [11/100], Iter [2280/3426] Loss: 0.1493 Acc: 94 %\n",
      "Epoch [11/100], Iter [2290/3426] Loss: 0.1544 Acc: 94 %\n",
      "Epoch [11/100], Iter [2300/3426] Loss: 0.1446 Acc: 94 %\n",
      "Epoch [11/100], Iter [2310/3426] Loss: 0.1621 Acc: 94 %\n",
      "Epoch [11/100], Iter [2320/3426] Loss: 0.1317 Acc: 94 %\n",
      "Epoch [11/100], Iter [2330/3426] Loss: 0.1524 Acc: 94 %\n",
      "Epoch [11/100], Iter [2340/3426] Loss: 0.1652 Acc: 94 %\n",
      "Epoch [11/100], Iter [2350/3426] Loss: 0.1485 Acc: 94 %\n",
      "Epoch [11/100], Iter [2360/3426] Loss: 0.1627 Acc: 94 %\n",
      "Epoch [11/100], Iter [2370/3426] Loss: 0.1488 Acc: 94 %\n",
      "Epoch [11/100], Iter [2380/3426] Loss: 0.1629 Acc: 94 %\n",
      "Epoch [11/100], Iter [2390/3426] Loss: 0.2118 Acc: 94 %\n",
      "Epoch [11/100], Iter [2400/3426] Loss: 0.1493 Acc: 94 %\n",
      "Epoch [11/100], Iter [2410/3426] Loss: 0.1452 Acc: 94 %\n",
      "Epoch [11/100], Iter [2420/3426] Loss: 0.1485 Acc: 94 %\n",
      "Epoch [11/100], Iter [2430/3426] Loss: 0.1552 Acc: 94 %\n",
      "Epoch [11/100], Iter [2440/3426] Loss: 0.1368 Acc: 94 %\n",
      "Epoch [11/100], Iter [2450/3426] Loss: 0.1476 Acc: 94 %\n",
      "Epoch [11/100], Iter [2460/3426] Loss: 0.1296 Acc: 94 %\n",
      "Epoch [11/100], Iter [2470/3426] Loss: 0.1663 Acc: 94 %\n",
      "Epoch [11/100], Iter [2480/3426] Loss: 0.1441 Acc: 94 %\n",
      "Epoch [11/100], Iter [2490/3426] Loss: 0.1559 Acc: 94 %\n",
      "Epoch [11/100], Iter [2500/3426] Loss: 0.1853 Acc: 94 %\n",
      "Epoch [11/100], Iter [2510/3426] Loss: 0.1486 Acc: 94 %\n",
      "Epoch [11/100], Iter [2520/3426] Loss: 0.1635 Acc: 94 %\n",
      "Epoch [11/100], Iter [2530/3426] Loss: 0.1518 Acc: 94 %\n",
      "Epoch [11/100], Iter [2540/3426] Loss: 0.1696 Acc: 94 %\n",
      "Epoch [11/100], Iter [2550/3426] Loss: 0.1619 Acc: 94 %\n",
      "Epoch [11/100], Iter [2560/3426] Loss: 0.1809 Acc: 94 %\n",
      "Epoch [11/100], Iter [2570/3426] Loss: 0.1484 Acc: 94 %\n",
      "Epoch [11/100], Iter [2580/3426] Loss: 0.1601 Acc: 94 %\n",
      "Epoch [11/100], Iter [2590/3426] Loss: 0.1901 Acc: 94 %\n",
      "Epoch [11/100], Iter [2600/3426] Loss: 0.1428 Acc: 94 %\n",
      "Epoch [11/100], Iter [2610/3426] Loss: 0.1723 Acc: 94 %\n",
      "Epoch [11/100], Iter [2620/3426] Loss: 0.1441 Acc: 94 %\n",
      "Epoch [11/100], Iter [2630/3426] Loss: 0.1472 Acc: 94 %\n",
      "Epoch [11/100], Iter [2640/3426] Loss: 0.1839 Acc: 94 %\n",
      "Epoch [11/100], Iter [2650/3426] Loss: 0.1580 Acc: 94 %\n",
      "Epoch [11/100], Iter [2660/3426] Loss: 0.1813 Acc: 94 %\n",
      "Epoch [11/100], Iter [2670/3426] Loss: 0.1293 Acc: 94 %\n",
      "Epoch [11/100], Iter [2680/3426] Loss: 0.1681 Acc: 94 %\n",
      "Epoch [11/100], Iter [2690/3426] Loss: 0.1506 Acc: 94 %\n",
      "Epoch [11/100], Iter [2700/3426] Loss: 0.1585 Acc: 94 %\n",
      "Epoch [11/100], Iter [2710/3426] Loss: 0.1382 Acc: 94 %\n",
      "Epoch [11/100], Iter [2720/3426] Loss: 0.1322 Acc: 94 %\n",
      "Epoch [11/100], Iter [2730/3426] Loss: 0.1802 Acc: 94 %\n",
      "Epoch [11/100], Iter [2740/3426] Loss: 0.1774 Acc: 94 %\n",
      "Epoch [11/100], Iter [2750/3426] Loss: 0.1604 Acc: 94 %\n",
      "Epoch [11/100], Iter [2760/3426] Loss: 0.1633 Acc: 94 %\n",
      "Epoch [11/100], Iter [2770/3426] Loss: 0.1631 Acc: 94 %\n",
      "Epoch [11/100], Iter [2780/3426] Loss: 0.1668 Acc: 94 %\n",
      "Epoch [11/100], Iter [2790/3426] Loss: 0.1795 Acc: 94 %\n",
      "Epoch [11/100], Iter [2800/3426] Loss: 0.1443 Acc: 94 %\n",
      "Epoch [11/100], Iter [2810/3426] Loss: 0.1600 Acc: 94 %\n",
      "Epoch [11/100], Iter [2820/3426] Loss: 0.1583 Acc: 94 %\n",
      "Epoch [11/100], Iter [2830/3426] Loss: 0.1343 Acc: 94 %\n",
      "Epoch [11/100], Iter [2840/3426] Loss: 0.1598 Acc: 94 %\n",
      "Epoch [11/100], Iter [2850/3426] Loss: 0.1583 Acc: 94 %\n",
      "Epoch [11/100], Iter [2860/3426] Loss: 0.1564 Acc: 94 %\n",
      "Epoch [11/100], Iter [2870/3426] Loss: 0.1684 Acc: 94 %\n",
      "Epoch [11/100], Iter [2880/3426] Loss: 0.1660 Acc: 94 %\n",
      "Epoch [11/100], Iter [2890/3426] Loss: 0.1646 Acc: 94 %\n",
      "Epoch [11/100], Iter [2900/3426] Loss: 0.1449 Acc: 94 %\n",
      "Epoch [11/100], Iter [2910/3426] Loss: 0.1655 Acc: 94 %\n",
      "Epoch [11/100], Iter [2920/3426] Loss: 0.1459 Acc: 94 %\n",
      "Epoch [11/100], Iter [2930/3426] Loss: 0.1712 Acc: 94 %\n",
      "Epoch [11/100], Iter [2940/3426] Loss: 0.1339 Acc: 94 %\n",
      "Epoch [11/100], Iter [2950/3426] Loss: 0.1322 Acc: 94 %\n",
      "Epoch [11/100], Iter [2960/3426] Loss: 0.1787 Acc: 94 %\n",
      "Epoch [11/100], Iter [2970/3426] Loss: 0.1824 Acc: 94 %\n",
      "Epoch [11/100], Iter [2980/3426] Loss: 0.1575 Acc: 94 %\n",
      "Epoch [11/100], Iter [2990/3426] Loss: 0.1554 Acc: 94 %\n",
      "Epoch [11/100], Iter [3000/3426] Loss: 0.1581 Acc: 94 %\n",
      "Epoch [11/100], Iter [3010/3426] Loss: 0.1670 Acc: 94 %\n",
      "Epoch [11/100], Iter [3020/3426] Loss: 0.1538 Acc: 94 %\n",
      "Epoch [11/100], Iter [3030/3426] Loss: 0.1587 Acc: 94 %\n",
      "Epoch [11/100], Iter [3040/3426] Loss: 0.1994 Acc: 94 %\n",
      "Epoch [11/100], Iter [3050/3426] Loss: 0.1439 Acc: 94 %\n",
      "Epoch [11/100], Iter [3060/3426] Loss: 0.1338 Acc: 94 %\n",
      "Epoch [11/100], Iter [3070/3426] Loss: 0.1610 Acc: 94 %\n",
      "Epoch [11/100], Iter [3080/3426] Loss: 0.1928 Acc: 94 %\n",
      "Epoch [11/100], Iter [3090/3426] Loss: 0.1469 Acc: 94 %\n",
      "Epoch [11/100], Iter [3100/3426] Loss: 0.1711 Acc: 94 %\n",
      "Epoch [11/100], Iter [3110/3426] Loss: 0.1396 Acc: 94 %\n",
      "Epoch [11/100], Iter [3120/3426] Loss: 0.1361 Acc: 94 %\n",
      "Epoch [11/100], Iter [3130/3426] Loss: 0.1494 Acc: 94 %\n",
      "Epoch [11/100], Iter [3140/3426] Loss: 0.2018 Acc: 94 %\n",
      "Epoch [11/100], Iter [3150/3426] Loss: 0.1463 Acc: 94 %\n",
      "Epoch [11/100], Iter [3160/3426] Loss: 0.1719 Acc: 94 %\n",
      "Epoch [11/100], Iter [3170/3426] Loss: 0.1331 Acc: 94 %\n",
      "Epoch [11/100], Iter [3180/3426] Loss: 0.1739 Acc: 94 %\n",
      "Epoch [11/100], Iter [3190/3426] Loss: 0.1844 Acc: 94 %\n",
      "Epoch [11/100], Iter [3200/3426] Loss: 0.1491 Acc: 94 %\n",
      "Epoch [11/100], Iter [3210/3426] Loss: 0.1743 Acc: 94 %\n",
      "Epoch [11/100], Iter [3220/3426] Loss: 0.1623 Acc: 94 %\n",
      "Epoch [11/100], Iter [3230/3426] Loss: 0.1681 Acc: 94 %\n",
      "Epoch [11/100], Iter [3240/3426] Loss: 0.1526 Acc: 94 %\n",
      "Epoch [11/100], Iter [3250/3426] Loss: 0.1495 Acc: 94 %\n",
      "Epoch [11/100], Iter [3260/3426] Loss: 0.1342 Acc: 94 %\n",
      "Epoch [11/100], Iter [3270/3426] Loss: 0.1293 Acc: 94 %\n",
      "Epoch [11/100], Iter [3280/3426] Loss: 0.1408 Acc: 94 %\n",
      "Epoch [11/100], Iter [3290/3426] Loss: 0.1653 Acc: 94 %\n",
      "Epoch [11/100], Iter [3300/3426] Loss: 0.1789 Acc: 94 %\n",
      "Epoch [11/100], Iter [3310/3426] Loss: 0.1560 Acc: 94 %\n",
      "Epoch [11/100], Iter [3320/3426] Loss: 0.1612 Acc: 94 %\n",
      "Epoch [11/100], Iter [3330/3426] Loss: 0.1799 Acc: 94 %\n",
      "Epoch [11/100], Iter [3340/3426] Loss: 0.1667 Acc: 94 %\n",
      "Epoch [11/100], Iter [3350/3426] Loss: 0.1536 Acc: 94 %\n",
      "Epoch [11/100], Iter [3360/3426] Loss: 0.1388 Acc: 94 %\n",
      "Epoch [11/100], Iter [3370/3426] Loss: 0.1350 Acc: 94 %\n",
      "Epoch [11/100], Iter [3380/3426] Loss: 0.1167 Acc: 94 %\n",
      "Epoch [11/100], Iter [3390/3426] Loss: 0.1714 Acc: 94 %\n",
      "Epoch [11/100], Iter [3400/3426] Loss: 0.1559 Acc: 94 %\n",
      "Epoch [11/100], Iter [3410/3426] Loss: 0.1646 Acc: 94 %\n",
      "Epoch [11/100], Iter [3420/3426] Loss: 0.1532 Acc: 94 %\n",
      "Accuracy of the model on the neg seq: 91 %\n",
      "Accuracy of the model on the pos seq: 94 %\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "for epoch in range(total_epoch):\n",
    "    loss_mean,acc_non,acc_in = train(epoch)\n",
    "    specificity,sensitivity,loss_t = test(epoch)\n",
    "    scheduler.step(loss_t)\n",
    "    write_loss.add_scalars('loss_acc/epoch',{\n",
    "        'train_loss':loss_mean,\n",
    "        'train_acc_neg':acc_non,\n",
    "        'train_acc_pos':acc_in,\n",
    "        'test_specificity':specificity,\n",
    "        'test_sensitivity':sensitivity,\n",
    "        'test_loss': loss_t,\n",
    "    },epoch)\n",
    "\n",
    "    if epoch % 10 == 0 :\n",
    "        save_filename =  'conv4-3_epoch-'+str(epoch)+'.pth'\n",
    "        save_path = os.path.join(save_dir, save_filename)\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    early_stopping(loss_t,model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    \n",
    "name = 'conv4-3_final'+'.pth'\n",
    "path = os.path.join(save_dir, name)\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/home/jiahao/code/SPH6004/mimiciv_aki/model/conv4-7_final.pth'))\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "F = torch.nn.Sigmoid()\n",
    "# model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_sum_t = 0\n",
    "nb_classes = 2\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "pred_y = list()\n",
    "test_y = list()\n",
    "probas_y = list()\n",
    "probas_y2 = list()\n",
    "model = model.cuda()\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for images,labels in test_loader:\n",
    "\n",
    "        images = Variable(images.unsqueeze(3).float().cuda())\n",
    "        a = labels\n",
    "        labels = Variable(labels.view(-1,1).cuda()).float()\n",
    "        \n",
    "        logits = model(images)\n",
    "        results = F(logits)\n",
    "        loss_test = criterion(logits, labels)\n",
    "        iter_loss_t = loss_test.data.item()\n",
    "        loss_sum_t += float(iter_loss_t)\n",
    "        outputs_m = 1-results\n",
    "        outputs_f = torch.cat((outputs_m,results),1)\n",
    "        probas_y.extend(outputs_f.data.cpu().numpy().tolist())\n",
    "        probas_y2.extend(results.data.cpu().numpy().tolist())\n",
    "       \n",
    "        test_y.extend(a.data.cpu().numpy().flatten().tolist())\n",
    "        predicted = (results.data>0.5).float()\n",
    "        pred_y.extend(predicted.data.cpu().numpy().flatten().tolist())\n",
    "        \n",
    "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "            confusion_matrix[t.long(), p.long()] += 1\n",
    "    acc = confusion_matrix.diag() / confusion_matrix.sum(1)\n",
    "    acc_non = acc[0]\n",
    "    acc_in = acc[1]\n",
    "    mean_acc = torch.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790491337781124"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scikitplot as skplt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "np_test = np.asarray(test_y)\n",
    "np_pred = np.asarray(pred_y)\n",
    "np_prob = np.asarray(probas_y)\n",
    "np_prob_2 = np.asarray(probas_y2)\n",
    "roc=skplt.metrics.plot_roc(np_test, np_prob,plot_micro=False,plot_macro=False,\n",
    "                         text_fontsize ='large')\n",
    "\n",
    "fpr_1, tpr_1, thresholds_1 =sklearn.metrics.roc_curve(np_test, np_prob_2)\n",
    "\n",
    "# plt.savefig('roc_inception_1_1_early.png', dpi=300)\n",
    "conf=skplt.metrics.plot_confusion_matrix(np_test, np_pred)\n",
    "# plt.savefig('conf_inception_1_2_early.png', dpi=300)\n",
    "sklearn.metrics.auc(fpr_1, tpr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5976767539978027]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import pandas as pd\n",
    "threshold = Find_Optimal_Cutoff(test_y, probas_y2)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
